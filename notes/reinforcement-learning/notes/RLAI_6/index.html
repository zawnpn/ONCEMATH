<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Welcome to zhangwp's blog."><link href=https://www.zhangwp.com/notes/reinforcement-learning/notes/RLAI_6/ rel=canonical><meta name=author content=zawnpn><link rel="shortcut icon" href=../../../../assets/images/favicon.svg><meta name=generator content="mkdocs-1.1.2, mkdocs-material-5.4.0"><title>Chapter 6 - ZHANGWP</title><link rel=stylesheet href=../../../../assets/stylesheets/main.fe0cca5b.min.css><link rel=stylesheet href=../../../../assets/stylesheets/palette.a46bcfb3.min.css><meta name=theme-color content=#546e7a></head> <body dir=ltr data-md-color-scheme data-md-color-primary=blue-grey data-md-color-accent> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#- class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https://www.zhangwp.com title=ZHANGWP class="md-header-nav__button md-logo" aria-label=ZHANGWP> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><path d="M257.981 272.971L63.638 467.314c-9.373 9.373-24.569 9.373-33.941 0L7.029 444.647c-9.357-9.357-9.375-24.522-.04-33.901L161.011 256 6.99 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L257.981 239.03c9.373 9.372 9.373 24.568 0 33.941zM640 456v-32c0-13.255-10.745-24-24-24H312c-13.255 0-24 10.745-24 24v32c0 13.255 10.745 24 24 24h304c13.255 0 24-10.745 24-24z"/></svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> ZHANGWP </span> <span class="md-header-nav__topic md-ellipsis"> Chapter 6 </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a href=https://github.com/zawnpn/ZHANGWP/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class="md-tabs md-tabs--active" aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../ class="md-tabs__link md-tabs__link--active"> Notes </a> </li> <li class=md-tabs__item> <a href=../../../../tips/ class=md-tabs__link> Tips </a> </li> <li class=md-tabs__item> <a href=../../../../share/ class=md-tabs__link> Share </a> </li> <li class=md-tabs__item> <a href=../../../../statements/ class=md-tabs__link> Statements </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https://www.zhangwp.com title=ZHANGWP class="md-nav__button md-logo" aria-label=ZHANGWP> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><path d="M257.981 272.971L63.638 467.314c-9.373 9.373-24.569 9.373-33.941 0L7.029 444.647c-9.357-9.357-9.375-24.522-.04-33.901L161.011 256 6.99 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L257.981 239.03c9.373 9.372 9.373 24.568 0 33.941zM640 456v-32c0-13.255-10.745-24-24-24H312c-13.255 0-24 10.745-24 24v32c0 13.255 10.745 24 24 24h304c13.255 0 24-10.745 24-24z"/></svg> </a> ZHANGWP </label> <div class=md-nav__source> <a href=https://github.com/zawnpn/ZHANGWP/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1 type=checkbox id=nav-1> <label class=md-nav__link for=nav-1> Home <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Home data-md-level=1> <label class=md-nav__title for=nav-1> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../.. title=Home class=md-nav__link> Home </a> </li> <li class=md-nav__item> <a href=../../../../links/ title=Links class=md-nav__link> Links </a> </li> <li class=md-nav__item> <a href=../../../../donates/ title=Donate class=md-nav__link> Donate </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2 checked> <label class=md-nav__link for=nav-2> Notes <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Notes data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Notes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../ title=Index class=md-nav__link> Index </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-2 type=checkbox id=nav-2-2 checked> <label class=md-nav__link for=nav-2-2> Reinforcement <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Reinforcement data-md-level=2> <label class=md-nav__title for=nav-2-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Reinforcement </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-2-1 type=checkbox id=nav-2-2-1 checked> <label class=md-nav__link for=nav-2-2-1> Reinforcement Learning An Introduction <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Reinforcement Learning An Introduction" data-md-level=3> <label class=md-nav__title for=nav-2-2-1> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Reinforcement Learning An Introduction </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../RLAI_2/ title="Chapter 2" class=md-nav__link> Chapter 2 </a> </li> <li class=md-nav__item> <a href=../RLAI_3/ title="Chapter 3" class=md-nav__link> Chapter 3 </a> </li> <li class=md-nav__item> <a href=../RLAI_4/ title="Chapter 4" class=md-nav__link> Chapter 4 </a> </li> <li class=md-nav__item> <a href=../RLAI_5/ title="Chapter 5" class=md-nav__link> Chapter 5 </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Chapter 6 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg> </span> </label> <a href=./ title="Chapter 6" class="md-nav__link md-nav__link--active"> Chapter 6 </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#61-td-prediction class=md-nav__link> 6.1 TD Prediction </a> </li> <li class=md-nav__item> <a href=#62-advantages-of-td-prediction-methods class=md-nav__link> 6.2 Advantages of TD Prediction Methods </a> <nav class=md-nav aria-label="6.2 Advantages of TD Prediction Methods"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_1 class=md-nav__link> 优点 </a> </li> <li class=md-nav__item> <a href=#_2 class=md-nav__link> 收敛性 </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> 效率对比 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#63-optimality-of-td0 class=md-nav__link> 6.3 Optimality of TD(0) </a> <nav class=md-nav aria-label="6.3 Optimality of TD(0)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#batch-update class=md-nav__link> 批量更新（Batch Update） </a> </li> <li class=md-nav__item> <a href=#certainty-equivalence-estimate class=md-nav__link> Certainty-Equivalence Estimate </a> <nav class=md-nav aria-label="Certainty-Equivalence Estimate"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_4 class=md-nav__link> 例子 </a> </li> <li class=md-nav__item> <a href=#td0-methods class=md-nav__link> TD(0) methods </a> </li> <li class=md-nav__item> <a href=#mc-methods class=md-nav__link> MC methods </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> 确定性等价估计 </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#64-65-66-td-control class=md-nav__link> 6.4 &amp; 6.5 &amp; 6.6 TD Control </a> <nav class=md-nav aria-label="6.4 & 6.5 & 6.6 TD Control"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sarsa class=md-nav__link> Sarsa 算法 </a> </li> <li class=md-nav__item> <a href=#q-learning class=md-nav__link> Q-learning 算法 </a> </li> <li class=md-nav__item> <a href=#expected-sarsa class=md-nav__link> Expected Sarsa 算法 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#67-maximization-bias-and-double-learning class=md-nav__link> 6.7 Maximization Bias and Double Learning </a> <nav class=md-nav aria-label="6.7 Maximization Bias and Double Learning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#double-learning class=md-nav__link> Double Learning </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#68-games-afterstates-and-other-special-cases class=md-nav__link> 6.8 Games, Afterstates, and Other Special Cases </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../RLAI_7/ title="Chapter 7" class=md-nav__link> Chapter 7 </a> </li> <li class=md-nav__item> <a href=../RLAI_8/ title="Chapter 8" class=md-nav__link> Chapter 8 </a> </li> <li class=md-nav__item> <a href=../RLAI_9/ title="Chapter 9" class=md-nav__link> Chapter 9 </a> </li> <li class=md-nav__item> <a href=../RLAI_10/ title="Chapter 10" class=md-nav__link> Chapter 10 </a> </li> <li class=md-nav__item> <a href=../RLAI_11/ title="Chapter 11" class=md-nav__link> Chapter 11 </a> </li> <li class=md-nav__item> <a href=../RLAI_12/ title="Chapter 12" class=md-nav__link> Chapter 12 </a> </li> <li class=md-nav__item> <a href=../RLAI_13/ title="Chapter 13" class=md-nav__link> Chapter 13 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-2-2 type=checkbox id=nav-2-2-2> <label class=md-nav__link for=nav-2-2-2> Some Introduction <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Some Introduction" data-md-level=3> <label class=md-nav__title for=nav-2-2-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Some Introduction </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../MCTS_introduction/ title=MCTS class=md-nav__link> MCTS </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Tips <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Tips data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Tips </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../tips/ title=Tips class=md-nav__link> Tips </a> </li> <li class=md-nav__item> <a href=../../../../tips/to-do/ title="To Do" class=md-nav__link> To Do </a> </li> <li class=md-nav__item> <a href=../../../../tips/python/ title=Python class=md-nav__link> Python </a> </li> <li class=md-nav__item> <a href=../../../../tips/data-processing/ title="Data Processing" class=md-nav__link> Data Processing </a> </li> <li class=md-nav__item> <a href=../../../../tips/git/ title=Git class=md-nav__link> Git </a> </li> <li class=md-nav__item> <a href=../../../../tips/linux/ title=Linux class=md-nav__link> Linux </a> </li> <li class=md-nav__item> <a href=../../../../tips/win/ title=Windows class=md-nav__link> Windows </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <label class=md-nav__link for=nav-4> Share <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Share data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Share </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/ title=Index class=md-nav__link> Index </a> </li> <li class=md-nav__item> <a href=../../../../share/blog-history/ title=博客历史 class=md-nav__link> 博客历史 </a> </li> <li class=md-nav__item> <a href=../../../../share/game-log/ title=Game-Log class=md-nav__link> Game-Log </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-4 type=checkbox id=nav-4-4> <label class=md-nav__link for=nav-4-4> NKU-Toolkit <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=NKU-Toolkit data-md-level=2> <label class=md-nav__title for=nav-4-4> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> NKU-Toolkit </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/nku-eamis/ title=NKU-EAMIS工具 class=md-nav__link> NKU-EAMIS工具 </a> </li> <li class=md-nav__item> <a href=../../../../share/nku-sms-rss/ title=NKU-SMS-RSS class=md-nav__link> NKU-SMS-RSS </a> </li> <li class=md-nav__item> <a href=../../../../share/eamis-miniapp/ title=NKU-EAMIS_MiniApp(南开大学教务助手小程序) class=md-nav__link> NKU-EAMIS_MiniApp(南开大学教务助手小程序) </a> </li> <li class=md-nav__item> <a href=../../../../share/eamis-workflow/ title="NKU-EAMIS for iOS(Workflow)" class=md-nav__link> NKU-EAMIS for iOS(Workflow) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-5 type=checkbox id=nav-4-5> <label class=md-nav__link for=nav-4-5> Steam-Toolkit <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Steam-Toolkit data-md-level=2> <label class=md-nav__title for=nav-4-5> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Steam-Toolkit </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/steam-market-price-bot/ title=Steam市场比价爬虫 class=md-nav__link> Steam市场比价爬虫 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-6 type=checkbox id=nav-4-6> <label class=md-nav__link for=nav-4-6> 数学建模 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=数学建模 data-md-level=2> <label class=md-nav__title for=nav-4-6> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> 数学建模 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/2017-mcm-icm/ title="2017美赛参赛整理(Problem D)" class=md-nav__link> 2017美赛参赛整理(Problem D) </a> </li> <li class=md-nav__item> <a href=../../../../share/2016-guosai/ title=2016数学建模国赛 class=md-nav__link> 2016数学建模国赛 </a> </li> <li class=md-nav__item> <a href=../../../../share/math-model-szb/ title=数学建模之2016深圳杯——初次尝试 class=md-nav__link> 数学建模之2016深圳杯——初次尝试 </a> </li> <li class=md-nav__item> <a href=../../../../share/polygon-to-ellipse/ title=随机多边形转化为椭圆的过程研究 class=md-nav__link> 随机多边形转化为椭圆的过程研究 </a> </li> <li class=md-nav__item> <a href=../../../../share/FFT-GPU-Accel/ title=FFT-GPU-Accel class=md-nav__link> FFT-GPU-Accel </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7 type=checkbox id=nav-4-7> <label class=md-nav__link for=nav-4-7> NKU 数院试题整理 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="NKU 数院试题整理" data-md-level=2> <label class=md-nav__title for=nav-4-7> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> NKU 数院试题整理 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/nku-sms-exams/ title=汇总 class=md-nav__link> 汇总 </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7-2 type=checkbox id=nav-4-7-2> <label class=md-nav__link for=nav-4-7-2> 分析 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=分析 data-md-level=3> <label class=md-nav__title for=nav-4-7-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> 分析 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/exam/functional-analysis-final/ title=2017-2018第一学期泛函分析期末考试 class=md-nav__link> 2017-2018第一学期泛函分析期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/real-variable-function/ title=2016-2017第二学期实变函数期末考试 class=md-nav__link> 2016-2017第二学期实变函数期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/mathematical-analysis-3-3-final/ title=2016-2017第一学期数学分析3-3期末考试 class=md-nav__link> 2016-2017第一学期数学分析3-3期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/complex-analysis-final/ title=2016-2017第一学期复变函数期末考试 class=md-nav__link> 2016-2017第一学期复变函数期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/mathematical-analysis-3-3-middle/ title=2016-2017第一学期数学分析3-3期中考试 class=md-nav__link> 2016-2017第一学期数学分析3-3期中考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/mathematical-analysis-3-2-final/ title=2015-2016第二学期数学分析3-2期末考试（含解答） class=md-nav__link> 2015-2016第二学期数学分析3-2期末考试（含解答） </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/mathematical-analysis-3-2-middle/ title=2015-2016第二学期数学分析3-2期中考试 class=md-nav__link> 2015-2016第二学期数学分析3-2期中考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/mathematical-analysis-3-1-final/ title=2015-2016第一学期数学分析3-1期末考试 class=md-nav__link> 2015-2016第一学期数学分析3-1期末考试 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7-3 type=checkbox id=nav-4-7-3> <label class=md-nav__link for=nav-4-7-3> 代数 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=代数 data-md-level=3> <label class=md-nav__title for=nav-4-7-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> 代数 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/exam/abstract-algebra-final/ title=2016-2017第一学期抽象代数期末考试 class=md-nav__link> 2016-2017第一学期抽象代数期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/abstract-algebra-middle/ title=2016-2017第一学期抽象代数期中考试 class=md-nav__link> 2016-2017第一学期抽象代数期中考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/advanced-algebra-2-2-final/ title=2015-2016第二学期高等代数2-2期末考试 class=md-nav__link> 2015-2016第二学期高等代数2-2期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/advanced-algebra-2-2-middle/ title=2015-2016第二学期高等代数2-2期中考试 class=md-nav__link> 2015-2016第二学期高等代数2-2期中考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/advanced-algebra-2-1-final/ title=2015-2016第一学期高等代数2-1期末考试 class=md-nav__link> 2015-2016第一学期高等代数2-1期末考试 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7-4 type=checkbox id=nav-4-7-4> <label class=md-nav__link for=nav-4-7-4> 概率统计 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=概率统计 data-md-level=3> <label class=md-nav__title for=nav-4-7-4> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> 概率统计 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/exam/probability-final/ title=2016-2017第二学期概率论期末考试 class=md-nav__link> 2016-2017第二学期概率论期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/probability-middle/ title=2016-2017第二学期概率论期中考试 class=md-nav__link> 2016-2017第二学期概率论期中考试 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7-5 type=checkbox id=nav-4-7-5> <label class=md-nav__link for=nav-4-7-5> 微分方程 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=微分方程 data-md-level=3> <label class=md-nav__title for=nav-4-7-5> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> 微分方程 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/exam/PDE-final/ title=2017-2018第一学期数理方程期末考试 class=md-nav__link> 2017-2018第一学期数理方程期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/ODE-final/ title=2016-2017第一学期常微分方程期末考试 class=md-nav__link> 2016-2017第一学期常微分方程期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/ODE-middle/ title=2016-2017第一学期常微分方程期中考试 class=md-nav__link> 2016-2017第一学期常微分方程期中考试 </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-8 type=checkbox id=nav-4-8> <label class=md-nav__link for=nav-4-8> Other <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Other data-md-level=2> <label class=md-nav__title for=nav-4-8> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Other </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/github-student-pack/ title="Student Developer Pack - GitHub Education" class=md-nav__link> Student Developer Pack - GitHub Education </a> </li> <li class=md-nav__item> <a href=../../../../share/my-postgraduate-share/ title="保研推免经验分享 - 数学系跨保 CS" class=md-nav__link> 保研推免经验分享 - 数学系跨保 CS </a> </li> <li class=md-nav__item> <a href=../../../../share/roc-fly/ title=鹏程万里 class=md-nav__link> 鹏程万里 </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5 type=checkbox id=nav-5> <label class=md-nav__link for=nav-5> Statements <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Statements data-md-level=1> <label class=md-nav__title for=nav-5> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Statements </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../statements/ title=Statements class=md-nav__link> Statements </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#61-td-prediction class=md-nav__link> 6.1 TD Prediction </a> </li> <li class=md-nav__item> <a href=#62-advantages-of-td-prediction-methods class=md-nav__link> 6.2 Advantages of TD Prediction Methods </a> <nav class=md-nav aria-label="6.2 Advantages of TD Prediction Methods"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_1 class=md-nav__link> 优点 </a> </li> <li class=md-nav__item> <a href=#_2 class=md-nav__link> 收敛性 </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> 效率对比 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#63-optimality-of-td0 class=md-nav__link> 6.3 Optimality of TD(0) </a> <nav class=md-nav aria-label="6.3 Optimality of TD(0)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#batch-update class=md-nav__link> 批量更新（Batch Update） </a> </li> <li class=md-nav__item> <a href=#certainty-equivalence-estimate class=md-nav__link> Certainty-Equivalence Estimate </a> <nav class=md-nav aria-label="Certainty-Equivalence Estimate"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_4 class=md-nav__link> 例子 </a> </li> <li class=md-nav__item> <a href=#td0-methods class=md-nav__link> TD(0) methods </a> </li> <li class=md-nav__item> <a href=#mc-methods class=md-nav__link> MC methods </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> 确定性等价估计 </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#64-65-66-td-control class=md-nav__link> 6.4 &amp; 6.5 &amp; 6.6 TD Control </a> <nav class=md-nav aria-label="6.4 & 6.5 & 6.6 TD Control"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sarsa class=md-nav__link> Sarsa 算法 </a> </li> <li class=md-nav__item> <a href=#q-learning class=md-nav__link> Q-learning 算法 </a> </li> <li class=md-nav__item> <a href=#expected-sarsa class=md-nav__link> Expected Sarsa 算法 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#67-maximization-bias-and-double-learning class=md-nav__link> 6.7 Maximization Bias and Double Learning </a> <nav class=md-nav aria-label="6.7 Maximization Bias and Double Learning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#double-learning class=md-nav__link> Double Learning </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#68-games-afterstates-and-other-special-cases class=md-nav__link> 6.8 Games, Afterstates, and Other Special Cases </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a href=https://github.com/zawnpn/ZHANGWP/edit/master/docs/notes/reinforcement-learning/notes/RLAI_6.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=->强化学习导论（六）- 时序差分学习<a class=headerlink href=#- title="Permanent link">&para;</a></h1> <p>本章在上一章的基础上，进一步介绍了新的方法：<strong>时序差分学习</strong>（Temporal-Difference learning），简称 TD Learning。</p> <p>时序差分学习可以看作蒙特卡罗（MC）和动态规划（DP）的一种结合：</p> <ul> <li>和 MC 的相似之处在于，TD 方法从实际的经验来获取信息，无需获知环境的全部信息。</li> <li>和 DP 的相似之处在于，TD 方法能够利用上之前已知的信息来做实时学习，无需等得到完整的收益反馈再进行估值更新。</li> </ul> <p>本章同样基于 <strong>GPI 模型</strong>，来介绍基于时序差分学习（TD learning）的算法。</p> <h2 id=61-td-prediction>6.1 TD Prediction<a class=headerlink href=#61-td-prediction title="Permanent link">&para;</a></h2> <p>我们先对比看看上一章的 MC 算法（固定<span><span class=MathJax_Preview>\alpha</span><script type=math/tex>\alpha</script></span>）和本章的 TD 算法的核心公式：</p> <p><strong>constant-<span><span class=MathJax_Preview>\alpha</span><script type=math/tex>\alpha</script></span> MC:</strong></p> <div> <div class=MathJax_Preview> V(S_t)\leftarrow V(S_t)+\alpha\left[G_t-V(S_t)\right] </div> <script type="math/tex; mode=display">
V(S_t)\leftarrow V(S_t)+\alpha\left[G_t-V(S_t)\right]
</script> </div> <p><strong>TD(0) (one-step TD):</strong></p> <div> <div class=MathJax_Preview> V(S_t)\leftarrow V(S_t)+\alpha\left[R_{t+1}+\gamma V(S_{t+1})-V(S_t)\right] </div> <script type="math/tex; mode=display">
V(S_t)\leftarrow V(S_t)+\alpha\left[R_{t+1}+\gamma V(S_{t+1})-V(S_t)\right]
</script> </div> <ul> <li>MC 方法必须等待整个 episode 结束后得到 <span><span class=MathJax_Preview>G_t</span><script type=math/tex>G_t</script></span> 才能做一次更新。</li> <li>TD 方法则只需等到这一步结束，利用实时观测到的奖励值 <span><span class=MathJax_Preview>R_{t+1}</span><script type=math/tex>R_{t+1}</script></span> 和现有估计值 <span><span class=MathJax_Preview>V(S_{t+1})</span><script type=math/tex>V(S_{t+1})</script></span> 来进行更新。</li> </ul> <p><em>这里的 TD(0) 方法指</em><em>单步 TD 方法</em><em>，括号里的 0 改为其他数字后又指其他算法，将会在后面章节介绍。</em></p> <p>我们在第二章讲过，这样的更新式可以更广义地写作</p> <div> <div class=MathJax_Preview> NewEstimate\leftarrow OldEstimate+StepSize\left[Target-OldEstimate\right] </div> <script type="math/tex; mode=display">
NewEstimate\leftarrow OldEstimate+StepSize\left[Target-OldEstimate\right]
</script> </div> <p>将括号中的式子看作是一种误差，便可将这样的更新式看作是不断地在消除误差。我们将 TD 方法中的这个误差定义为 <strong>TD error:</strong></p> <div> <div class=MathJax_Preview> \delta_t\doteq R_{t+1}+\gamma V(S_{t+1})-V(S_t) </div> <script type="math/tex; mode=display">
\delta_t\doteq R_{t+1}+\gamma V(S_{t+1})-V(S_t)
</script> </div> <h2 id=62-advantages-of-td-prediction-methods>6.2 Advantages of TD Prediction Methods<a class=headerlink href=#62-advantages-of-td-prediction-methods title="Permanent link">&para;</a></h2> <h3 id=_1>优点<a class=headerlink href=#_1 title="Permanent link">&para;</a></h3> <ul> <li>无须获知环境的具体模型。</li> <li>通过一种在线的、完全实时的方式来进行增量更新。</li> <li>如果 episodes 太长，或者是连续型任务，MC 方法将会有很严重的延迟问题，TD 方法能够解决这种问题。</li> </ul> <h3 id=_2>收敛性<a class=headerlink href=#_2 title="Permanent link">&para;</a></h3> <p>给定策略 <span><span class=MathJax_Preview>\pi</span><script type=math/tex>\pi</script></span> ，满足一定条件的情况下，能够证明 TD(0) 方法能确保 <span><span class=MathJax_Preview>v</span><script type=math/tex>v</script></span> 收敛到 <span><span class=MathJax_Preview>v_\pi</span><script type=math/tex>v_\pi</script></span>：</p> <div> <div class=MathJax_Preview> \sum_{k=1}^{\infty}\alpha=\infty\qquad \mathrm{and}\qquad\sum_{k=1}^{\infty}\alpha^2&lt;\infty </div> <script type="math/tex; mode=display">
\sum_{k=1}^{\infty}\alpha=\infty\qquad \mathrm{and}\qquad\sum_{k=1}^{\infty}\alpha^2<\infty
</script> </div> <p>这个结果是来自随机逼近方面的理论，我们在第二章也提到过。需要注意的是，这只是其收敛的一个必要条件，一些情况下即使不满足，也一样能收敛。</p> <h3 id=_3>效率对比<a class=headerlink href=#_3 title="Permanent link">&para;</a></h3> <ul> <li>目前还没能从数学上证明哪个方法（TD &amp; MC）收敛得更快。</li> <li>实际情况下，对于随机性的任务，TD 方法通常收敛得比 constant-<span><span class=MathJax_Preview>\alpha</span><script type=math/tex>\alpha</script></span> MC 方法要快一些。</li> </ul> <p><strong>一个例子</strong>:</p> <p><img alt src=../imgs/RLAI_6/rand-walk.png></p> <p>问题的背景就是从中间结点 C 出发，若能达到右边的终止态，返回奖励值 1，其余情况均返回奖励值 0。我们用 <span><span class=MathJax_Preview>P_i</span><script type=math/tex>P_i</script></span> 来表示当我们处于状态 i 下，最终能到达右终止态的概率，易知</p> <div> <div class=MathJax_Preview> \begin{cases} P_a=\dfrac{1}{2}P_b+\dfrac{1}{2}\times 0\\ P_b=\dfrac{1}{2}P_a+\dfrac{1}{2}P_c\\ P_c=\dfrac{1}{2}P_b+\dfrac{1}{2}P_d\\ P_d=\dfrac{1}{2}P_c+\dfrac{1}{2}P_e\\ P_e=\dfrac{1}{2}P_d+\dfrac{1}{2}\times 1\\ \end{cases} </div> <script type="math/tex; mode=display">
\begin{cases}
P_a=\dfrac{1}{2}P_b+\dfrac{1}{2}\times 0\\
P_b=\dfrac{1}{2}P_a+\dfrac{1}{2}P_c\\
P_c=\dfrac{1}{2}P_b+\dfrac{1}{2}P_d\\
P_d=\dfrac{1}{2}P_c+\dfrac{1}{2}P_e\\
P_e=\dfrac{1}{2}P_d+\dfrac{1}{2}\times 1\\
\end{cases}
</script> </div> <p>解上述方程，可得</p> <div> <div class=MathJax_Preview> P_a=\frac{1}{6},P_b=\frac{2}{6},P_c=\frac{3}{6},P_d=\frac{4}{6},P_e=\frac{5}{6} </div> <script type="math/tex; mode=display">
P_a=\frac{1}{6},P_b=\frac{2}{6},P_c=\frac{3}{6},P_d=\frac{4}{6},P_e=\frac{5}{6}
</script> </div> <p>由于到达右终止态的 reward 是 1，那么乘上这个奖励值，最终的期望值其实就等于这些概率</p> <div> <div class=MathJax_Preview> V(A)=\frac{1}{6},V(B)=\frac{2}{6},V(C)=\frac{3}{6},V(D)=\frac{4}{6},V(E)=\frac{5}{6} </div> <script type="math/tex; mode=display">
V(A)=\frac{1}{6},V(B)=\frac{2}{6},V(C)=\frac{3}{6},V(D)=\frac{4}{6},V(E)=\frac{5}{6}
</script> </div> <p>那么，在这个问题背景下，我们的算法表现如何呢？</p> <p><img alt src=../imgs/RLAI_6/rand-walk-result.png></p> <ul> <li>左图描绘了 TD(0) 算法下经过 n 个 episodes 后得到的估计值，可以看出，100 次训练后，估计值已经非常接近真实值了。</li> <li>右图对比了两种算法在不同 <span><span class=MathJax_Preview>\alpha</span><script type=math/tex>\alpha</script></span> 取值下的误差收敛曲线。可以看出，至少在该例中，TD 方法确实要优于 MC 方法。</li> </ul> <h2 id=63-optimality-of-td0>6.3 Optimality of TD(0)<a class=headerlink href=#63-optimality-of-td0 title="Permanent link">&para;</a></h2> <h3 id=batch-update>批量更新（Batch Update）<a class=headerlink href=#batch-update title="Permanent link">&para;</a></h3> <div> <div class=MathJax_Preview> V(S_t)\leftarrow V(S_t)+\alpha\left[G_t-V(S_t)\right]\\ V(S_t)\leftarrow V(S_t)+\alpha\left[R_{t+1}+\gamma V(S_{t+1})-V(S_t)\right] </div> <script type="math/tex; mode=display">
V(S_t)\leftarrow V(S_t)+\alpha\left[G_t-V(S_t)\right]\\
V(S_t)\leftarrow V(S_t)+\alpha\left[R_{t+1}+\gamma V(S_{t+1})-V(S_t)\right]
</script> </div> <p>对于上面这样的更新式，我们有时也可通过<strong>批量更新（Batch Update）</strong>来进行更新操作：</p> <ul> <li>每一步 t 我们仍按照原来的步骤做计算，求出增量（也就误差值）。</li> <li>先不执行更新，而是将增量（误差值）累积起来。</li> <li>当一整批训练数据都按上述步骤处理完后，再统一将增量更新到目标值上。</li> </ul> <h3 id=certainty-equivalence-estimate>Certainty-Equivalence Estimate<a class=headerlink href=#certainty-equivalence-estimate title="Permanent link">&para;</a></h3> <h4 id=_4>例子<a class=headerlink href=#_4 title="Permanent link">&para;</a></h4> <p>给定 8 个 episodes 作为一个 batch：</p> <div> <div class=MathJax_Preview> \begin{aligned} (A,0,B,0)\qquad&amp;(B,1)&amp;(B,1)\qquad&amp;(B,1)\\ (B,1)\qquad&amp;(B,1)&amp;(B,1)\qquad&amp;(B,0) \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned}
(A,0,B,0)\qquad&(B,1)&(B,1)\qquad&(B,1)\\
(B,1)\qquad&(B,1)&(B,1)\qquad&(B,0)
\end{aligned}
</script> </div> <p>很显然，可以看出 <span><span class=MathJax_Preview>V(B)=\frac{3}{4}</span><script type=math/tex>V(B)=\frac{3}{4}</script></span> ，而 <span><span class=MathJax_Preview>V(A)</span><script type=math/tex>V(A)</script></span> 则有两种答案，在 TD 方法下 <span><span class=MathJax_Preview>V(A)=\frac{3}{4}</span><script type=math/tex>V(A)=\frac{3}{4}</script></span> ，而对于 MC ，<span><span class=MathJax_Preview>V(A)=0</span><script type=math/tex>V(A)=0</script></span> 。为什么会发生这样的情况呢？我们先来按照两种方法模拟计算一下：</p> <h4 id=td0-methods>TD(0) methods<a class=headerlink href=#td0-methods title="Permanent link">&para;</a></h4> <div> <div class=MathJax_Preview> V_0(A)=V_0(B)=V(T)=0\\ \alpha_a=1,\alpha_b=\frac{1}{8},\gamma=1\\ \begin{aligned} (1)&amp;{\begin{cases} \delta_1(A)=R_0+V_0(B)-V_0(A)=0+0-0=0\\ \delta_1(B)=\sum_{i}\left[R_{0i}+V(T)-V_0(B)\right]=6+0-0=6\\ V_1(A)=V_0(A)+1\times\delta_1(A)=0\\ V_1(B)=V_0(B)+\frac{1}{8}\delta_1(B)=\frac{3}{4} \end{cases}}\\ (2)&amp;{\begin{cases} \delta_2(A)=R_1+V_1(B)-V_1(A)=0+\frac{3}{4}-0=\frac{3}{4}\\ \delta_2(B)=\sum_{i}\left[R_{1i}+V(T)-V_1(B)\right]=6+0-\frac{8\times3}{4}=0\\ V_2(A)=V_1(A)+1\times\delta_2(A)=\frac{3}{4}\\ V_2(B)=V_1(B)+\frac{1}{8}\delta_2(B)=\frac{3}{4} \end{cases}}\\ \vdots\\ (n)&amp;{\begin{cases} \delta_n(A)=0,\delta_n(B)=0\\ V_n(A)=\frac{3}{4},V_n(B)=\frac{3}{4} \end{cases}} \end{aligned} </div> <script type="math/tex; mode=display">
V_0(A)=V_0(B)=V(T)=0\\
\alpha_a=1,\alpha_b=\frac{1}{8},\gamma=1\\
\begin{aligned}
(1)&{\begin{cases}
\delta_1(A)=R_0+V_0(B)-V_0(A)=0+0-0=0\\
\delta_1(B)=\sum_{i}\left[R_{0i}+V(T)-V_0(B)\right]=6+0-0=6\\
V_1(A)=V_0(A)+1\times\delta_1(A)=0\\
V_1(B)=V_0(B)+\frac{1}{8}\delta_1(B)=\frac{3}{4}
\end{cases}}\\
(2)&{\begin{cases}
\delta_2(A)=R_1+V_1(B)-V_1(A)=0+\frac{3}{4}-0=\frac{3}{4}\\
\delta_2(B)=\sum_{i}\left[R_{1i}+V(T)-V_1(B)\right]=6+0-\frac{8\times3}{4}=0\\
V_2(A)=V_1(A)+1\times\delta_2(A)=\frac{3}{4}\\
V_2(B)=V_1(B)+\frac{1}{8}\delta_2(B)=\frac{3}{4}
\end{cases}}\\
\vdots\\
(n)&{\begin{cases}
\delta_n(A)=0,\delta_n(B)=0\\
V_n(A)=\frac{3}{4},V_n(B)=\frac{3}{4}
\end{cases}}
\end{aligned}
</script> </div> <p><img alt src=../imgs/RLAI_6/batch-update-td0.png></p> <h4 id=mc-methods>MC methods<a class=headerlink href=#mc-methods title="Permanent link">&para;</a></h4> <div> <div class=MathJax_Preview> V_0(A)=V_0(B)=V(T)=0\\ \alpha_a=\alpha_b=\frac{1}{8},\gamma=1\\ \begin{aligned} (1)&amp;{\begin{cases} \delta_1(A)=G_1(A)-V_0(A)=0-0=0\\ \delta_1(B)=\sum_{i}\left[G_{0i}-V_0(B)\right]=6-0=6\\ V_1(A)=V_0(A)+\frac{1}{8}\delta_1(A)=0\\ V_1(B)=V_0(B)+\frac{1}{8}\delta_1(B)=\frac{3}{4} \end{cases}}\\ (2)&amp;{\begin{cases} \delta_2(A)=G_1(A)-V_1(A)=0-0=0\\ \delta_2(B)=\sum_{i}\left[G_{2i}-V_1(B)\right]=6-6=0\\ V_1(A)=V_0(A)+\frac{1}{8}\delta_1(A)=0\\ V_1(B)=V_0(B)+\frac{1}{8}\delta_1(B)=\frac{3}{4} \end{cases}}\\ \vdots\\ (n)&amp;{\begin{cases} \delta_n(A)=0,\delta_n(B)=0\\ V_n(A)=0,V_n(B)=\frac{3}{4} \end{cases}} \end{aligned} </div> <script type="math/tex; mode=display">
V_0(A)=V_0(B)=V(T)=0\\
\alpha_a=\alpha_b=\frac{1}{8},\gamma=1\\
\begin{aligned}
(1)&{\begin{cases}
\delta_1(A)=G_1(A)-V_0(A)=0-0=0\\
\delta_1(B)=\sum_{i}\left[G_{0i}-V_0(B)\right]=6-0=6\\
V_1(A)=V_0(A)+\frac{1}{8}\delta_1(A)=0\\
V_1(B)=V_0(B)+\frac{1}{8}\delta_1(B)=\frac{3}{4}
\end{cases}}\\
(2)&{\begin{cases}
\delta_2(A)=G_1(A)-V_1(A)=0-0=0\\
\delta_2(B)=\sum_{i}\left[G_{2i}-V_1(B)\right]=6-6=0\\
V_1(A)=V_0(A)+\frac{1}{8}\delta_1(A)=0\\
V_1(B)=V_0(B)+\frac{1}{8}\delta_1(B)=\frac{3}{4}
\end{cases}}\\
\vdots\\
(n)&{\begin{cases}
\delta_n(A)=0,\delta_n(B)=0\\
V_n(A)=0,V_n(B)=\frac{3}{4}
\end{cases}}
\end{aligned}
</script> </div> <h4 id=_5>确定性等价估计<a class=headerlink href=#_5 title="Permanent link">&para;</a></h4> <ul> <li>MC 方法本质上是对<strong>训练集</strong>给出了<strong>最小均方误差估计</strong>，在我们这个例子中，A 出现了的 episode 只有一个，而恰好其最终返回值 <span><span class=MathJax_Preview>G(A)=0</span><script type=math/tex>G(A)=0</script></span> ，MC 方法基于这段经验就认为 <span><span class=MathJax_Preview>V(A)=0</span><script type=math/tex>V(A)=0</script></span> ，这就显得有点「过拟合」了——过于追求训练集上的最小误差，而没有充分考虑综合因素。</li> <li>TD(0) 方法则是给出了<strong>极大似然估计</strong>：<span><span class=MathJax_Preview>\hat{\theta}=\mathop{\arg\max}\limits_\theta p(\theta|\mathbf{x})</span><script type=math/tex>\hat{\theta}=\mathop{\arg\max}\limits_\theta p(\theta|\mathbf{x})</script></span> 。此处的极大似然估计不是某个具体的参数，而是基于观测数据形成的马尔可夫过程<strong>模型</strong>。极大似然估计其实就是<strong>给定数据的最大生成概率的对应估计</strong>，也就是说，前面的这个模型包含了对状态转移概率、奖励值等信息的正确估计，一旦给定正确的信息，它就能作出合理的估计。我们称这样的估计为<strong>确定性等价估计（Certainty-Equivalence Estimate）</strong>。</li> </ul> <p>而 TD 方法之所以通常比 MC 收敛得更快，正是因为它是确定性等价估计，更加稳健高效。</p> <h2 id=64-65-66-td-control>6.4 &amp; 6.5 &amp; 6.6 TD Control<a class=headerlink href=#64-65-66-td-control title="Permanent link">&para;</a></h2> <p>这三节均是基于 GPI 介绍具体的 TD 算法，由于三种算法本质相近，故将三节合在一起说。</p> <p>前面提到，我们要按照下面的形式来更新目标值</p> <div> <div class=MathJax_Preview> Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha\left[R_{t+1}+\gamma\hat{Q}(S_{t+1},A_{t+1})-Q(S_t,A_t)\right] </div> <script type="math/tex; mode=display">
Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha\left[R_{t+1}+\gamma\hat{Q}(S_{t+1},A_{t+1})-Q(S_t,A_t)\right]
</script> </div> <p>注意到更新式中我们把 <span><span class=MathJax_Preview>Q</span><script type=math/tex>Q</script></span> 写作 <span><span class=MathJax_Preview>\hat{Q}</span><script type=math/tex>\hat{Q}</script></span> ，统一表示对 <span><span class=MathJax_Preview>Q</span><script type=math/tex>Q</script></span> 的估计，可以是原有的估计方式 <span><span class=MathJax_Preview>Q(S_{t+1},A_{t+1})</span><script type=math/tex>Q(S_{t+1},A_{t+1})</script></span> ，也可以是其他的估计，在这三节里，不同的估计方法就分别对应了不同的算法，那为什么要这样做呢？</p> <p>我们前面介绍的 TD 算法是在拿旧的 <span><span class=MathJax_Preview>Q_{old}</span><script type=math/tex>Q_{old}</script></span> 计算误差：</p> <div> <div class=MathJax_Preview> R_{t+1}+\gamma Q_{old}(S_{t+1},A_{t+1})-Q_{old}(S_t,A_t) </div> <script type="math/tex; mode=display">
R_{t+1}+\gamma Q_{old}(S_{t+1},A_{t+1})-Q_{old}(S_t,A_t)
</script> </div> <p>但我们本应用 <span><span class=MathJax_Preview>Q_{new}</span><script type=math/tex>Q_{new}</script></span> 来计算：</p> <div> <div class=MathJax_Preview> R_{t+1}+\gamma Q_{new}(S_{t+1},A_{t+1})-Q_{old}(S_t,A_t) </div> <script type="math/tex; mode=display">
R_{t+1}+\gamma Q_{new}(S_{t+1},A_{t+1})-Q_{old}(S_t,A_t)
</script> </div> <p>这种直接采用旧的估计值来更新 target 的方法，稍加分析能够发现其实就是统计学里的<strong>自助抽样法（bootstrap)</strong>——有放回地重新抽样。回到前面的问题，为什么要这样做？在我们重新抽样后，有人认为应按原有方式继续那样计算，也有人认为那样计算不能很好地代表 <span><span class=MathJax_Preview>Q_{new}</span><script type=math/tex>Q_{new}</script></span> ，所以，在不同的见解下，对这个估计值 <span><span class=MathJax_Preview>\hat{Q}</span><script type=math/tex>\hat{Q}</script></span> 做不同的调整，形成了不同的算法。</p> <h3 id=sarsa>Sarsa 算法<a class=headerlink href=#sarsa title="Permanent link">&para;</a></h3> <p>若 <span><span class=MathJax_Preview>\hat{Q}(S_{t+1},A_{t+1})=Q(S_{t+1},A_{t+1})</span><script type=math/tex>\hat{Q}(S_{t+1},A_{t+1})=Q(S_{t+1},A_{t+1})</script></span> ，这时的 TD 算法称为 Sarsa ，其更新式为</p> <div> <div class=MathJax_Preview> Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha\left[R_{t+1}+\gamma Q(S_{t+1},A_{t+1})-Q(S_t,A_t)\right] </div> <script type="math/tex; mode=display">
Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha\left[R_{t+1}+\gamma Q(S_{t+1},A_{t+1})-Q(S_t,A_t)\right]
</script> </div> <ul> <li>由于算法的每次更新需要用到数据组合 <span><span class=MathJax_Preview>(S_t,A_t,R_{t+1},S_{t+1},A_{t+1})</span><script type=math/tex>(S_t,A_t,R_{t+1},S_{t+1},A_{t+1})</script></span> ，故取其字母组成其名字 SARSA ，称为 Sarsa 算法。</li> <li>显然，Sarsa 是 On-policy 的算法，且和 MC 相似，需要确保各状态都被访问足够多次数才能收敛，因此一般都用于 <span><span class=MathJax_Preview>\varepsilon</span><script type=math/tex>\varepsilon</script></span>-greedy 或 <span><span class=MathJax_Preview>\varepsilon</span><script type=math/tex>\varepsilon</script></span>-soft 策略。</li> </ul> <p><img alt src=../imgs/RLAI_6/sarsa.png></p> <h3 id=q-learning>Q-learning 算法<a class=headerlink href=#q-learning title="Permanent link">&para;</a></h3> <p>若 <span><span class=MathJax_Preview>\hat{Q}(S_{t+1},A_{t+1})=\max\limits_aQ(S_{t+1},a)</span><script type=math/tex>\hat{Q}(S_{t+1},A_{t+1})=\max\limits_aQ(S_{t+1},a)</script></span> ，这时的 TD 算法称为 Q-learning ，其更新式为</p> <div> <div class=MathJax_Preview> Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha\left[R_{t+1}+\gamma \max\limits_aQ(S_{t+1},a)-Q(S_t,A_t)\right] </div> <script type="math/tex; mode=display">
Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha\left[R_{t+1}+\gamma  \max\limits_aQ(S_{t+1},a)-Q(S_t,A_t)\right]
</script> </div> <p>易分析知，我们是从所有的 <span><span class=MathJax_Preview>Q(S_{t+1},a)</span><script type=math/tex>Q(S_{t+1},a)</script></span> 中直接<strong>选取</strong>了最大值来更新（而不是像前面的 Sarsa 一样还需往前实际走一步 <span><span class=MathJax_Preview>A_{t+1}</span><script type=math/tex>A_{t+1}</script></span>）就能完成更新， 更新之后，我们可以任意采取其他策略来做 exploration actions ，所以 Q-learning 是 Off-policy 方法。</p> <p><img alt src=../imgs/RLAI_6/q-learning.png></p> <h3 id=expected-sarsa>Expected Sarsa 算法<a class=headerlink href=#expected-sarsa title="Permanent link">&para;</a></h3> <p>若 <span><span class=MathJax_Preview>\hat{Q}(S_{t+1},A_{t+1})=\mathbb{E}_\pi\left[Q(S_{t+1},A_{t+1})\mid S_{t+1}\right]</span><script type=math/tex>\hat{Q}(S_{t+1},A_{t+1})=\mathbb{E}_\pi\left[Q(S_{t+1},A_{t+1})\mid S_{t+1}\right]</script></span> ，这时的 TD 算法称为 Expected Sarsa ，其更新式为</p> <div> <div class=MathJax_Preview> \begin{aligned} Q(S_t,A_t)&amp;\leftarrow Q(S_t,A_t)+\alpha\left[R_{t+1}+\gamma \mathbb{E}_\pi\left[Q(S_{t+1},A_{t+1})\mid S_{t+1}\right]-Q(S_t,A_t)\right]\\ &amp;\leftarrow Q(S_t,A_t)+\alpha\left[R_{t+1}+\gamma\sum_a\pi(a|S_{t+1})Q(S_{t+1},a) -Q(S_t,A_t)\right] \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned}
Q(S_t,A_t)&\leftarrow Q(S_t,A_t)+\alpha\left[R_{t+1}+\gamma  \mathbb{E}_\pi\left[Q(S_{t+1},A_{t+1})\mid S_{t+1}\right]-Q(S_t,A_t)\right]\\
&\leftarrow Q(S_t,A_t)+\alpha\left[R_{t+1}+\gamma\sum_a\pi(a|S_{t+1})Q(S_{t+1},a)  -Q(S_t,A_t)\right]
\end{aligned}
</script> </div> <p>Expected Sarsa 可以看作是对 Sarsa 的一种改进，它只会略微增加计算上的消耗，但能降低方差，更加稳定。</p> <p>下面是一个具体的实验范例：</p> <p><img alt src=../imgs/RLAI_6/performance-compare.png></p> <ul> <li><strong>Asymptotic performance</strong>: 图中的 Asymptotic performance 指 100,000 个 episodes 之后的实验结果均值。</li> <li><strong>Interim performance</strong>: 图中的 Interim performance 指 100 个 episodes 之后的实验结果均值。</li> </ul> <p>从图中可以看出，即使 <span><span class=MathJax_Preview>\alpha=1</span><script type=math/tex>\alpha=1</script></span> ，Expected Sarsa 也一样能够收敛（此时其形式很接近 DP ），而 Sarsa 则只能在 <span><span class=MathJax_Preview>\alpha</span><script type=math/tex>\alpha</script></span> 较小时才有好的表现。</p> <p>Expected Sarsa 可以是 On-policy ，也可以是 Off-policy 。</p> <h2 id=67-maximization-bias-and-double-learning>6.7 Maximization Bias and Double Learning<a class=headerlink href=#67-maximization-bias-and-double-learning title="Permanent link">&para;</a></h2> <p>前面提到的许多算法都含有<strong>最大化</strong>的操作，通过这些最大化操作来逐步构建出最优策略，比如 Q-learning 中有 <span><span class=MathJax_Preview>\max\limits_a Q(S_{t+1},a)</span><script type=math/tex>\max\limits_a Q(S_{t+1},a)</script></span> 、Sarsa 中也常有 <span><span class=MathJax_Preview>\varepsilon</span><script type=math/tex>\varepsilon</script></span>-greedy 策略，同样包含最大化操作。这些最大化操作常常会造成显著的正偏差。</p> <p>我们考虑一个例子：</p> <ul> <li>只有一个状态 s 。</li> <li>许多行动 a 的真实值 <span><span class=MathJax_Preview>q(s,a)</span><script type=math/tex>q(s,a)</script></span> 为 0 ，而估计值 <span><span class=MathJax_Preview>Q(s,a)</span><script type=math/tex>Q(s,a)</script></span> 在 0 附近波动，可正可负。</li> <li>最大化操作下的估计值，很大概率会是正值，因此产生了正偏差。</li> </ul> <p>我们称上面这类的正偏差为 <strong>maximization bias</strong> 。</p> <p>显然我们是需要消除这样的偏差值，下面引入 Double Learning 来解决这一问题。</p> <h3 id=double-learning>Double Learning<a class=headerlink href=#double-learning title="Permanent link">&para;</a></h3> <p>首先看个例子</p> <p><img alt src=../imgs/RLAI_6/max-bias.png></p> <ul> <li>如上图右上角的示意图所示，每个 episode 均从状态 A 出发，能够选择的行动只有<strong>向左</strong>或者<strong>向右</strong>，对应的奖励值均为 0 。</li> <li>由于 <span><span class=MathJax_Preview>R(B)\sim\mathcal N(-0.1,1)</span><script type=math/tex>R(B)\sim\mathcal N(-0.1,1)</script></span> ，易分析知，最后会有 <span><span class=MathJax_Preview>V(left)=-0.1, V(right)=0</span><script type=math/tex>V(left)=-0.1, V(right)=0</script></span> ，所以理论上只应该选择向右而不是向左。</li> </ul> <p>然而，在刚开始信息量不足时，向左的行动本应预期反馈 -0.1 左右的值，结果由于算法中的「最大化操作」，反而可能反馈了正的奖励值，导致此时模型更倾向于选择向左行动，如上图红线所示。从这个例子可以看出，正偏差带来的影响非常大，即使是很多次训练后，仍然有较大的误差偏离。因此，需要采用 Double Learning 来消除这一问题。</p> <p><strong>Double Learning</strong>:</p> <ul> <li>将样本分划为两个集合，并分别学习出独立的估计，简记作 <span><span class=MathJax_Preview>Q_1(a), Q_2(a)</span><script type=math/tex>Q_1(a), Q_2(a)</script></span> ，两者均是对真实值 <span><span class=MathJax_Preview>q(a)</span><script type=math/tex>q(a)</script></span> 的估计。</li> <li>用其中一个估计值来决定最优行动 <span><span class=MathJax_Preview>A^*=\mathop{\arg\max}\limits_aQ_1(a)</span><script type=math/tex>A^*=\mathop{\arg\max}\limits_aQ_1(a)</script></span> 。</li> <li>通过另一个估计值来计算最优行动对应的值函数 <span><span class=MathJax_Preview>Q_2(A^*)=Q_2(\mathop{\arg\max}\limits_aQ_1(a))</span><script type=math/tex>Q_2(A^*)=Q_2(\mathop{\arg\max}\limits_aQ_1(a))</script></span> 。<span><span class=MathJax_Preview>Q_2(A^*)</span><script type=math/tex>Q_2(A^*)</script></span> 是无偏估计，这是因为 <span><span class=MathJax_Preview>\mathbb{E}[Q_2(A^*)]=q(A^*)</span><script type=math/tex>\mathbb{E}[Q_2(A^*)]=q(A^*)</script></span> 。</li> <li>还可以重复一遍上述过程，并替换两个集合，得到另一个无偏估计 <span><span class=MathJax_Preview>Q_1(\mathop{\arg\max}\limits_aQ_2(a))</span><script type=math/tex>Q_1(\mathop{\arg\max}\limits_aQ_2(a))</script></span> 。</li> </ul> <p>这便是 <strong>double learning</strong> 的思想，能够消除 maxmization bias 造成的影响。理解起来很容易，第一次选出的 <span><span class=MathJax_Preview>A^*</span><script type=math/tex>A^*</script></span> 可能代入 <span><span class=MathJax_Preview>Q_1</span><script type=math/tex>Q_1</script></span> 后得到 <span><span class=MathJax_Preview>Q_1(A^*)=Q_1(\mathop{\arg\max}\limits_aQ_1(a))=\max\limits_aQ_1(a)</span><script type=math/tex>Q_1(A^*)=Q_1(\mathop{\arg\max}\limits_aQ_1(a))=\max\limits_aQ_1(a)</script></span> 为正值，但若代入另一个独立的估计函数 <span><span class=MathJax_Preview>Q_2</span><script type=math/tex>Q_2</script></span> 后，则显然其结果值不会再像前者那样能必然取到最大值。</p> <p><img alt src=../imgs/RLAI_6/double-q-learning.png></p> <p>容易分析知，Double learning 只会加倍内存需求，而不会给计算上带来额外的消耗。</p> <h2 id=68-games-afterstates-and-other-special-cases>6.8 Games, Afterstates, and Other Special Cases<a class=headerlink href=#68-games-afterstates-and-other-special-cases title="Permanent link">&para;</a></h2> <p>一些特殊情况下，我们可以在执行完行动后再去更新，比如下图这样的棋局，同一个局面可以由不同的情况达到，有着相同的期望收益。</p> <p><img alt src=../imgs/RLAI_6/tic.png></p> <p>我们称这种行动之后统一的状态为 <strong>Afterstates</strong> 。Afterstates 在一些特殊情况（比如上图这类游戏）很有用处，能够简化问题，大幅提升学习效率。</p> <hr> <div class=md-source-date> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">August 1, 2019</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid" aria-label=Footer> <a href=../RLAI_5/ title="Chapter 5" class="md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> Chapter 5 </div> </div> </a> <a href=../RLAI_7/ title="Chapter 7" class="md-footer-nav__link md-footer-nav__link--next" rel=next> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> Chapter 7 </div> </div> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2016-2020 ZHANGWP </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/zawnpn target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/zawnpn target=_blank rel=noopener title=twitter.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://psnprofiles.com/zawnpn target=_blank rel=noopener title=psnprofiles.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><path d="M570.9 372.3c-11.3 14.2-38.8 24.3-38.8 24.3L327 470.2v-54.3l150.9-53.8c17.1-6.1 19.8-14.8 5.8-19.4-13.9-4.6-39.1-3.3-56.2 2.9L327 381.1v-56.4c23.2-7.8 47.1-13.6 75.7-16.8 40.9-4.5 90.9.6 130.2 15.5 44.2 14 49.2 34.7 38 48.9zm-224.4-92.5v-139c0-16.3-3-31.3-18.3-35.6-11.7-3.8-19 7.1-19 23.4v347.9l-93.8-29.8V32c39.9 7.4 98 24.9 129.2 35.4C424.1 94.7 451 128.7 451 205.2c0 74.5-46 102.8-104.5 74.6zM43.2 410.2c-45.4-12.8-53-39.5-32.3-54.8 19.1-14.2 51.7-24.9 51.7-24.9l134.5-47.8v54.5l-96.8 34.6c-17.1 6.1-19.7 14.8-5.8 19.4 13.9 4.6 39.1 3.3 56.2-2.9l46.4-16.9v48.8c-51.6 9.3-101.4 7.3-153.9-10z"/></svg> </a> <a href=https://steamcommunity.com/id/zawnpn/ target=_blank rel=noopener title=steamcommunity.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M496 256c0 137-111.2 248-248.4 248-113.8 0-209.6-76.3-239-180.4l95.2 39.3c6.4 32.1 34.9 56.4 68.9 56.4 39.2 0 71.9-32.4 70.2-73.5l84.5-60.2c52.1 1.3 95.8-40.9 95.8-93.5 0-51.6-42-93.5-93.7-93.5s-93.7 42-93.7 93.5v1.2L176.6 279c-15.5-.9-30.7 3.4-43.5 12.1L0 236.1C10.2 108.4 117.1 8 247.6 8 384.8 8 496 119 496 256zM155.7 384.3l-30.5-12.6a52.79 52.79 0 0027.2 25.8c26.9 11.2 57.8-1.6 69-28.4 5.4-13 5.5-27.3.1-40.3-5.4-13-15.5-23.2-28.5-28.6-12.9-5.4-26.7-5.2-38.9-.6l31.5 13c19.8 8.2 29.2 30.9 20.9 50.7-8.3 19.9-31 29.2-50.8 21zm173.8-129.9c-34.4 0-62.4-28-62.4-62.3s28-62.3 62.4-62.3 62.4 28 62.4 62.3-27.9 62.3-62.4 62.3zm.1-15.6c25.9 0 46.9-21 46.9-46.8 0-25.9-21-46.8-46.9-46.8s-46.9 21-46.9 46.8c.1 25.8 21.1 46.8 46.9 46.8z"/></svg> </a> <a href=https://www.zhihu.com/people/zhangwanpeng target=_blank rel=noopener title=www.zhihu.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13H170.54zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82v170.31zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62v.01zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2l19.23 14.43zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78l.03-.01z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../../../../assets/javascripts/vendor.d710d30a.min.js></script> <script src=../../../../assets/javascripts/bundle.b39636ac.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script> <script>
        app = initialize({
          base: "../../../..",
          features: ["tabs"],
          search: Object.assign({
            worker: "../../../../assets/javascripts/worker/search.a68abb33.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> <script src="//cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-MML-AM_SVG"></script> </body> </html>