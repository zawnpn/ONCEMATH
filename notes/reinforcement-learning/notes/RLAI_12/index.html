<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Welcome to zhangwp's blog."><link href=https://www.zhangwp.com/notes/reinforcement-learning/notes/RLAI_12/ rel=canonical><meta name=author content=zawnpn><link rel="shortcut icon" href=../../../../assets/images/favicon.svg><meta name=generator content="mkdocs-1.1.2, mkdocs-material-5.4.0"><title>Chapter 12 - ZHANGWP</title><link rel=stylesheet href=../../../../assets/stylesheets/main.fe0cca5b.min.css><link rel=stylesheet href=../../../../assets/stylesheets/palette.a46bcfb3.min.css><meta name=theme-color content=#546e7a></head> <body dir=ltr data-md-color-scheme data-md-color-primary=blue-grey data-md-color-accent> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#- class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https://www.zhangwp.com title=ZHANGWP class="md-header-nav__button md-logo" aria-label=ZHANGWP> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><path d="M257.981 272.971L63.638 467.314c-9.373 9.373-24.569 9.373-33.941 0L7.029 444.647c-9.357-9.357-9.375-24.522-.04-33.901L161.011 256 6.99 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L257.981 239.03c9.373 9.372 9.373 24.568 0 33.941zM640 456v-32c0-13.255-10.745-24-24-24H312c-13.255 0-24 10.745-24 24v32c0 13.255 10.745 24 24 24h304c13.255 0 24-10.745 24-24z"/></svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> ZHANGWP </span> <span class="md-header-nav__topic md-ellipsis"> Chapter 12 </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a href=https://github.com/zawnpn/ZHANGWP/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class="md-tabs md-tabs--active" aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../ class="md-tabs__link md-tabs__link--active"> Notes </a> </li> <li class=md-tabs__item> <a href=../../../../tips/ class=md-tabs__link> Tips </a> </li> <li class=md-tabs__item> <a href=../../../../share/ class=md-tabs__link> Share </a> </li> <li class=md-tabs__item> <a href=../../../../statements/ class=md-tabs__link> Statements </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https://www.zhangwp.com title=ZHANGWP class="md-nav__button md-logo" aria-label=ZHANGWP> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><path d="M257.981 272.971L63.638 467.314c-9.373 9.373-24.569 9.373-33.941 0L7.029 444.647c-9.357-9.357-9.375-24.522-.04-33.901L161.011 256 6.99 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L257.981 239.03c9.373 9.372 9.373 24.568 0 33.941zM640 456v-32c0-13.255-10.745-24-24-24H312c-13.255 0-24 10.745-24 24v32c0 13.255 10.745 24 24 24h304c13.255 0 24-10.745 24-24z"/></svg> </a> ZHANGWP </label> <div class=md-nav__source> <a href=https://github.com/zawnpn/ZHANGWP/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1 type=checkbox id=nav-1> <label class=md-nav__link for=nav-1> Home <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Home data-md-level=1> <label class=md-nav__title for=nav-1> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../.. title=Home class=md-nav__link> Home </a> </li> <li class=md-nav__item> <a href=../../../../links/ title=Links class=md-nav__link> Links </a> </li> <li class=md-nav__item> <a href=../../../../donates/ title=Donate class=md-nav__link> Donate </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2 checked> <label class=md-nav__link for=nav-2> Notes <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Notes data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Notes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../ title=Index class=md-nav__link> Index </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-2 type=checkbox id=nav-2-2 checked> <label class=md-nav__link for=nav-2-2> Reinforcement <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Reinforcement data-md-level=2> <label class=md-nav__title for=nav-2-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Reinforcement </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-2-1 type=checkbox id=nav-2-2-1 checked> <label class=md-nav__link for=nav-2-2-1> Reinforcement Learning An Introduction <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Reinforcement Learning An Introduction" data-md-level=3> <label class=md-nav__title for=nav-2-2-1> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Reinforcement Learning An Introduction </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../RLAI_2/ title="Chapter 2" class=md-nav__link> Chapter 2 </a> </li> <li class=md-nav__item> <a href=../RLAI_3/ title="Chapter 3" class=md-nav__link> Chapter 3 </a> </li> <li class=md-nav__item> <a href=../RLAI_4/ title="Chapter 4" class=md-nav__link> Chapter 4 </a> </li> <li class=md-nav__item> <a href=../RLAI_5/ title="Chapter 5" class=md-nav__link> Chapter 5 </a> </li> <li class=md-nav__item> <a href=../RLAI_6/ title="Chapter 6" class=md-nav__link> Chapter 6 </a> </li> <li class=md-nav__item> <a href=../RLAI_7/ title="Chapter 7" class=md-nav__link> Chapter 7 </a> </li> <li class=md-nav__item> <a href=../RLAI_8/ title="Chapter 8" class=md-nav__link> Chapter 8 </a> </li> <li class=md-nav__item> <a href=../RLAI_9/ title="Chapter 9" class=md-nav__link> Chapter 9 </a> </li> <li class=md-nav__item> <a href=../RLAI_10/ title="Chapter 10" class=md-nav__link> Chapter 10 </a> </li> <li class=md-nav__item> <a href=../RLAI_11/ title="Chapter 11" class=md-nav__link> Chapter 11 </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Chapter 12 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg> </span> </label> <a href=./ title="Chapter 12" class="md-nav__link md-nav__link--active"> Chapter 12 </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#121-the-lambdalambda-return class=md-nav__link> 12.1 The \lambda\lambda-return </a> </li> <li class=md-nav__item> <a href=#122-tdlambdalambda class=md-nav__link> 12.2 TD(\lambda\lambda) </a> </li> <li class=md-nav__item> <a href=#123-n-step-truncated-lambdalambda-return-methods class=md-nav__link> 12.3 n-step Truncated \lambda\lambda-return Methods </a> </li> <li class=md-nav__item> <a href=#124-redoing-updates-the-online-lambdalambda-return-algorithm class=md-nav__link> 12.4 Redoing Updates: The Online \lambda\lambda-return Algorithm </a> </li> <li class=md-nav__item> <a href=#125-true-online-tdlambdalambda class=md-nav__link> 12.5 True Online TD(\lambda\lambda) </a> </li> <li class=md-nav__item> <a href=#126-dutch-traces-in-monte-carlo-learning class=md-nav__link> 12.6 Dutch Traces in Monte Carlo Learning </a> </li> <li class=md-nav__item> <a href=#127-sarsalambdalambda class=md-nav__link> 12.7 Sarsa(\lambda\lambda) </a> </li> <li class=md-nav__item> <a href=#128-variable-lambdalambda-and-gammagamma class=md-nav__link> 12.8 Variable \lambda\lambda and \gamma​\gamma​ </a> </li> <li class=md-nav__item> <a href=#129-off-policy-traces-with-control-variates class=md-nav__link> 12.9 Off-policy Traces with Control Variates </a> </li> <li class=md-nav__item> <a href=#1210-watkinss-qlambdalambda-to-tree-backuplambdalambda class=md-nav__link> 12.10 Watkins's Q(\lambda\lambda) to Tree-Backup(\lambda\lambda) </a> </li> <li class=md-nav__item> <a href=#1211-stable-off-policy-methods-with-traces class=md-nav__link> 12.11 Stable Off-policy Methods with Traces </a> <nav class=md-nav aria-label="12.11 Stable Off-policy Methods with Traces"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-gtdlambdalambda-tdc-eligibility-trace class=md-nav__link> (1) GTD(\lambda\lambda) ：TDC 算法的 eligibility trace 形式 </a> </li> <li class=md-nav__item> <a href=#2-gqlambdalambda-gradient-td-action-value-eligibility-trace class=md-nav__link> (2) GQ(\lambda\lambda) ：Gradient-TD 算法（action-value）的 eligibility trace 形式 </a> </li> <li class=md-nav__item> <a href=#3-htdlambdalambda-gtdlambdalambda-tdlambdalambda class=md-nav__link> (3) HTD(\lambda\lambda) ：由 GTD(\lambda\lambda) 和 TD(\lambda\lambda) 的结合算法 </a> </li> <li class=md-nav__item> <a href=#4-emphatic-tdlambdalambda-emphatic-td-eligibility-trace class=md-nav__link> (4) Emphatic TD(\lambda\lambda) ：Emphatic TD 的 eligibility trace 形式 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#1212-implementation-issues class=md-nav__link> 12.12 Implementation Issues </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../RLAI_13/ title="Chapter 13" class=md-nav__link> Chapter 13 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-2-2 type=checkbox id=nav-2-2-2> <label class=md-nav__link for=nav-2-2-2> Some Introduction <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="Some Introduction" data-md-level=3> <label class=md-nav__title for=nav-2-2-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Some Introduction </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../MCTS_introduction/ title=MCTS class=md-nav__link> MCTS </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Tips <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Tips data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Tips </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../tips/ title=Tips class=md-nav__link> Tips </a> </li> <li class=md-nav__item> <a href=../../../../tips/to-do/ title="To Do" class=md-nav__link> To Do </a> </li> <li class=md-nav__item> <a href=../../../../tips/python/ title=Python class=md-nav__link> Python </a> </li> <li class=md-nav__item> <a href=../../../../tips/data-processing/ title="Data Processing" class=md-nav__link> Data Processing </a> </li> <li class=md-nav__item> <a href=../../../../tips/git/ title=Git class=md-nav__link> Git </a> </li> <li class=md-nav__item> <a href=../../../../tips/linux/ title=Linux class=md-nav__link> Linux </a> </li> <li class=md-nav__item> <a href=../../../../tips/win/ title=Windows class=md-nav__link> Windows </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <label class=md-nav__link for=nav-4> Share <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Share data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Share </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/ title=Index class=md-nav__link> Index </a> </li> <li class=md-nav__item> <a href=../../../../share/blog-history/ title=博客历史 class=md-nav__link> 博客历史 </a> </li> <li class=md-nav__item> <a href=../../../../share/game-log/ title=Game-Log class=md-nav__link> Game-Log </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-4 type=checkbox id=nav-4-4> <label class=md-nav__link for=nav-4-4> NKU-Toolkit <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=NKU-Toolkit data-md-level=2> <label class=md-nav__title for=nav-4-4> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> NKU-Toolkit </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/nku-eamis/ title=NKU-EAMIS工具 class=md-nav__link> NKU-EAMIS工具 </a> </li> <li class=md-nav__item> <a href=../../../../share/nku-sms-rss/ title=NKU-SMS-RSS class=md-nav__link> NKU-SMS-RSS </a> </li> <li class=md-nav__item> <a href=../../../../share/eamis-miniapp/ title=NKU-EAMIS_MiniApp(南开大学教务助手小程序) class=md-nav__link> NKU-EAMIS_MiniApp(南开大学教务助手小程序) </a> </li> <li class=md-nav__item> <a href=../../../../share/eamis-workflow/ title="NKU-EAMIS for iOS(Workflow)" class=md-nav__link> NKU-EAMIS for iOS(Workflow) </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-5 type=checkbox id=nav-4-5> <label class=md-nav__link for=nav-4-5> Steam-Toolkit <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Steam-Toolkit data-md-level=2> <label class=md-nav__title for=nav-4-5> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Steam-Toolkit </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/steam-market-price-bot/ title=Steam市场比价爬虫 class=md-nav__link> Steam市场比价爬虫 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-6 type=checkbox id=nav-4-6> <label class=md-nav__link for=nav-4-6> 数学建模 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=数学建模 data-md-level=2> <label class=md-nav__title for=nav-4-6> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> 数学建模 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/2017-mcm-icm/ title="2017美赛参赛整理(Problem D)" class=md-nav__link> 2017美赛参赛整理(Problem D) </a> </li> <li class=md-nav__item> <a href=../../../../share/2016-guosai/ title=2016数学建模国赛 class=md-nav__link> 2016数学建模国赛 </a> </li> <li class=md-nav__item> <a href=../../../../share/math-model-szb/ title=数学建模之2016深圳杯——初次尝试 class=md-nav__link> 数学建模之2016深圳杯——初次尝试 </a> </li> <li class=md-nav__item> <a href=../../../../share/polygon-to-ellipse/ title=随机多边形转化为椭圆的过程研究 class=md-nav__link> 随机多边形转化为椭圆的过程研究 </a> </li> <li class=md-nav__item> <a href=../../../../share/FFT-GPU-Accel/ title=FFT-GPU-Accel class=md-nav__link> FFT-GPU-Accel </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7 type=checkbox id=nav-4-7> <label class=md-nav__link for=nav-4-7> NKU 数院试题整理 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label="NKU 数院试题整理" data-md-level=2> <label class=md-nav__title for=nav-4-7> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> NKU 数院试题整理 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/nku-sms-exams/ title=汇总 class=md-nav__link> 汇总 </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7-2 type=checkbox id=nav-4-7-2> <label class=md-nav__link for=nav-4-7-2> 分析 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=分析 data-md-level=3> <label class=md-nav__title for=nav-4-7-2> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> 分析 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/exam/functional-analysis-final/ title=2017-2018第一学期泛函分析期末考试 class=md-nav__link> 2017-2018第一学期泛函分析期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/real-variable-function/ title=2016-2017第二学期实变函数期末考试 class=md-nav__link> 2016-2017第二学期实变函数期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/mathematical-analysis-3-3-final/ title=2016-2017第一学期数学分析3-3期末考试 class=md-nav__link> 2016-2017第一学期数学分析3-3期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/complex-analysis-final/ title=2016-2017第一学期复变函数期末考试 class=md-nav__link> 2016-2017第一学期复变函数期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/mathematical-analysis-3-3-middle/ title=2016-2017第一学期数学分析3-3期中考试 class=md-nav__link> 2016-2017第一学期数学分析3-3期中考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/mathematical-analysis-3-2-final/ title=2015-2016第二学期数学分析3-2期末考试（含解答） class=md-nav__link> 2015-2016第二学期数学分析3-2期末考试（含解答） </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/mathematical-analysis-3-2-middle/ title=2015-2016第二学期数学分析3-2期中考试 class=md-nav__link> 2015-2016第二学期数学分析3-2期中考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/mathematical-analysis-3-1-final/ title=2015-2016第一学期数学分析3-1期末考试 class=md-nav__link> 2015-2016第一学期数学分析3-1期末考试 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7-3 type=checkbox id=nav-4-7-3> <label class=md-nav__link for=nav-4-7-3> 代数 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=代数 data-md-level=3> <label class=md-nav__title for=nav-4-7-3> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> 代数 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/exam/abstract-algebra-final/ title=2016-2017第一学期抽象代数期末考试 class=md-nav__link> 2016-2017第一学期抽象代数期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/abstract-algebra-middle/ title=2016-2017第一学期抽象代数期中考试 class=md-nav__link> 2016-2017第一学期抽象代数期中考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/advanced-algebra-2-2-final/ title=2015-2016第二学期高等代数2-2期末考试 class=md-nav__link> 2015-2016第二学期高等代数2-2期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/advanced-algebra-2-2-middle/ title=2015-2016第二学期高等代数2-2期中考试 class=md-nav__link> 2015-2016第二学期高等代数2-2期中考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/advanced-algebra-2-1-final/ title=2015-2016第一学期高等代数2-1期末考试 class=md-nav__link> 2015-2016第一学期高等代数2-1期末考试 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7-4 type=checkbox id=nav-4-7-4> <label class=md-nav__link for=nav-4-7-4> 概率统计 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=概率统计 data-md-level=3> <label class=md-nav__title for=nav-4-7-4> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> 概率统计 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/exam/probability-final/ title=2016-2017第二学期概率论期末考试 class=md-nav__link> 2016-2017第二学期概率论期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/probability-middle/ title=2016-2017第二学期概率论期中考试 class=md-nav__link> 2016-2017第二学期概率论期中考试 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7-5 type=checkbox id=nav-4-7-5> <label class=md-nav__link for=nav-4-7-5> 微分方程 <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=微分方程 data-md-level=3> <label class=md-nav__title for=nav-4-7-5> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> 微分方程 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/exam/PDE-final/ title=2017-2018第一学期数理方程期末考试 class=md-nav__link> 2017-2018第一学期数理方程期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/ODE-final/ title=2016-2017第一学期常微分方程期末考试 class=md-nav__link> 2016-2017第一学期常微分方程期末考试 </a> </li> <li class=md-nav__item> <a href=../../../../share/exam/ODE-middle/ title=2016-2017第一学期常微分方程期中考试 class=md-nav__link> 2016-2017第一学期常微分方程期中考试 </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-8 type=checkbox id=nav-4-8> <label class=md-nav__link for=nav-4-8> Other <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Other data-md-level=2> <label class=md-nav__title for=nav-4-8> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Other </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../share/github-student-pack/ title="Student Developer Pack - GitHub Education" class=md-nav__link> Student Developer Pack - GitHub Education </a> </li> <li class=md-nav__item> <a href=../../../../share/my-postgraduate-share/ title="保研推免经验分享 - 数学系跨保 CS" class=md-nav__link> 保研推免经验分享 - 数学系跨保 CS </a> </li> <li class=md-nav__item> <a href=../../../../share/roc-fly/ title=鹏程万里 class=md-nav__link> 鹏程万里 </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5 type=checkbox id=nav-5> <label class=md-nav__link for=nav-5> Statements <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg> </span> </label> <nav class=md-nav aria-label=Statements data-md-level=1> <label class=md-nav__title for=nav-5> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Statements </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../statements/ title=Statements class=md-nav__link> Statements </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#121-the-lambdalambda-return class=md-nav__link> 12.1 The \lambda\lambda-return </a> </li> <li class=md-nav__item> <a href=#122-tdlambdalambda class=md-nav__link> 12.2 TD(\lambda\lambda) </a> </li> <li class=md-nav__item> <a href=#123-n-step-truncated-lambdalambda-return-methods class=md-nav__link> 12.3 n-step Truncated \lambda\lambda-return Methods </a> </li> <li class=md-nav__item> <a href=#124-redoing-updates-the-online-lambdalambda-return-algorithm class=md-nav__link> 12.4 Redoing Updates: The Online \lambda\lambda-return Algorithm </a> </li> <li class=md-nav__item> <a href=#125-true-online-tdlambdalambda class=md-nav__link> 12.5 True Online TD(\lambda\lambda) </a> </li> <li class=md-nav__item> <a href=#126-dutch-traces-in-monte-carlo-learning class=md-nav__link> 12.6 Dutch Traces in Monte Carlo Learning </a> </li> <li class=md-nav__item> <a href=#127-sarsalambdalambda class=md-nav__link> 12.7 Sarsa(\lambda\lambda) </a> </li> <li class=md-nav__item> <a href=#128-variable-lambdalambda-and-gammagamma class=md-nav__link> 12.8 Variable \lambda\lambda and \gamma​\gamma​ </a> </li> <li class=md-nav__item> <a href=#129-off-policy-traces-with-control-variates class=md-nav__link> 12.9 Off-policy Traces with Control Variates </a> </li> <li class=md-nav__item> <a href=#1210-watkinss-qlambdalambda-to-tree-backuplambdalambda class=md-nav__link> 12.10 Watkins's Q(\lambda\lambda) to Tree-Backup(\lambda\lambda) </a> </li> <li class=md-nav__item> <a href=#1211-stable-off-policy-methods-with-traces class=md-nav__link> 12.11 Stable Off-policy Methods with Traces </a> <nav class=md-nav aria-label="12.11 Stable Off-policy Methods with Traces"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-gtdlambdalambda-tdc-eligibility-trace class=md-nav__link> (1) GTD(\lambda\lambda) ：TDC 算法的 eligibility trace 形式 </a> </li> <li class=md-nav__item> <a href=#2-gqlambdalambda-gradient-td-action-value-eligibility-trace class=md-nav__link> (2) GQ(\lambda\lambda) ：Gradient-TD 算法（action-value）的 eligibility trace 形式 </a> </li> <li class=md-nav__item> <a href=#3-htdlambdalambda-gtdlambdalambda-tdlambdalambda class=md-nav__link> (3) HTD(\lambda\lambda) ：由 GTD(\lambda\lambda) 和 TD(\lambda\lambda) 的结合算法 </a> </li> <li class=md-nav__item> <a href=#4-emphatic-tdlambdalambda-emphatic-td-eligibility-trace class=md-nav__link> (4) Emphatic TD(\lambda\lambda) ：Emphatic TD 的 eligibility trace 形式 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#1212-implementation-issues class=md-nav__link> 12.12 Implementation Issues </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a href=https://github.com/zawnpn/ZHANGWP/edit/master/docs/notes/reinforcement-learning/notes/RLAI_12.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=->强化学习导论（十二）- 资格迹<a class=headerlink href=#- title="Permanent link">&para;</a></h1> <p>Eligibility Traces 是强化学习的基本原理之一。几乎所有 TD 方法都可以和 eligibility traces 结合起来生成更高效通用的方法。</p> <p>在 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 方法中，<span><span class=MathJax_Preview>\lambda\in[0,1]</span><script type=math/tex>\lambda\in[0,1]</script></span>，两个极端的例子是 MC (<span><span class=MathJax_Preview>\lambda=1</span><script type=math/tex>\lambda=1</script></span>) 和 1-step TD (<span><span class=MathJax_Preview>\lambda=0</span><script type=math/tex>\lambda=0</script></span>)。</p> <p>与n-step方法相比：</p> <ul> <li>Eligibility Traces 方法只需存储一个trace vector，而不是 n 个最新的 feature vectors</li> <li>学习过程是连续且均匀的，不会有延迟</li> <li>不需要在 episode 结束时才进行所有运算</li> <li>学习可以立刻影响行为，不需要 n step 后才延迟生效</li> </ul> <p>前面讲过的很多方法根据后面的一些 rewards 来更新，这种形式称为 forward views ，通常 forward views 并不实用，因为 update 依赖于当前未知的量，这一章会介绍一种新方法，采用 eligibility trace 往前看最近经过的 states ，从而得到当前 TD error ，称之为 backward views 。</p> <h2 id=121-the-lambdalambda-return><strong>12.1 The <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return</strong><a class=headerlink href=#121-the-lambdalambda-return title="Permanent link">&para;</a></h2> <p>n-step return 的定义如下：</p> <div> <div class=MathJax_Preview> G _ { t : t + n } \doteq R _ { t + 1 } + \gamma R _ { t + 2 } + \cdots + \gamma ^ { n - 1 } R _ { t + n } + \gamma ^ { n } \hat { v } \left( S _ { t + n } , \mathbf { w } _ { t + n - 1 } \right) </div> <script type="math/tex; mode=display">
G _ { t : t + n } \doteq R _ { t + 1 } + \gamma R _ { t + 2 } + \cdots + \gamma ^ { n - 1 } R _ { t + n } + \gamma ^ { n } \hat { v } \left( S _ { t + n } , \mathbf { w } _ { t + n - 1 } \right)
</script> </div> <p>现在考虑多个 n-step return 的加权平均，只需权重和为 1，仍能用作 update target，如 <span><span class=MathJax_Preview>\frac { 1 } { 2 } G _ { t : t + 2 } + \frac { 1 } { 2 } G _ { t : t + 4 }</span><script type=math/tex>\frac { 1 } { 2 } G _ { t : t + 2 } + \frac { 1 } { 2 } G _ { t : t + 4 }</script></span> ，这种更新方式称为 compound update，其 backup 图如下</p> <p><img alt src=../imgs/RLAI_12/compound.png></p> <p>TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 也属于这种 averaging n-step update ，他包括了所有的 n-step updates，权重系数分别为 <span><span class=MathJax_Preview>\lambda^{n-1}, \lambda\in[0,1]</span><script type=math/tex>\lambda^{n-1}, \lambda\in[0,1]</script></span>，<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 定义如下（其中 <span><span class=MathJax_Preview>1-\lambda</span><script type=math/tex>1-\lambda</script></span> 确保能归一化）：</p> <div> <div class=MathJax_Preview> G _ { t } ^ { \lambda } \doteq ( 1 - \lambda ) \sum _ { n = 1 } ^ { \infty } \lambda ^ { n - 1 } G _ { t : t + n } </div> <script type="math/tex; mode=display">
G _ { t } ^ { \lambda } \doteq ( 1 - \lambda ) \sum _ { n = 1 } ^ { \infty } \lambda ^ { n - 1 } G _ { t : t + n }
</script> </div> <p>其 backup 图如下：</p> <p><img alt src=../imgs/RLAI_12/td-lamb.png></p> <p>将上式提取一部分出来，可写为</p> <div> <div class=MathJax_Preview> G _ { t } ^ { \lambda } = ( 1 - \lambda ) \sum _ { n = 1 } ^ { T - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { T - t - 1 } G _ { t } </div> <script type="math/tex; mode=display">
G _ { t } ^ { \lambda } = ( 1 - \lambda ) \sum _ { n = 1 } ^ { T - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { T - t - 1 } G _ { t }
</script> </div> <p>观察可知，当 <span><span class=MathJax_Preview>\lambda=1</span><script type=math/tex>\lambda=1</script></span> ，此方法为 MC；当 <span><span class=MathJax_Preview>\lambda=0</span><script type=math/tex>\lambda=0</script></span> ，此方法为 1-step TD。</p> <p>更一般地，将这个 <span><span class=MathJax_Preview>G_t^\lambda</span><script type=math/tex>G_t^\lambda</script></span> 作为 update target ，此算法称为『<strong>offline <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return algorithm</strong>』，采用半梯度法更新：</p> <div> <div class=MathJax_Preview> \mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G _ { t } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) </div> <script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G _ { t } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)
</script> </div> <p>下图通过一个实例比较了算法效果：</p> <p><img alt src=../imgs/RLAI_12/offline-lamb-compare.png></p> <p>目前我们讨论的方法都是『<strong>forward views</strong>』算法，在每个 state 处都能得到一些未来的信息，如下面示意图所示。</p> <p><img alt src=../imgs/RLAI_12/forward.png></p> <h2 id=122-tdlambdalambda><strong>12.2 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>)</strong><a class=headerlink href=#122-tdlambdalambda title="Permanent link">&para;</a></h2> <p>本节介绍的 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 对上一节的 offline <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 有三点提升：</p> <ul> <li>单步更新权重向量，无需等待 episode 结束</li> <li>计算在时间上均匀分布</li> <li>不仅可用于 episode 问题，还适用于连续问题</li> </ul> <p>本节引入 eligibility trace <span><span class=MathJax_Preview>\mathbf{z}_t\in \mathbb{R}^d</span><script type=math/tex>\mathbf{z}_t\in \mathbb{R}^d</script></span> ，他与权向量 <span><span class=MathJax_Preview>\mathbf{w}_t</span><script type=math/tex>\mathbf{w}_t</script></span> 维度相同，权向量有长期的记忆性，其存在时间与系统等长，而 eligibility trace 则体现短期记忆，存在于 episode 内的一个子片段中。</p> <p>eligibility trace 定义如下：</p> <div> <div class=MathJax_Preview> \begin{array} { l } { \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } } \\ { \mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) , \quad 0 \leq t \leq T } \end{array} </div> <script type="math/tex; mode=display">
\begin{array} { l } { \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } } \\ { \mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) , \quad 0 \leq t \leq T } \end{array}
</script> </div> <p>eligibility trace 一直在追踪那些对『<strong>recent state valuation</strong>』有贡献的权重分量，这个 recent 体现在系数 <span><span class=MathJax_Preview>\gamma\lambda</span><script type=math/tex>\gamma\lambda</script></span> 上。</p> <p>在 1-step TD 中，TD error 为</p> <div> <div class=MathJax_Preview> \delta _ { t } \doteq R _ { t + 1 } + \gamma \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) </div> <script type="math/tex; mode=display">
\delta _ { t } \doteq R _ { t + 1 } + \gamma \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)
</script> </div> <p>更新式为</p> <div> <div class=MathJax_Preview> \mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t }\color{blue}{\nabla\hat{v}(S_t,\mathbf{w}_t)} </div> <script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t }\color{blue}{\nabla\hat{v}(S_t,\mathbf{w}_t)}
</script> </div> <p>将梯度增加一些信息</p> <div> <div class=MathJax_Preview> \mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t }[\color{blue}{\nabla\hat{v}(S_t,\mathbf{w}_t)+\gamma\lambda\mathbf{z}_{t-1}}] </div> <script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t }[\color{blue}{\nabla\hat{v}(S_t,\mathbf{w}_t)+\gamma\lambda\mathbf{z}_{t-1}}]
</script> </div> <p>即可得到 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 的更新式</p> <div> <div class=MathJax_Preview> \mathbf { w } _ { t + 1 } \stackrel { \cdot } { = } \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t } </div> <script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \stackrel { \cdot } { = } \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t }
</script> </div> <p>算法伪代码如下</p> <p><img alt src=../imgs/RLAI_12/td-lamb-code.png></p> <p>TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 是 backward 的，即，每个时刻得到新的 TD error 后，又依据它对之前 states 的 eligibility trace 作一些调整，如下面示意图所示。</p> <p><img alt src=../imgs/RLAI_12/backward.png></p> <p>算法的实际测试效果如下图所示</p> <p><img alt src=../imgs/RLAI_12/td-offline-lamb.png></p> <p>当 <span><span class=MathJax_Preview>\lambda=0</span><script type=math/tex>\lambda=0</script></span> 时，trace 恰好就是 value function 的梯度，此时正好对应 1-step TD ；当 <span><span class=MathJax_Preview>\lambda=1</span><script type=math/tex>\lambda=1</script></span> 时，可以看出每一个 state 都刚好衰减 <span><span class=MathJax_Preview>\gamma</span><script type=math/tex>\gamma</script></span> 倍，跑完这个 episode ，恰好就是 MC 。可以看出，使用了 eligibility trace 后仍能统一地表示各种算法。</p> <p>若满足条件</p> <div> <div class=MathJax_Preview> \sum _ { n = 1 } ^ { \infty } \alpha _ { n } = \infty \quad \text { and } \quad \sum _ { n = 1 } ^ { \infty } \alpha _ { n } ^ { 2 }&lt; \infty </div> <script type="math/tex; mode=display">
\sum _ { n = 1 } ^ { \infty } \alpha _ { n } = \infty \quad \text { and } \quad \sum _ { n = 1 } ^ { \infty } \alpha _ { n } ^ { 2 }< \infty
</script> </div> <p>线性 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 可以在 on-policy 下确保收敛，此时有上界</p> <div> <div class=MathJax_Preview> \overline { \mathrm { VE } } \left( \mathbf { w } _ { \infty } \right) \leq \frac { 1 - \gamma \lambda } { 1 - \gamma } \min _ { \mathbf { w } } \overline { \mathrm { VE } } ( \mathbf { w } ) </div> <script type="math/tex; mode=display">
\overline { \mathrm { VE } } \left( \mathbf { w } _ { \infty } \right) \leq \frac { 1 - \gamma \lambda } { 1 - \gamma } \min _ { \mathbf { w } } \overline { \mathrm { VE } } ( \mathbf { w } )
</script> </div> <h2 id=123-n-step-truncated-lambdalambda-return-methods><strong>12.3 n-step Truncated <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return Methods</strong><a class=headerlink href=#123-n-step-truncated-lambdalambda-return-methods title="Permanent link">&para;</a></h2> <p>前面讲过的 offline <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 是一个重要的概念，但并不实用，因为他需要跑完一整个 episode 才能结束，而在连续型任务中，n 可以无限大，<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 无法计算，因此需要考虑将序列截断，用估计值来替代抛弃掉的较远的 rewards 。</p> <p>定义 truncated <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 如下：</p> <div> <div class=MathJax_Preview> G _ { t :h } ^ { \lambda } \doteq ( 1 - \lambda ) \sum _ { n = 1 } ^ { h - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { h - t - 1 } G _ { t : h } </div> <script type="math/tex; mode=display">
G _ { t :h } ^ { \lambda } \doteq ( 1 - \lambda ) \sum _ { n = 1 } ^ { h - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { h - t - 1 } G _ { t : h }
</script> </div> <p>而之前定义的完整的 <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 为：</p> <div> <div class=MathJax_Preview> G _ { t } ^ { \lambda } = ( 1 - \lambda ) \sum _ { n = 1 } ^ { T - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { T - t - 1 } G _ { t } </div> <script type="math/tex; mode=display">
G _ { t } ^ { \lambda } = ( 1 - \lambda ) \sum _ { n = 1 } ^ { T - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { T - t - 1 } G _ { t }
</script> </div> <p>对比可知，truncated <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 提前结束了模拟（后面未模拟部分用估计值代替），在此算法中，update 只被延迟了 n 步。称该算法为 truncated TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) ，或 TTD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 。</p> <p>下面是算法的 backup 示意图：</p> <p><img alt src=../imgs/RLAI_12/ttd.png></p> <p>算法的更新式为</p> <div> <div class=MathJax_Preview> \mathbf { w } _ { t + n } \doteq \mathbf { w } _ { t + n - 1 } + \alpha \left[ G _ { t : t + n } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t + n - 1 } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t + n - 1 } \right) </div> <script type="math/tex; mode=display">
\mathbf { w } _ { t + n } \doteq \mathbf { w } _ { t + n - 1 } + \alpha \left[ G _ { t : t + n } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t + n - 1 } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t + n - 1 } \right)
</script> </div> <p>其中</p> <div> <div class=MathJax_Preview> \begin{aligned} &amp;G_ { t : t + k } ^ { \lambda } = \hat { v } \left( S _ { t } , \mathbf { w } _ { t - 1 } \right) + \sum _ { i = t } ^ { t + k - 1 } ( \gamma \lambda ) ^ { i - t } \delta _ { i } ^ { \prime }\\ &amp;\delta _ { t } ^ { \prime } \doteq R _ { t + 1 } + \gamma \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t - 1 } \right) \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned}
&G_ { t : t + k } ^ { \lambda } = \hat { v } \left( S _ { t } , \mathbf { w } _ { t - 1 } \right) + \sum _ { i = t } ^ { t + k - 1 } ( \gamma \lambda ) ^ { i - t } \delta _ { i } ^ { \prime }\\
&\delta _ { t } ^ { \prime } \doteq R _ { t + 1 } + \gamma \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t - 1 } \right)
\end{aligned}
</script> </div> <h2 id=124-redoing-updates-the-online-lambdalambda-return-algorithm><strong>12.4 Redoing Updates: The Online <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return Algorithm</strong><a class=headerlink href=#124-redoing-updates-the-online-lambdalambda-return-algorithm title="Permanent link">&para;</a></h2> <p>实用 truncated TD 涉及到对 n 的平衡，n 越大越接近 offline <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return ，越小则更新速度越快。此平衡是可以达到的，方法是每次获得新数据后，重新从头开始执行所有更新：</p> <div> <div class=MathJax_Preview> \begin{array} { c l }{h = 1 : }&amp;{ \mathbf { w } _ { 1 } ^ { 1 } \doteq \mathbf { w } _ { 0 } ^ { 1 } + \alpha \left[ G _ { 0 : 1 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 1 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 1 } \right)}\\\\{ h = 2 : } &amp; { \mathbf { w } _ { 1 } ^ { 2 } \doteq \mathbf { w } _ { 0 } ^ { 2 } + \alpha \left[ G _ { 0 : 2 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 2 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 2 } \right) } \\ { } &amp; { \mathbf { w } _ { 2 } ^ { 2 } \doteq \mathbf { w } _ { 1 } ^ { 2 } + \alpha \left[ G _ { 1 : 2 } ^ { \lambda } - \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 2 } \right) \right] \nabla \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 2 } \right) }\\\\{ h = 3 :} &amp;{ \mathbf { w } _ { 1 } ^ { 3 } \doteq \mathbf { w } _ { 0 } ^ { 3 } + \alpha \left[ G _ { 0 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 3 } \right) } \\ {}&amp;{ \mathbf { w } _ { 2 } ^ { 3 } \doteq \mathbf { w } _ { 1 } ^ { 3 } + \alpha \left[ G _ { 1 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 3 } \right) } \\{}&amp; { \mathbf { w } _ { 3 } ^ { 3 } \doteq \mathbf { w } _ { 2 } ^ { 3 } + \alpha \left[ G _ { 2 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 2 } , \mathbf { w } _ { 2 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 2 } , \mathbf { w } _ { 2 } ^ { 3 } \right) } \end{array} </div> <script type="math/tex; mode=display">
\begin{array} { c l }{h = 1 : }&{ \mathbf { w } _ { 1 } ^ { 1 } \doteq \mathbf { w } _ { 0 } ^ { 1 } + \alpha \left[ G _ { 0 : 1 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 1 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 1 } \right)}\\\\{ h = 2 : } & { \mathbf { w } _ { 1 } ^ { 2 } \doteq \mathbf { w } _ { 0 } ^ { 2 } + \alpha \left[ G _ { 0 : 2 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 2 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 2 } \right) } \\ { } & { \mathbf { w } _ { 2 } ^ { 2 } \doteq \mathbf { w } _ { 1 } ^ { 2 } + \alpha \left[ G _ { 1 : 2 } ^ { \lambda } - \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 2 } \right) \right] \nabla \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 2 } \right) }\\\\{ h = 3 :} &{ \mathbf { w } _ { 1 } ^ { 3 } \doteq \mathbf { w } _ { 0 } ^ { 3 } + \alpha \left[ G _ { 0 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 3 } \right) } \\ {}&{ \mathbf { w } _ { 2 } ^ { 3 } \doteq \mathbf { w } _ { 1 } ^ { 3 } + \alpha \left[ G _ { 1 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 3 } \right) } \\{}& { \mathbf { w } _ { 3 } ^ { 3 } \doteq \mathbf { w } _ { 2 } ^ { 3 } + \alpha \left[ G _ { 2 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 2 } , \mathbf { w } _ { 2 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 2 } , \mathbf { w } _ { 2 } ^ { 3 } \right) } \end{array}
</script> </div> <p>其中 <span><span class=MathJax_Preview>\mathbf{w}_0^h</span><script type=math/tex>\mathbf{w}_0^h</script></span> 都继承自上一个 episode（因此所有的 <span><span class=MathJax_Preview>\mathbf{w}_0^h</span><script type=math/tex>\mathbf{w}_0^h</script></span> 也都为同一值），<span><span class=MathJax_Preview>\mathbf{w}_h^h</span><script type=math/tex>\mathbf{w}_h^h</script></span> 则为每一步的更新结果。</p> <p>更一般的表示为：</p> <div> <div class=MathJax_Preview> \mathbf { w } _ { t + 1 } ^ { h } \doteq \mathbf { w } _ { t } ^ { h } + \alpha \left[ G _ { t : h } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } ^ { h } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } ^ { h } \right) </div> <script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } ^ { h } \doteq \mathbf { w } _ { t } ^ { h } + \alpha \left[ G _ { t : h } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } ^ { h } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } ^ { h } \right)
</script> </div> <p>此算法称为『<strong>online <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return algorithm</strong>』，是完全在线算法，每个时间点 t 均使用已有数据产生一个新权重向量 <span><span class=MathJax_Preview>\mathbf{w}_t</span><script type=math/tex>\mathbf{w}_t</script></span> 。</p> <p>他在每个时间点 h 都能充分利用上 h 时间之前的所有信息，可以看出现在这种算法对数据的利用率更高，更新效果更好，缺点则为每次均需从头计算，复杂度高。</p> <p>下面是实际的性能比较：</p> <p><img alt src=../imgs/RLAI_12/on-td-lamb.png></p> <h2 id=125-true-online-tdlambdalambda><strong>12.5 True Online TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>)</strong><a class=headerlink href=#125-true-online-tdlambdalambda title="Permanent link">&para;</a></h2> <p>online <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 效果很好，但计算复杂度太高，需要考虑利用 eligibility trace 将算法变换为 backward view 算法，这便是本节要讲的『<strong>true online TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>)</strong>』。</p> <p>之前的 online <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 方法产生的权重序列如下：</p> <div> <div class=MathJax_Preview> \begin{array}{cccccc} \mathbf{w}_0^0 &amp; &amp; &amp; &amp; &amp; \\ \mathbf{w}_0^1 &amp; \mathbf{w}_1^1 &amp; &amp; &amp; &amp; \\ \mathbf{w}_0^2 &amp; \mathbf{w}_1^2 &amp; \mathbf{w}_2^2 &amp; &amp; &amp; \\ \mathbf{w}_0^3 &amp; \mathbf{w}_1^3 &amp; \mathbf{w}_2^3 &amp; \mathbf{w}_3^3 &amp; &amp; \\ \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \\ \mathbf{w}_0^T &amp; \mathbf{w}_1^T &amp; \mathbf{w}_2^T &amp; \mathbf{w}_3^T &amp; \cdots &amp; \mathbf{w}_T^T \end{array} </div> <script type="math/tex; mode=display">
\begin{array}{cccccc}
    \mathbf{w}_0^0 &  &  &  &  &  \\
    \mathbf{w}_0^1 & \mathbf{w}_1^1 &  &  &  &  \\
    \mathbf{w}_0^2 & \mathbf{w}_1^2 & \mathbf{w}_2^2 &  &  &  \\
    \mathbf{w}_0^3 & \mathbf{w}_1^3 & \mathbf{w}_2^3 & \mathbf{w}_3^3 &  &  \\
    \vdots & \vdots & \vdots & \vdots & \ddots &  \\
    \mathbf{w}_0^T & \mathbf{w}_1^T & \mathbf{w}_2^T & \mathbf{w}_3^T & \cdots & \mathbf{w}_T^T
\end{array}
</script> </div> <p>事实上，我们需要的只是每行最后一个权重 <span><span class=MathJax_Preview>\mathbf{w}_t^t</span><script type=math/tex>\mathbf{w}_t^t</script></span> ，得到 <span><span class=MathJax_Preview>\mathbf{w}_t=\mathbf{w}_t^t</span><script type=math/tex>\mathbf{w}_t=\mathbf{w}_t^t</script></span> 。</p> <p>对于 linear case，true online TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 定义如下：</p> <div> <div class=MathJax_Preview> \begin{array}{l} \mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t } + \alpha \left( \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } - \mathbf { w } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \left( \mathbf { z } _ { t } - \mathbf { x } _ { t } \right)\\ \mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \left( 1 - \alpha \gamma \lambda \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t } \end{array} </div> <script type="math/tex; mode=display">
\begin{array}{l}
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t } + \alpha \left( \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } - \mathbf { w } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \left( \mathbf { z } _ { t } - \mathbf { x } _ { t } \right)\\
\mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \left( 1 - \alpha \gamma \lambda \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t }
\end{array}
</script> </div> <p>此算法可以产生和 online <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 算法一样的结果，空间要求和 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 相同，计算量稍微增加了 50%，但仍为 <span><span class=MathJax_Preview>O(d)</span><script type=math/tex>O(d)</script></span> 复杂度。</p> <p>这一节 true online TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 使用的 eligibility trace 称为『<strong>dutch trace</strong>』，之前的 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 中则称为『<strong>accumulating trace</strong>』。</p> <p><img alt src=../imgs/RLAI_12/true-td-lamb.png></p> <h2 id=126-dutch-traces-in-monte-carlo-learning><strong>12.6 Dutch Traces in Monte Carlo Learning</strong><a class=headerlink href=#126-dutch-traces-in-monte-carlo-learning title="Permanent link">&para;</a></h2> <p>尽管 eligibility trace 于 TD 方法结合紧密，但他们本质上并无联系，事实上，eligibility trace 起源于 MC learning ，下面用一个例子简单介绍一下。</p> <p>线性情况下，梯度 MC 法的更新式如下：</p> <div> <div class=MathJax_Preview> \mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } \right] \mathbf { x } _ { t } </div> <script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } \right] \mathbf { x } _ { t }
</script> </div> <p>为了简化问题，这里的 return <span><span class=MathJax_Preview>G</span><script type=math/tex>G</script></span> 只是 episode 结束后得到的单个 reward（因此没有下标），并且没有做 discounting 。想要做的优化就是，在 episode 每一步都进行一些计算，但仍只在 episode 结束后才进行更新，所以复杂度仍为 <span><span class=MathJax_Preview>O(d)</span><script type=math/tex>O(d)</script></span>。算法如下：</p> <div> <div class=MathJax_Preview> \begin{aligned} \mathbf { w } _ { T } &amp; = \mathbf { w } _ { T - 1 } + \alpha \left( G - \mathbf { w } _ { T - 1 } ^ { \top } \mathbf { x } _ { T - 1 } \right) \mathbf { x } _ { T - 1 } \\ &amp; = \mathbf { w } _ { T - 1 } + \alpha \mathbf { x } _ { T - 1 } \left( - \mathbf { x } _ { T - 1 } ^ { \top } \mathbf { w } _ { T - 1 } \right) + \alpha G \mathbf { x } _ { T - 1 } \\ &amp; = \left( \mathbf { I } - \alpha \mathbf { x } _ { T - 1 } \mathbf { x } _ { T - 1 } ^ { \top } \right) \mathbf { w } _ { T - 1 } + \alpha G \mathbf { x } _ { T - 1 } \\ &amp; = \mathbf { F } _ { T - 1 } \mathbf { w } _ { T - 1 } + \alpha G \mathbf { x } _ { T - 1 } \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned} \mathbf { w } _ { T } & = \mathbf { w } _ { T - 1 } + \alpha \left( G - \mathbf { w } _ { T - 1 } ^ { \top } \mathbf { x } _ { T - 1 } \right) \mathbf { x } _ { T - 1 } \\ & = \mathbf { w } _ { T - 1 } + \alpha \mathbf { x } _ { T - 1 } \left( - \mathbf { x } _ { T - 1 } ^ { \top } \mathbf { w } _ { T - 1 } \right) + \alpha G \mathbf { x } _ { T - 1 } \\ & = \left( \mathbf { I } - \alpha \mathbf { x } _ { T - 1 } \mathbf { x } _ { T - 1 } ^ { \top } \right) \mathbf { w } _ { T - 1 } + \alpha G \mathbf { x } _ { T - 1 } \\ & = \mathbf { F } _ { T - 1 } \mathbf { w } _ { T - 1 } + \alpha G \mathbf { x } _ { T - 1 } \end{aligned}
</script> </div> <p>这里引入 <span><span class=MathJax_Preview>\mathbf { F } _ { t } \doteq \mathbf { I } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top }</span><script type=math/tex>\mathbf { F } _ { t } \doteq \mathbf { I } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top }</script></span> 称为 遗忘矩阵（or 衰退矩阵），接上式，下面进行递归</p> <div> <div class=MathJax_Preview> \begin{array} { l } { = \mathbf { F } _ { T - 1 } \left( \mathbf { F } _ { T - 2 } \mathbf { w } _ { T - 2 } + \alpha G \mathbf { x } _ { T - 2 } \right) + \alpha G \mathbf { x } _ { T - 1 } } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { w } _ { T - 2 } + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \left( \mathbf { F } _ { T - 3 } \mathbf { w } _ { T - 3 } + \alpha G \mathbf { x } _ { T - 3 } \right) + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { F } _ { T - 3 } \mathbf { W } _ { T - 3 } + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { x } _ { T - 3 } + \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) } \\\vdots\\ = \underbrace { \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \cdots \mathbf { F } _ { 0 } \mathbf { w } _ { 0 } } _ { \mathbf { a } _ { T - 1 } } + \alpha G \underbrace {\sum _ { k = 0 } ^ { T - 1 } \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k }}_{\mathbf{z}_{T-1}}\\ = \mathbf { a } _ { T - 1 } + \alpha G \mathbf { z } _ { T - 1 } \end{array} </div> <script type="math/tex; mode=display">
\begin{array} { l } { = \mathbf { F } _ { T - 1 } \left( \mathbf { F } _ { T - 2 } \mathbf { w } _ { T - 2 } + \alpha G \mathbf { x } _ { T - 2 } \right) + \alpha G \mathbf { x } _ { T - 1 } } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { w } _ { T - 2 } + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \left( \mathbf { F } _ { T - 3 } \mathbf { w } _ { T - 3 } + \alpha G \mathbf { x } _ { T - 3 } \right) + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { F } _ { T - 3 } \mathbf { W } _ { T - 3 } + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { x } _ { T - 3 } + \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) }
\\\vdots\\
= \underbrace { \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \cdots \mathbf { F } _ { 0 } \mathbf { w } _ { 0 } } _ { \mathbf { a } _ { T - 1 } } + \alpha G \underbrace {\sum _ { k = 0 } ^ { T - 1 } \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k }}_{\mathbf{z}_{T-1}}\\
= \mathbf { a } _ { T - 1 } + \alpha G \mathbf { z } _ { T - 1 }
\end{array}
</script> </div> <p>其中 <span><span class=MathJax_Preview>\mathbf{a}_{T-1}, \mathbf{z}_{T-1}</span><script type=math/tex>\mathbf{a}_{T-1}, \mathbf{z}_{T-1}</script></span> 是 T-1 时刻的两个辅助记忆向量，即使不知道 G ，也能在每步先做一些这样的计算，用以存储一些信息。</p> <p>事实上，<span><span class=MathJax_Preview>\mathbf{z}_t</span><script type=math/tex>\mathbf{z}_t</script></span> 是一个 dutch-style eligibility trace，初始值为 <span><span class=MathJax_Preview>\mathbf{z}_0=\mathbf{x}_0</span><script type=math/tex>\mathbf{z}_0=\mathbf{x}_0</script></span> ，他的更新式为：</p> <div> <div class=MathJax_Preview> \begin{aligned} \mathbf { z } _ { t } &amp; \doteq \sum _ { k = 0 } ^ { t } \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } , \quad 1 \leq t &lt; T \\ &amp; = \sum _ { k = 0 } ^ { t - 1 } \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } + \mathbf { x } _ { t } \\ &amp; = \mathbf { F } _ { t } \sum _ { k = 0 } ^ { t - 1 } \mathbf { F } _ { t - 1 } \mathbf { F } _ { t - 2 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } + \mathbf { x } _ { t } \\ &amp;= \mathbf { F } _ { t } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t } \\ &amp; = \left( \mathbf { I } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \right) \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t } \\ &amp; = \mathbf { z } _ { t - 1 } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t } \\ &amp; = \mathbf { z } _ { t - 1 } - \alpha \left( \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t } + \mathbf { x } _ { t } \\ &amp; = \mathbf { z } _ { t - 1 } + \left( 1 - \alpha \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t } \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned} \mathbf { z } _ { t } & \doteq \sum _ { k = 0 } ^ { t } \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } , \quad 1 \leq t < T \\ & = \sum _ { k = 0 } ^ { t - 1 } \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } + \mathbf { x } _ { t } \\ & = \mathbf { F } _ { t } \sum _ { k = 0 } ^ { t - 1 } \mathbf { F } _ { t - 1 } \mathbf { F } _ { t - 2 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } + \mathbf { x } _ { t } \\
  &= \mathbf { F } _ { t } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t }  \\ & = \left( \mathbf { I } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \right) \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t }  \\ & = \mathbf { z } _ { t - 1 } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t }  \\ & = \mathbf { z } _ { t - 1 } - \alpha \left( \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t } + \mathbf { x } _ { t }  \\ & = \mathbf { z } _ { t - 1 } + \left( 1 - \alpha \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t }
\end{aligned}
</script> </div> <p>辅助向量 <span><span class=MathJax_Preview>\mathbf{a}_t</span><script type=math/tex>\mathbf{a}_t</script></span> 初始值为 <span><span class=MathJax_Preview>\mathbf{a}_0=\mathbf{w}_0</span><script type=math/tex>\mathbf{a}_0=\mathbf{w}_0</script></span> ，更新式为</p> <div> <div class=MathJax_Preview> \mathbf { a } _ { t } \doteq \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { 0 } \mathbf { w } _ { 0 } = \mathbf { F } _ { t } \mathbf { a } _ { t - 1 } = \mathbf { a } _ { t - 1 } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \mathbf { a } _ { t - 1 } </div> <script type="math/tex; mode=display">
\mathbf { a } _ { t } \doteq \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { 0 } \mathbf { w } _ { 0 } = \mathbf { F } _ { t } \mathbf { a } _ { t - 1 } = \mathbf { a } _ { t - 1 } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \mathbf { a } _ { t - 1 }
</script> </div> <p>在 t &lt; T 时，每步更新辅助向量 <span><span class=MathJax_Preview>\mathbf{a}_t,\mathbf{z}_t</span><script type=math/tex>\mathbf{a}_t,\mathbf{z}_t</script></span> ，当 T 时刻获得 G 后再最终计算出 <span><span class=MathJax_Preview>\mathbf{w}_T</span><script type=math/tex>\mathbf{w}_T</script></span>。得到的结果和 MC 相同，但计算更简单。</p> <p>本例说明了 eligibility trace 并不局限于 TD 方法，只要想做长期预测，都可以采用 eligibility trace 。</p> <h2 id=127-sarsalambdalambda><strong>12.7 Sarsa(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>)</strong><a class=headerlink href=#127-sarsalambdalambda title="Permanent link">&para;</a></h2> <p>这一节把 eligibility trace 从 state-value 扩展到 action-value，只需简单地将 <span><span class=MathJax_Preview>\hat{v}(s,\mathbf{w})</span><script type=math/tex>\hat{v}(s,\mathbf{w})</script></span> 变为 <span><span class=MathJax_Preview>\hat{q}(s,a,\mathbf{w})</span><script type=math/tex>\hat{q}(s,a,\mathbf{w})</script></span> 。</p> <p>action-value 形式的 n-step return 为：</p> <div> <div class=MathJax_Preview> G _ { t : t + n } \doteq R _ { t + 1 } + \cdots + \gamma ^ { n - 1 } R _ { t + n } + \gamma ^ { n } \hat { q } \left( S _ { t + n } , A _ { t + n } , \mathbf { w } _ { t + n - 1 } \right) </div> <script type="math/tex; mode=display">
G _ { t : t + n } \doteq R _ { t + 1 } + \cdots + \gamma ^ { n - 1 } R _ { t + n } + \gamma ^ { n } \hat { q } \left( S _ { t + n } , A _ { t + n } , \mathbf { w } _ { t + n - 1 } \right)
</script> </div> <p>利用这个 return ，可以根据前面公式构造 action-value 形式的 truncated <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return <span><span class=MathJax_Preview>G_t^\lambda</span><script type=math/tex>G_t^\lambda</script></span> ，进而得到 action-value 形式的 offline <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 算法：</p> <div> <div class=MathJax_Preview> \mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G _ { t } ^ { \lambda } - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) \right] \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) </div> <script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G _ { t } ^ { \lambda } - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) \right] \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
</script> </div> <p>算法示意图如下：</p> <p><img alt src=../imgs/RLAI_12/sarsa-lamb.png></p> <p>Sarsa(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 和 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 相似，更新式为</p> <div> <div class=MathJax_Preview> \begin{array}{l} \mathbf { w } _ { t + 1 } \stackrel { \cdot } { = } \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t }\\ \delta _ { t } \doteq R _ { t + 1 } + \gamma \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)\\ { \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } } \\ { \mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) } \end{array} </div> <script type="math/tex; mode=display">
\begin{array}{l}
\mathbf { w } _ { t + 1 } \stackrel { \cdot } { = } \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t }\\
\delta _ { t } \doteq R _ { t + 1 } + \gamma \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)\\
{ \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } } \\ { \mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) }
\end{array}
</script> </div> <p>算法伪码如下：</p> <p><img alt src=../imgs/RLAI_12/sarsa-lamb-code.png></p> <p>该算法与传统的 n-step sarsa 效果对比如下：</p> <p><img alt src=../imgs/RLAI_12/sarsa-lamb-vs-n-sarsa.png></p> <p>上面是 offline <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 算法，下面介绍 action-value 的 online <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 算法。</p> <p><img alt src=../imgs/RLAI_12/online-sarsa-lamb-code.png></p> <p>本节算法之间的比较：</p> <p><img alt src=../imgs/RLAI_12/true-ol-sarsa-lamb-vs-sarsa-lamb.png></p> <h2 id=128-variable-lambdalambda-and-gammagamma><strong>12.8 Variable <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span> and <span><span class=MathJax_Preview>\gamma​</span><script type=math/tex>\gamma​</script></span></strong><a class=headerlink href=#128-variable-lambdalambda-and-gammagamma title="Permanent link">&para;</a></h2> <p>为了更泛化地表示每一步中 bootstrapping 和 discounting 的程度，需要更通用的 <span><span class=MathJax_Preview>\lambda,\gamma</span><script type=math/tex>\lambda,\gamma</script></span> ，现定义函数 <span><span class=MathJax_Preview>\lambda : \mathcal{S} \times \mathcal { A } \rightarrow [ 0,1 ]</span><script type=math/tex>\lambda : \mathcal{S} \times \mathcal { A } \rightarrow [ 0,1 ]</script></span> 和 <span><span class=MathJax_Preview>\gamma : \mathcal{S} \rightarrow [ 0,1 ]</span><script type=math/tex>\gamma : \mathcal{S} \rightarrow [ 0,1 ]</script></span> ，从而得到 <span><span class=MathJax_Preview>\lambda _ { t } \doteq \lambda \left( S _ { t } , A _ { t } \right),\gamma _ { t } \doteq \gamma \left( S _ { t } \right)</span><script type=math/tex>\lambda _ { t } \doteq \lambda \left( S _ { t } , A _ { t } \right),\gamma _ { t } \doteq \gamma \left( S _ { t } \right)</script></span> 。</p> <p>函数 <span><span class=MathJax_Preview>\gamma</span><script type=math/tex>\gamma</script></span> 称为『<strong>termination function</strong>』，现在重新定义 return ：</p> <div> <div class=MathJax_Preview> \begin{aligned} G _ { t } &amp; \doteq R _ { t + 1 } + \gamma _ { t + 1 } G _ { t + 1 } \\ &amp; = R _ { t + 1 } + \gamma _ { t + 1 } R _ { t + 2 } + \gamma _ { t + 1 } \gamma _ { t + 2 } R _ { t + 3 } + \gamma _ { t + 1 } \gamma _ { t + 2 } \gamma _ { t + 3 } R _ { t + 4 } + \cdots \\ &amp; = \sum _ { k = t } ^ { \infty } \left( \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \right) R _ { k + 1 } \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned} G _ { t } & \doteq R _ { t + 1 } + \gamma _ { t + 1 } G _ { t + 1 } \\ & = R _ { t + 1 } + \gamma _ { t + 1 } R _ { t + 2 } + \gamma _ { t + 1 } \gamma _ { t + 2 } R _ { t + 3 } + \gamma _ { t + 1 } \gamma _ { t + 2 } \gamma _ { t + 3 } R _ { t + 4 } + \cdots \\ & = \sum _ { k = t } ^ { \infty } \left( \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \right) R _ { k + 1 } \end{aligned}
</script> </div> <p>为保证结果有限，需要 <span><span class=MathJax_Preview>\prod _ { k = t } ^ { \infty } \gamma _ { k } = 0</span><script type=math/tex>\prod _ { k = t } ^ { \infty } \gamma _ { k } = 0</script></span> 。</p> <p>这种形式的好处是，episodic 任务无需再指定开始状态和结束状态，只需使 <span><span class=MathJax_Preview>\gamma(s)=0</span><script type=math/tex>\gamma(s)=0</script></span> 即可，因此便能统一 episodic 和 discounted-continuing 。</p> <p>上面说了对 discounting 的泛化，下面再介绍对 bootstrapping 的泛化。</p> <p>若考虑对 state-value 做 bootstrap ，则泛化参数记为 <span><span class=MathJax_Preview>\lambda_s</span><script type=math/tex>\lambda_s</script></span> ，同理若对 action-value 做 bootstrap ，则泛化参数记为 <span><span class=MathJax_Preview>\lambda_a</span><script type=math/tex>\lambda_a</script></span>（<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span> 控制了 bootstrap 的程度，当为 1 时完全不做 bootstrap ，当为 0 时则完全是在 bootstrap ）。于是可以得到新的<strong>递归</strong>形式的 state-based <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return ：</p> <div> <div class=MathJax_Preview> G _ { t } ^ { \lambda s } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda s } \right) </div> <script type="math/tex; mode=display">
G _ { t } ^ { \lambda s } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda s } \right)
</script> </div> <p>或是 action-based <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return ：</p> <div> <div class=MathJax_Preview> G _ { t } ^ { \lambda a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda a } \right) </div> <script type="math/tex; mode=display">
G _ { t } ^ { \lambda a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda a } \right)
</script> </div> <p>或者 Expected Sarsa 形式：</p> <div> <div class=MathJax_Preview> \begin{aligned} &amp;G _ { t } ^ { \lambda a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda a } \right)\\ &amp;\overline { V } _ { t } ( s ) \doteq \sum _ { a } \pi ( a | s ) \hat { q } \left( s , a , \mathbf { w } _ { t } \right) \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned}
&G _ { t } ^ { \lambda a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda a } \right)\\
&\overline { V } _ { t } ( s ) \doteq \sum _ { a } \pi ( a | s ) \hat { q } \left( s , a , \mathbf { w } _ { t } \right)
\end{aligned}
</script> </div> <h2 id=129-off-policy-traces-with-control-variates><strong>12.9 Off-policy Traces with Control Variates</strong><a class=headerlink href=#129-off-policy-traces-with-control-variates title="Permanent link">&para;</a></h2> <p>本节主要将 importance sampling 整合进算法。这里采用第 7 章的 per-decision 方法，定义如下的 <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return ：</p> <div> <div class=MathJax_Preview> G _ { t } ^ { \lambda s } \doteq \rho _ { t } \left( R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda s } \right) \right) + \left( 1 - \rho _ { t } \right) \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) </div> <script type="math/tex; mode=display">
G _ { t } ^ { \lambda s } \doteq \rho _ { t } \left( R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda s } \right) \right) + \left( 1 - \rho _ { t } \right) \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)
</script> </div> <p>他的 truncated 形式可由 state-based TD error 逼近得到：</p> <div> <div class=MathJax_Preview> \begin{aligned} &amp;\delta _ { t } ^ { s } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)\\ &amp;G _ { t } ^ { \lambda s } \approx \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) + \rho _ { t } \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned}
&\delta _ { t } ^ { s } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)\\
&G _ { t } ^ { \lambda s } \approx \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) + \rho _ { t } \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i }
\end{aligned}
</script> </div> <p>通过上面形式的 <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return ，可以方便地进行 forward-view 更新</p> <div> <div class=MathJax_Preview> \begin{aligned} \mathbf { w } _ { t + 1 } &amp; = \mathbf { w } _ { t } + \alpha \left( G _ { t } ^ { \lambda s } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right) \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \\ &amp; \approx \mathbf { w } _ { t } + \alpha \rho _ { t } \left( \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \right) \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned} \mathbf { w } _ { t + 1 } & = \mathbf { w } _ { t } + \alpha \left( G _ { t } ^ { \lambda s } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right) \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \\ & \approx \mathbf { w } _ { t } + \alpha \rho _ { t } \left( \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \right) \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \end{aligned}
</script> </div> <p>下面探究 forward view 和 backward view 的近似关系。对整个 forward view 过程进行求和，得到：</p> <div> <div class=MathJax_Preview> \begin{aligned} \sum _ { t = 1 } ^ { \infty } \left( \mathbf { w } _ { t + 1 } - \mathbf { w } _ { t } \right) &amp; \approx \sum _ { t = 1 } ^ { \infty } \sum _ { k = t } ^ { \infty } \alpha \rho _ { t } \delta _ { k } ^ { s } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ &amp; = \sum _ { k = 1 } ^ { \infty } \sum _ { t = 1 } ^ { k } \alpha \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ &amp; = \sum _ { k = 1 } ^ { \infty } \alpha \delta _ { k } ^ { s } \sum _ { t = 1 } ^ { k } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned} \sum _ { t = 1 } ^ { \infty } \left( \mathbf { w } _ { t + 1 } - \mathbf { w } _ { t } \right) & \approx \sum _ { t = 1 } ^ { \infty } \sum _ { k = t } ^ { \infty } \alpha \rho _ { t } \delta _ { k } ^ { s } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ & = \sum _ { k = 1 } ^ { \infty } \sum _ { t = 1 } ^ { k } \alpha \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ & = \sum _ { k = 1 } ^ { \infty } \alpha \delta _ { k } ^ { s } \sum _ { t = 1 } ^ { k } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \end{aligned}
</script> </div> <p>其中第二个等号用到了一个求和规则：</p> <div> <div class=MathJax_Preview> \sum _ { t = x } ^ { y } \sum _ { k = t } ^ { y } = \sum _ { k = x } ^ { y } \sum _ { t = x } ^ { k } </div> <script type="math/tex; mode=display">
\sum _ { t = x } ^ { y } \sum _ { k = t } ^ { y } = \sum _ { k = x } ^ { y } \sum _ { t = x } ^ { k }
</script> </div> <p>若上式的第二个求和项可写作 eligibility trace 并用于更新，则更新式变为 backward view TD update 。即，若表达式为 k 时刻的 trace，那他可由 k-1 时刻的值更新而得：</p> <div> <div class=MathJax_Preview> \begin{aligned} \mathbf { z } _ { k } &amp; = \sum _ { t = 1 } ^ { k } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ &amp; = \sum _ { t = 1 } ^ { k - 1 } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } + \rho _ { k } \nabla \hat { v } \left( S _ { k } , \mathbf { w } _ { k } \right) \\ &amp; = \gamma _ { k } \lambda _ { k } \rho _ { k } \underbrace{\sum _ { t = 1 } ^ { k - 1 } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k - 1 } \gamma _ { i } \lambda _ { i } \rho _ { i }}_{\mathbf{z}_{k-1}} +\rho_k\nabla\hat{v}(S_k,\mathbf{w}_k)\\ &amp; = \rho _ { k } \left( \gamma _ { k } \lambda _ { k } \mathbf { z } _ { k - 1 } + \nabla \hat { v } \left( S _ { k } , \mathbf { w } _ { k } \right) \right) \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned} \mathbf { z } _ { k } & = \sum _ { t = 1 } ^ { k } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ & = \sum _ { t = 1 } ^ { k - 1 } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } + \rho _ { k } \nabla \hat { v } \left( S _ { k } , \mathbf { w } _ { k } \right) \\ & = \gamma _ { k } \lambda _ { k } \rho _ { k } \underbrace{\sum _ { t = 1 } ^ { k - 1 } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k - 1 } \gamma _ { i } \lambda _ { i } \rho _ { i }}_{\mathbf{z}_{k-1}} +\rho_k\nabla\hat{v}(S_k,\mathbf{w}_k)\\ & = \rho _ { k } \left( \gamma _ { k } \lambda _ { k } \mathbf { z } _ { k - 1 } + \nabla \hat { v } \left( S _ { k } , \mathbf { w } _ { k } \right) \right) \end{aligned}
</script> </div> <p>整理即得</p> <div> <div class=MathJax_Preview> \mathbf { z } _ { t } \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right) </div> <script type="math/tex; mode=display">
\mathbf { z } _ { t } \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right)
</script> </div> <p>这个 eligibility trace 结合 半梯度 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 更新即为一般的 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 算法（<span><span class=MathJax_Preview>\rho_t=1</span><script type=math/tex>\rho_t=1</script></span> 时对应 on-policy）。在 off-policy 情况下，算法性能还不错，但是作为一个半梯度算法，稳定性欠佳（后面几节会考虑扩展此算法来保证稳定性）。</p> <p>对于 action-value 情况的算法，其实和 state-value 情况类似，现构造一个 action-based <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return ：</p> <div> <div class=MathJax_Preview> \begin{aligned} G _ { t } ^ { \lambda a } &amp; \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \left[ \rho _ { t + 1 } G _ { t + 1 } ^ { \lambda a } + \overline { V } _ { t } \left( S _ { t + 1 } \right) - \rho _ { t + 1 } \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right] \right) \\ &amp; = R _ { t + 1 } + \gamma _ { t + 1 } \left( \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \rho _ { t + 1 } \left[ G _ { t + 1 } ^ { \lambda a } - \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right] \right) \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned} G _ { t } ^ { \lambda a } & \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \left[ \rho _ { t + 1 } G _ { t + 1 } ^ { \lambda a } + \overline { V } _ { t } \left( S _ { t + 1 } \right) - \rho _ { t + 1 } \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right] \right) \\ & = R _ { t + 1 } + \gamma _ { t + 1 } \left( \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \rho _ { t + 1 } \left[ G _ { t + 1 } ^ { \lambda a } - \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right] \right) \end{aligned}
</script> </div> <p>其中</p> <div> <div class=MathJax_Preview> \overline { V } _ { t } ( s ) \doteq \sum _ { a } \pi ( a | s ) \hat { q } \left( s , a , \mathbf { w } _ { t } \right) </div> <script type="math/tex; mode=display">
\overline { V } _ { t } ( s ) \doteq \sum _ { a } \pi ( a | s ) \hat { q } \left( s , a , \mathbf { w } _ { t } \right)
</script> </div> <p>同样又基于 action-based TD error 来逼近 <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return ：</p> <div> <div class=MathJax_Preview> \begin{aligned} &amp;G _ { t } ^ { \lambda a } \approx \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) + \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { a } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i }\\ &amp;\delta _ { t } ^ { a } = R _ { t + 1 } + \gamma _ { t + 1 } \overline { V } _ { t } \left( S _ { t + 1 } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned}
&G _ { t } ^ { \lambda a } \approx \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) + \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { a } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i }\\
&\delta _ { t } ^ { a } = R _ { t + 1 } + \gamma _ { t + 1 } \overline { V } _ { t } \left( S _ { t + 1 } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
\end{aligned}
</script> </div> <p>然后做类似变换，得到 eligibility trace for action values：</p> <div> <div class=MathJax_Preview> \mathbf { z } _ { t } \doteq \gamma _ { t } \lambda _ { t } \rho _ { t } \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) </div> <script type="math/tex; mode=display">
\mathbf { z } _ { t } \doteq \gamma _ { t } \lambda _ { t } \rho _ { t } \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
</script> </div> <p>将其用于半梯度更新可得到更一般的 Sarsa(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) ，同样可通用于 on-policy 和 off-policy 。</p> <p><span><span class=MathJax_Preview>\lambda=1</span><script type=math/tex>\lambda=1</script></span> 时，目前这些算法和 MC 联系密切，而 <span><span class=MathJax_Preview>\lambda&lt;1</span><script type=math/tex>\lambda<1</script></span> 时，上面所有的 off-policy 算法都将面临 11 章提到过的『<strong>致命三因素（the deadly triad）</strong>』—— approximation、bootstrapping、off-policy 。</p> <h2 id=1210-watkinss-qlambdalambda-to-tree-backuplambdalambda><strong>12.10 Watkins's Q(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) to Tree-Backup(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>)</strong><a class=headerlink href=#1210-watkinss-qlambdalambda-to-tree-backuplambdalambda title="Permanent link">&para;</a></h2> <p>近些年提出了很多在 Q-learning 上使用 eligibility trace 的扩展算法，最早的便是 Watkins's Q(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) ：若采取 greedy action，则照常对 eligibility trace 进行衰退，否则，就将首个 non-greedy action 之后的 traces 重置为 0 。算法的 backup 示意图如下：</p> <p><img alt src=../imgs/RLAI_12/watkins.png></p> <p>第 7 章介绍过无需 importance sampling 的 n-step tree backup 算法，下面将 eligibility trace 结合于其中，称为 Tree-Backup(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 或 TB(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 算法，示意图如下：</p> <p><img alt src=../imgs/RLAI_12/tb-lamb.png></p> <p>该算法的 <span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>-return 为使用 action values 的递归式：</p> <div> <div class=MathJax_Preview> \begin{aligned} G _ { t } ^ { \lambda a } &amp; \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \left[ \sum _ { a \neq A _ { t + 1 } } \pi ( a | S _ { t + 1 } ) \hat { q } \left( S _ { t + 1 } , a , \mathbf { w } _ { t } \right) + \pi \left( A _ { t + 1 } | S _ { t + 1 } \right) G _ { t + 1 } ^ { \lambda a } \right] \right) \\ &amp; = R _ { t + 1 } + \gamma _ { t + 1 } \left( \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \pi \left( A _ { t + 1 } | S _ { t + 1 } \right) \left( G _ { t + 1 } ^ { \lambda a } - \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right) \right) \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned} G _ { t } ^ { \lambda a } & \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \left[ \sum _ { a \neq A _ { t + 1 } } \pi ( a | S _ { t + 1 } ) \hat { q } \left( S _ { t + 1 } , a , \mathbf { w } _ { t } \right) + \pi \left( A _ { t + 1 } | S _ { t + 1 } \right) G _ { t + 1 } ^ { \lambda a } \right] \right) \\ & = R _ { t + 1 } + \gamma _ { t + 1 } \left( \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \pi \left( A _ { t + 1 } | S _ { t + 1 } \right) \left( G _ { t + 1 } ^ { \lambda a } - \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right) \right) \end{aligned}
</script> </div> <p>再对 return 做逼近：</p> <div> <div class=MathJax_Preview> \begin{aligned} &amp;\delta _ { t } ^ { a } = R _ { t + 1 } + \gamma _ { t + 1 } \overline { V } _ { t } \left( S _ { t + 1 } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)\\ &amp;G _ { t } ^ { \lambda a } \approx \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) + \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { a } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \pi \left( A _ { i } | S _ { i } \right) \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned}
&\delta _ { t } ^ { a } = R _ { t + 1 } + \gamma _ { t + 1 } \overline { V } _ { t } \left( S _ { t + 1 } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)\\
&G _ { t } ^ { \lambda a } \approx \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) + \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { a } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \pi \left( A _ { i } | S _ { i } \right)
\end{aligned}
</script> </div> <p>最后得到 eligibility trace update：</p> <div> <div class=MathJax_Preview> \mathbf { z } _ { t } \doteq \gamma _ { t } \lambda _ { t } \pi \left( A _ { t } | S _ { t } \right) \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) </div> <script type="math/tex; mode=display">
\mathbf { z } _ { t } \doteq \gamma _ { t } \lambda _ { t } \pi \left( A _ { t } | S _ { t } \right) \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
</script> </div> <p>再利用更新规则</p> <div> <div class=MathJax_Preview> \mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t } </div> <script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t }
</script> </div> <p>组成了完整的 TB(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 算法。该算法依然不稳定，同样需要结合后面的方法。</p> <h2 id=1211-stable-off-policy-methods-with-traces><strong>12.11 Stable Off-policy Methods with Traces</strong><a class=headerlink href=#1211-stable-off-policy-methods-with-traces title="Permanent link">&para;</a></h2> <p>前面几节中的一些 eligibility trace 方法是可以在 off-policy 中取得稳定解的，这一节介绍四种最为重要的使用了 bootstrapping 和 discounting 的函数，他们的思想都基于 11 章中的 Gradient-TD、Emphatic-TD。下面的算法都假定了<strong>线性</strong>函数逼近这一前提（至于非线性，理论上也能做相似的处理），符号若无特殊说明，都和前面相同。</p> <h3 id=1-gtdlambdalambda-tdc-eligibility-trace>(1) GTD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) ：TDC 算法的 eligibility trace 形式<a class=headerlink href=#1-gtdlambdalambda-tdc-eligibility-trace title="Permanent link">&para;</a></h3> <p>目标：学习 <span><span class=MathJax_Preview>\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</span><script type=math/tex>\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</script></span> ，更新式如下：</p> <div> <div class=MathJax_Preview> \begin{aligned} &amp;\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { s } \mathbf { z } _ { t } - \alpha \gamma _ { t + 1 } \left( 1 - \lambda _ { t + 1 } \right) \left( \mathbf { z } _ { t } ^ { \top } \mathbf { v } _ { t } \right) \mathbf { x } _ { t + 1 }\\ &amp;\mathbf { v } _ { t + 1 } \doteq \mathbf { v } _ { t } + \beta \delta _ { t } ^ { s } \mathbf { z } _ { t } - \beta \left( \mathbf { v } _ { t } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t } \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned}
&\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { s } \mathbf { z } _ { t } - \alpha \gamma _ { t + 1 } \left( 1 - \lambda _ { t + 1 } \right) \left( \mathbf { z } _ { t } ^ { \top } \mathbf { v } _ { t } \right) \mathbf { x } _ { t + 1 }\\
&\mathbf { v } _ { t + 1 } \doteq \mathbf { v } _ { t } + \beta \delta _ { t } ^ { s } \mathbf { z } _ { t } - \beta \left( \mathbf { v } _ { t } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t }
\end{aligned}
</script> </div> <h3 id=2-gqlambdalambda-gradient-td-action-value-eligibility-trace>(2) GQ(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) ：Gradient-TD 算法（action-value）的 eligibility trace 形式<a class=headerlink href=#2-gqlambdalambda-gradient-td-action-value-eligibility-trace title="Permanent link">&para;</a></h3> <p>目标：学习 <span><span class=MathJax_Preview>\hat { q } \left( s , a , \mathbf { w } _ { t } \right) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s , a ) \approx q _ { \pi } ( s , a )</span><script type=math/tex>\hat { q } \left( s , a , \mathbf { w } _ { t } \right) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s , a ) \approx q _ { \pi } ( s , a )</script></span> ，更新式如下：</p> <div> <div class=MathJax_Preview> \begin{aligned} &amp;\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { a } \mathbf { z } _ { t } - \alpha \gamma _ { t + 1 } \left( 1 - \lambda _ { t + 1 } \right) \left( \mathbf { z } _ { t } ^ { \top } \mathbf { v } _ { t } \right) \overline { \mathbf { x } } _ { t + 1 }\\ &amp;\overline { \mathbf { x } } _ { t } \doteq \sum _ { a } \pi ( a | S _ { t } ) \mathbf { x } \left( S _ { t } , a \right)\\ &amp;\delta _ { t } ^ { a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \mathbf { w } _ { t } ^ { \top } \overline { \mathbf { x } } _ { t + 1 } - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned}
&\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { a } \mathbf { z } _ { t } - \alpha \gamma _ { t + 1 } \left( 1 - \lambda _ { t + 1 } \right) \left( \mathbf { z } _ { t } ^ { \top } \mathbf { v } _ { t } \right) \overline { \mathbf { x } } _ { t + 1 }\\
&\overline { \mathbf { x } } _ { t } \doteq \sum _ { a } \pi ( a | S _ { t } ) \mathbf { x } \left( S _ { t } , a \right)\\
&\delta _ { t } ^ { a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \mathbf { w } _ { t } ^ { \top } \overline { \mathbf { x } } _ { t + 1 } - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t }
\end{aligned}
</script> </div> <h3 id=3-htdlambdalambda-gtdlambdalambda-tdlambdalambda>(3) HTD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) ：由 GTD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 和 TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) 的结合算法<a class=headerlink href=#3-htdlambdalambda-gtdlambdalambda-tdlambdalambda title="Permanent link">&para;</a></h3> <p>目标：学习 <span><span class=MathJax_Preview>\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</span><script type=math/tex>\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</script></span> ，更新式如下：</p> <div> <div class=MathJax_Preview> \begin{aligned} \mathbf { w } _ { t + 1 } &amp; \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { s } \mathbf { z } _ { t } + \alpha \left( \left( \mathbf { z } _ { t } - \mathbf { z } _ { t } ^ { b } \right) ^ { \top } \mathbf { v } _ { t } \right) \left( \mathbf { x } _ { t } - \gamma _ { t + 1 } \mathbf { x } _ { t + 1 } \right) \\ \mathbf { v } _ { t + 1 } &amp; \doteq \mathbf { v } _ { t } + \beta \delta _ { t } ^ { s } \mathbf { z } _ { t } - \beta \left( \mathbf { z } _ { t } ^ { b ^\top } \mathbf { v } _ { t } \right) \left( \mathbf { x } _ { t } - \gamma _ { t + 1 } \mathbf { x } _ { t + 1 } \right) , \quad \text { with } \mathbf { v } _ { 0 } \doteq \mathbf { 0 } \\ \mathbf { z } _ { t } &amp; \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t } \right) , \quad \text { with } \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } \\ \mathbf { z } _ { t } ^ { b } &amp; \doteq \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } ^ { b } + \mathbf { x } _ { t } , \quad \text { with } \mathbf { z } _ { - 1 } ^ { b } \doteq \mathbf { 0 } \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned} \mathbf { w } _ { t + 1 } & \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { s } \mathbf { z } _ { t } + \alpha \left( \left( \mathbf { z } _ { t } - \mathbf { z } _ { t } ^ { b } \right) ^ { \top } \mathbf { v } _ { t } \right) \left( \mathbf { x } _ { t } - \gamma _ { t + 1 } \mathbf { x } _ { t + 1 } \right) \\ \mathbf { v } _ { t + 1 } & \doteq \mathbf { v } _ { t } + \beta \delta _ { t } ^ { s } \mathbf { z } _ { t } - \beta \left( \mathbf { z } _ { t } ^ { b ^\top } \mathbf { v } _ { t } \right) \left( \mathbf { x } _ { t } - \gamma _ { t + 1 } \mathbf { x } _ { t + 1 } \right) , \quad \text { with } \mathbf { v } _ { 0 } \doteq \mathbf { 0 } \\ \mathbf { z } _ { t } & \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t } \right) , \quad \text { with } \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } \\ \mathbf { z } _ { t } ^ { b } & \doteq \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } ^ { b } + \mathbf { x } _ { t } , \quad \text { with } \mathbf { z } _ { - 1 } ^ { b } \doteq \mathbf { 0 } \end{aligned}
</script> </div> <h3 id=4-emphatic-tdlambdalambda-emphatic-td-eligibility-trace>(4) Emphatic TD(<span><span class=MathJax_Preview>\lambda</span><script type=math/tex>\lambda</script></span>) ：Emphatic TD 的 eligibility trace 形式<a class=headerlink href=#4-emphatic-tdlambdalambda-emphatic-td-eligibility-trace title="Permanent link">&para;</a></h3> <p>目标：学习 <span><span class=MathJax_Preview>\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</span><script type=math/tex>\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</script></span> ，此算法在 off-policy 下收敛性很强（代价是高方差、慢速），允许任何程度的 bootstrapping 。更新式如下：</p> <div> <div class=MathJax_Preview> \begin{aligned} &amp;\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t } \\ &amp;\delta _ { t } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t + 1 } - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } \\ &amp; \mathbf { z } _ { t } \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + M _ { t } \mathbf { x } _ { t } \right) , \text { with } \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } \\&amp; M _ { t } \doteq \lambda _ { t } I _ { t } + \left( 1 - \lambda _ { t } \right) F _ { t } \\ &amp;F _ { t } \doteq \rho _ { t - 1 } \gamma _ { t } F _ { t - 1 } + I _ { t } , \quad \text { with } F _ { 0 } \doteq i \left( S _ { 0 } \right) \end{aligned} </div> <script type="math/tex; mode=display">
\begin{aligned} &\mathbf { w } _ { t + 1 }  \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t } \\ &\delta _ { t } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t + 1 } - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } \\ & \mathbf { z } _ { t } \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + M _ { t } \mathbf { x } _ { t } \right) , \text { with } \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } \\& M _ { t } \doteq \lambda _ { t } I _ { t } + \left( 1 - \lambda _ { t } \right) F _ { t } \\ &F _ { t } \doteq  \rho _ { t - 1 } \gamma _ { t } F _ { t - 1 } + I _ { t } , \quad \text { with } F _ { 0 } \doteq i \left( S _ { 0 } \right) \end{aligned}
</script> </div> <p>其中，</p> <ul> <li><span><span class=MathJax_Preview>M_t\geq0</span><script type=math/tex>M_t\geq0</script></span> ：emphasis</li> <li><span><span class=MathJax_Preview>F_t\geq0</span><script type=math/tex>F_t\geq0</script></span> ：followon trace</li> <li><span><span class=MathJax_Preview>I_t\geq 0</span><script type=math/tex>I_t\geq 0</script></span> ：interest</li> </ul> <h2 id=1212-implementation-issues><strong>12.12 Implementation Issues</strong><a class=headerlink href=#1212-implementation-issues title="Permanent link">&para;</a></h2> <p>看起来 eligibility trace 比 one-step 方法更复杂，因为他需要在每个时间点对所有状态做更新。但其实执行起来并不是什么大问题，因为实际中绝大多数 state 的 trace 都为 0，只有少量最近经历过的 state 的trace 大于 0 ，所以也只需做少量更新。</p> <p>在有函数逼近的情况下，不使用 eligibility trace 的方法的计算优势有所下降，尤其是当使用了神经网络，使用 trace 时的内存和计算力的消耗只是原来的两倍。</p> <hr> <div class=md-source-date> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">August 1, 2019</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid" aria-label=Footer> <a href=../RLAI_11/ title="Chapter 11" class="md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> Chapter 11 </div> </div> </a> <a href=../RLAI_13/ title="Chapter 13" class="md-footer-nav__link md-footer-nav__link--next" rel=next> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> Chapter 13 </div> </div> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2016-2020 ZHANGWP </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/zawnpn target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/zawnpn target=_blank rel=noopener title=twitter.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://psnprofiles.com/zawnpn target=_blank rel=noopener title=psnprofiles.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><path d="M570.9 372.3c-11.3 14.2-38.8 24.3-38.8 24.3L327 470.2v-54.3l150.9-53.8c17.1-6.1 19.8-14.8 5.8-19.4-13.9-4.6-39.1-3.3-56.2 2.9L327 381.1v-56.4c23.2-7.8 47.1-13.6 75.7-16.8 40.9-4.5 90.9.6 130.2 15.5 44.2 14 49.2 34.7 38 48.9zm-224.4-92.5v-139c0-16.3-3-31.3-18.3-35.6-11.7-3.8-19 7.1-19 23.4v347.9l-93.8-29.8V32c39.9 7.4 98 24.9 129.2 35.4C424.1 94.7 451 128.7 451 205.2c0 74.5-46 102.8-104.5 74.6zM43.2 410.2c-45.4-12.8-53-39.5-32.3-54.8 19.1-14.2 51.7-24.9 51.7-24.9l134.5-47.8v54.5l-96.8 34.6c-17.1 6.1-19.7 14.8-5.8 19.4 13.9 4.6 39.1 3.3 56.2-2.9l46.4-16.9v48.8c-51.6 9.3-101.4 7.3-153.9-10z"/></svg> </a> <a href=https://steamcommunity.com/id/zawnpn/ target=_blank rel=noopener title=steamcommunity.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M496 256c0 137-111.2 248-248.4 248-113.8 0-209.6-76.3-239-180.4l95.2 39.3c6.4 32.1 34.9 56.4 68.9 56.4 39.2 0 71.9-32.4 70.2-73.5l84.5-60.2c52.1 1.3 95.8-40.9 95.8-93.5 0-51.6-42-93.5-93.7-93.5s-93.7 42-93.7 93.5v1.2L176.6 279c-15.5-.9-30.7 3.4-43.5 12.1L0 236.1C10.2 108.4 117.1 8 247.6 8 384.8 8 496 119 496 256zM155.7 384.3l-30.5-12.6a52.79 52.79 0 0027.2 25.8c26.9 11.2 57.8-1.6 69-28.4 5.4-13 5.5-27.3.1-40.3-5.4-13-15.5-23.2-28.5-28.6-12.9-5.4-26.7-5.2-38.9-.6l31.5 13c19.8 8.2 29.2 30.9 20.9 50.7-8.3 19.9-31 29.2-50.8 21zm173.8-129.9c-34.4 0-62.4-28-62.4-62.3s28-62.3 62.4-62.3 62.4 28 62.4 62.3-27.9 62.3-62.4 62.3zm.1-15.6c25.9 0 46.9-21 46.9-46.8 0-25.9-21-46.8-46.9-46.8s-46.9 21-46.9 46.8c.1 25.8 21.1 46.8 46.9 46.8z"/></svg> </a> <a href=https://www.zhihu.com/people/zhangwanpeng target=_blank rel=noopener title=www.zhihu.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13H170.54zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82v170.31zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62v.01zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2l19.23 14.43zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78l.03-.01z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../../../../assets/javascripts/vendor.d710d30a.min.js></script> <script src=../../../../assets/javascripts/bundle.b39636ac.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script> <script>
        app = initialize({
          base: "../../../..",
          features: ["tabs"],
          search: Object.assign({
            worker: "../../../../assets/javascripts/worker/search.a68abb33.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> <script src="//cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-MML-AM_SVG"></script> </body> </html>