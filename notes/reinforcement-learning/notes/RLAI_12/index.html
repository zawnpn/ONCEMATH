



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Welcome to zhangwp's blog.">
      
      
        <link rel="canonical" href="https://www.zhangwp.com/notes/reinforcement-learning/notes/RLAI_12/">
      
      
        <meta name="author" content="zawnpn">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-3.0.4">
    
    
      
        <title>Chapter 12 - ZHANGWP</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/application.451f80e5.css">
      
        <link rel="stylesheet" href="../../../../assets/stylesheets/application-palette.22915126.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
      <script src="../../../../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
    
    <link rel="stylesheet" href="../../../../assets/fonts/material-icons.css">
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="white" data-md-color-accent="light-blue">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="../../../../#-" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://www.zhangwp.com" title="ZHANGWP" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                ZHANGWP
              </span>
              <span class="md-header-nav__topic">
                Chapter 12
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/zawnpn/ZHANGWP/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../.." title="Home" class="md-tabs__link">
          Home
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../" title="Notes" class="md-tabs__link md-tabs__link--active">
          Notes
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../../tips/" title="Tips" class="md-tabs__link">
          Tips
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../../share/" title="Share" class="md-tabs__link">
          Share
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../../statements/" title="Statements" class="md-tabs__link">
          Statements
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://www.zhangwp.com" title="ZHANGWP" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    ZHANGWP
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/zawnpn/ZHANGWP/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      Home
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        Home
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../links/" title="Links" class="md-nav__link">
      Links
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../donates/" title="Donate" class="md-nav__link">
      Donate
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Notes
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Notes
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-2" type="checkbox" id="nav-2-2" checked>
    
    <label class="md-nav__link" for="nav-2-2">
      Reinforcement
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-2">
        Reinforcement
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-2-1" type="checkbox" id="nav-2-2-1" checked>
    
    <label class="md-nav__link" for="nav-2-2-1">
      Reinforcement Learning An Introduction
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-2-2-1">
        Reinforcement Learning An Introduction
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_2/" title="Chapter 2" class="md-nav__link">
      Chapter 2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_3/" title="Chapter 3" class="md-nav__link">
      Chapter 3
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_4/" title="Chapter 4" class="md-nav__link">
      Chapter 4
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_5/" title="Chapter 5" class="md-nav__link">
      Chapter 5
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_6/" title="Chapter 6" class="md-nav__link">
      Chapter 6
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_7/" title="Chapter 7" class="md-nav__link">
      Chapter 7
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_8/" title="Chapter 8" class="md-nav__link">
      Chapter 8
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_9/" title="Chapter 9" class="md-nav__link">
      Chapter 9
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_10/" title="Chapter 10" class="md-nav__link">
      Chapter 10
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_11/" title="Chapter 11" class="md-nav__link">
      Chapter 11
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Chapter 12
      </label>
    
    <a href="./" title="Chapter 12" class="md-nav__link md-nav__link--active">
      Chapter 12
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#121-the-lambdalambda-return" title="12.1 The \lambda\lambda-return" class="md-nav__link">
    12.1 The \lambda\lambda-return
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#122-tdlambdalambda" title="12.2 TD(\lambda\lambda)" class="md-nav__link">
    12.2 TD(\lambda\lambda)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#123-n-step-truncated-lambdalambda-return-methods" title="12.3 n-step Truncated \lambda\lambda-return Methods" class="md-nav__link">
    12.3 n-step Truncated \lambda\lambda-return Methods
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#124-redoing-updates-the-online-lambdalambda-return-algorithm" title="12.4 Redoing Updates: The Online \lambda\lambda-return Algorithm" class="md-nav__link">
    12.4 Redoing Updates: The Online \lambda\lambda-return Algorithm
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#125-true-online-tdlambdalambda" title="12.5 True Online TD(\lambda\lambda)" class="md-nav__link">
    12.5 True Online TD(\lambda\lambda)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#126-dutch-traces-in-monte-carlo-learning" title="12.6 Dutch Traces in Monte Carlo Learning" class="md-nav__link">
    12.6 Dutch Traces in Monte Carlo Learning
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#127-sarsalambdalambda" title="12.7 Sarsa(\lambda\lambda)" class="md-nav__link">
    12.7 Sarsa(\lambda\lambda)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#128-variable-lambdalambda-and-gammagamma" title="12.8 Variable \lambda\lambda and \gamma​\gamma​" class="md-nav__link">
    12.8 Variable \lambda\lambda and \gamma​\gamma​
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#129-off-policy-traces-with-control-variates" title="12.9 Off-policy Traces with Control Variates" class="md-nav__link">
    12.9 Off-policy Traces with Control Variates
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1210-watkinss-qlambdalambda-to-tree-backuplambdalambda" title="12.10 Watkins's Q(\lambda\lambda) to Tree-Backup(\lambda\lambda)" class="md-nav__link">
    12.10 Watkins's Q(\lambda\lambda) to Tree-Backup(\lambda\lambda)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1211-stable-off-policy-methods-with-traces" title="12.11 Stable Off-policy Methods with Traces" class="md-nav__link">
    12.11 Stable Off-policy Methods with Traces
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-gtdlambdalambda-tdc-eligibility-trace" title="(1) GTD(\lambda\lambda) ：TDC 算法的 eligibility trace 形式" class="md-nav__link">
    (1) GTD(\lambda\lambda) ：TDC 算法的 eligibility trace 形式
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-gqlambdalambda-gradient-td-action-value-eligibility-trace" title="(2) GQ(\lambda\lambda) ：Gradient-TD 算法（action-value）的 eligibility trace 形式" class="md-nav__link">
    (2) GQ(\lambda\lambda) ：Gradient-TD 算法（action-value）的 eligibility trace 形式
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-htdlambdalambda-gtdlambdalambda-tdlambdalambda" title="(3) HTD(\lambda\lambda) ：由 GTD(\lambda\lambda) 和 TD(\lambda\lambda) 的结合算法" class="md-nav__link">
    (3) HTD(\lambda\lambda) ：由 GTD(\lambda\lambda) 和 TD(\lambda\lambda) 的结合算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-emphatic-tdlambdalambda-emphatic-td-eligibility-trace" title="(4) Emphatic TD(\lambda\lambda) ：Emphatic TD 的 eligibility trace 形式" class="md-nav__link">
    (4) Emphatic TD(\lambda\lambda) ：Emphatic TD 的 eligibility trace 形式
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1212-implementation-issues" title="12.12 Implementation Issues" class="md-nav__link">
    12.12 Implementation Issues
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_13/" title="Chapter 13" class="md-nav__link">
      Chapter 13
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-2-2" type="checkbox" id="nav-2-2-2">
    
    <label class="md-nav__link" for="nav-2-2-2">
      Some Introduction
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-2-2-2">
        Some Introduction
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../MCTS_introduction/" title="MCTS" class="md-nav__link">
      MCTS
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Tips
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Tips
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../tips/" title="Tips" class="md-nav__link">
      Tips
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../tips/to-do/" title="To Do" class="md-nav__link">
      To Do
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../tips/python/" title="Python" class="md-nav__link">
      Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../tips/data-processing/" title="Data Processing" class="md-nav__link">
      Data Processing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../tips/git/" title="Git" class="md-nav__link">
      Git
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../tips/linux/" title="Linux" class="md-nav__link">
      Linux
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../tips/win/" title="Windows" class="md-nav__link">
      Windows
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Share
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        Share
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/blog-history/" title="博客历史" class="md-nav__link">
      博客历史
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/game-log/" title="Game-Log" class="md-nav__link">
      Game-Log
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-4" type="checkbox" id="nav-4-4">
    
    <label class="md-nav__link" for="nav-4-4">
      NKU-Toolkit
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-4">
        NKU-Toolkit
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/nku-eamis/" title="NKU-EAMIS工具" class="md-nav__link">
      NKU-EAMIS工具
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/nku-sms-rss/" title="NKU-SMS-RSS" class="md-nav__link">
      NKU-SMS-RSS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/eamis-miniapp/" title="NKU-EAMIS_MiniApp(南开大学教务助手小程序)" class="md-nav__link">
      NKU-EAMIS_MiniApp(南开大学教务助手小程序)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/eamis-workflow/" title="NKU-EAMIS for iOS(Workflow)" class="md-nav__link">
      NKU-EAMIS for iOS(Workflow)
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5" type="checkbox" id="nav-4-5">
    
    <label class="md-nav__link" for="nav-4-5">
      Steam-Toolkit
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-5">
        Steam-Toolkit
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/steam-market-price-bot/" title="Steam市场比价爬虫" class="md-nav__link">
      Steam市场比价爬虫
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-6" type="checkbox" id="nav-4-6">
    
    <label class="md-nav__link" for="nav-4-6">
      数学建模
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-6">
        数学建模
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/2017-mcm-icm/" title="2017美赛参赛整理(Problem D)" class="md-nav__link">
      2017美赛参赛整理(Problem D)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/2016-guosai/" title="2016数学建模国赛" class="md-nav__link">
      2016数学建模国赛
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/math-model-szb/" title="数学建模之2016深圳杯——初次尝试" class="md-nav__link">
      数学建模之2016深圳杯——初次尝试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/polygon-to-ellipse/" title="随机多边形转化为椭圆的过程研究" class="md-nav__link">
      随机多边形转化为椭圆的过程研究
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/FFT-GPU-Accel/" title="FFT-GPU-Accel" class="md-nav__link">
      FFT-GPU-Accel
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-7" type="checkbox" id="nav-4-7">
    
    <label class="md-nav__link" for="nav-4-7">
      NKU 数院试题整理
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-7">
        NKU 数院试题整理
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/nku-sms-exams/" title="汇总" class="md-nav__link">
      汇总
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-7-2" type="checkbox" id="nav-4-7-2">
    
    <label class="md-nav__link" for="nav-4-7-2">
      分析
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-7-2">
        分析
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/functional-analysis-final/" title="2017-2018第一学期泛函分析期末考试" class="md-nav__link">
      2017-2018第一学期泛函分析期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/real-variable-function/" title="2016-2017第二学期实变函数期末考试" class="md-nav__link">
      2016-2017第二学期实变函数期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/mathematical-analysis-3-3-final/" title="2016-2017第一学期数学分析3-3期末考试" class="md-nav__link">
      2016-2017第一学期数学分析3-3期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/complex-analysis-final/" title="2016-2017第一学期复变函数期末考试" class="md-nav__link">
      2016-2017第一学期复变函数期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/mathematical-analysis-3-3-middle/" title="2016-2017第一学期数学分析3-3期中考试" class="md-nav__link">
      2016-2017第一学期数学分析3-3期中考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/mathematical-analysis-3-2-final/" title="2015-2016第二学期数学分析3-2期末考试（含解答）" class="md-nav__link">
      2015-2016第二学期数学分析3-2期末考试（含解答）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/mathematical-analysis-3-2-middle/" title="2015-2016第二学期数学分析3-2期中考试" class="md-nav__link">
      2015-2016第二学期数学分析3-2期中考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/mathematical-analysis-3-1-final/" title="2015-2016第一学期数学分析3-1期末考试" class="md-nav__link">
      2015-2016第一学期数学分析3-1期末考试
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-7-3" type="checkbox" id="nav-4-7-3">
    
    <label class="md-nav__link" for="nav-4-7-3">
      代数
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-7-3">
        代数
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/abstract-algebra-final/" title="2016-2017第一学期抽象代数期末考试" class="md-nav__link">
      2016-2017第一学期抽象代数期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/abstract-algebra-middle/" title="2016-2017第一学期抽象代数期中考试" class="md-nav__link">
      2016-2017第一学期抽象代数期中考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/advanced-algebra-2-2-final/" title="2015-2016第二学期高等代数2-2期末考试" class="md-nav__link">
      2015-2016第二学期高等代数2-2期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/advanced-algebra-2-2-middle/" title="2015-2016第二学期高等代数2-2期中考试" class="md-nav__link">
      2015-2016第二学期高等代数2-2期中考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/advanced-algebra-2-1-final/" title="2015-2016第一学期高等代数2-1期末考试" class="md-nav__link">
      2015-2016第一学期高等代数2-1期末考试
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-7-4" type="checkbox" id="nav-4-7-4">
    
    <label class="md-nav__link" for="nav-4-7-4">
      概率统计
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-7-4">
        概率统计
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/probability-final/" title="2016-2017第二学期概率论期末考试" class="md-nav__link">
      2016-2017第二学期概率论期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/probability-middle/" title="2016-2017第二学期概率论期中考试" class="md-nav__link">
      2016-2017第二学期概率论期中考试
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-7-5" type="checkbox" id="nav-4-7-5">
    
    <label class="md-nav__link" for="nav-4-7-5">
      微分方程
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-7-5">
        微分方程
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/PDE-final/" title="2017-2018第一学期数理方程期末考试" class="md-nav__link">
      2017-2018第一学期数理方程期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/ODE-final/" title="2016-2017第一学期常微分方程期末考试" class="md-nav__link">
      2016-2017第一学期常微分方程期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/exam/ODE-middle/" title="2016-2017第一学期常微分方程期中考试" class="md-nav__link">
      2016-2017第一学期常微分方程期中考试
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-8" type="checkbox" id="nav-4-8">
    
    <label class="md-nav__link" for="nav-4-8">
      Other
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-8">
        Other
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/github-student-pack/" title="Student Developer Pack - GitHub Education" class="md-nav__link">
      Student Developer Pack - GitHub Education
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/my-postgraduate-share/" title="保研推免经验分享 - 数学系跨保 CS" class="md-nav__link">
      保研推免经验分享 - 数学系跨保 CS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/roc-fly/" title="鹏程万里" class="md-nav__link">
      鹏程万里
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Statements
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Statements
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../statements/" title="Statements" class="md-nav__link">
      Statements
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#121-the-lambdalambda-return" title="12.1 The \lambda\lambda-return" class="md-nav__link">
    12.1 The \lambda\lambda-return
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#122-tdlambdalambda" title="12.2 TD(\lambda\lambda)" class="md-nav__link">
    12.2 TD(\lambda\lambda)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#123-n-step-truncated-lambdalambda-return-methods" title="12.3 n-step Truncated \lambda\lambda-return Methods" class="md-nav__link">
    12.3 n-step Truncated \lambda\lambda-return Methods
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#124-redoing-updates-the-online-lambdalambda-return-algorithm" title="12.4 Redoing Updates: The Online \lambda\lambda-return Algorithm" class="md-nav__link">
    12.4 Redoing Updates: The Online \lambda\lambda-return Algorithm
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#125-true-online-tdlambdalambda" title="12.5 True Online TD(\lambda\lambda)" class="md-nav__link">
    12.5 True Online TD(\lambda\lambda)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#126-dutch-traces-in-monte-carlo-learning" title="12.6 Dutch Traces in Monte Carlo Learning" class="md-nav__link">
    12.6 Dutch Traces in Monte Carlo Learning
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#127-sarsalambdalambda" title="12.7 Sarsa(\lambda\lambda)" class="md-nav__link">
    12.7 Sarsa(\lambda\lambda)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#128-variable-lambdalambda-and-gammagamma" title="12.8 Variable \lambda\lambda and \gamma​\gamma​" class="md-nav__link">
    12.8 Variable \lambda\lambda and \gamma​\gamma​
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#129-off-policy-traces-with-control-variates" title="12.9 Off-policy Traces with Control Variates" class="md-nav__link">
    12.9 Off-policy Traces with Control Variates
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1210-watkinss-qlambdalambda-to-tree-backuplambdalambda" title="12.10 Watkins's Q(\lambda\lambda) to Tree-Backup(\lambda\lambda)" class="md-nav__link">
    12.10 Watkins's Q(\lambda\lambda) to Tree-Backup(\lambda\lambda)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1211-stable-off-policy-methods-with-traces" title="12.11 Stable Off-policy Methods with Traces" class="md-nav__link">
    12.11 Stable Off-policy Methods with Traces
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-gtdlambdalambda-tdc-eligibility-trace" title="(1) GTD(\lambda\lambda) ：TDC 算法的 eligibility trace 形式" class="md-nav__link">
    (1) GTD(\lambda\lambda) ：TDC 算法的 eligibility trace 形式
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-gqlambdalambda-gradient-td-action-value-eligibility-trace" title="(2) GQ(\lambda\lambda) ：Gradient-TD 算法（action-value）的 eligibility trace 形式" class="md-nav__link">
    (2) GQ(\lambda\lambda) ：Gradient-TD 算法（action-value）的 eligibility trace 形式
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-htdlambdalambda-gtdlambdalambda-tdlambdalambda" title="(3) HTD(\lambda\lambda) ：由 GTD(\lambda\lambda) 和 TD(\lambda\lambda) 的结合算法" class="md-nav__link">
    (3) HTD(\lambda\lambda) ：由 GTD(\lambda\lambda) 和 TD(\lambda\lambda) 的结合算法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-emphatic-tdlambdalambda-emphatic-td-eligibility-trace" title="(4) Emphatic TD(\lambda\lambda) ：Emphatic TD 的 eligibility trace 形式" class="md-nav__link">
    (4) Emphatic TD(\lambda\lambda) ：Emphatic TD 的 eligibility trace 形式
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1212-implementation-issues" title="12.12 Implementation Issues" class="md-nav__link">
    12.12 Implementation Issues
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/zawnpn/ZHANGWP/edit/master/docs/notes/reinforcement-learning/notes/RLAI_12.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="-">强化学习导论（十二）- 资格迹<a class="headerlink" href="#-" title="Permanent link">&para;</a></h1>
<p>Eligibility Traces 是强化学习的基本原理之一。几乎所有 TD 方法都可以和 eligibility traces 结合起来生成更高效通用的方法。</p>
<p>在 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 方法中，<span><span class="MathJax_Preview">\lambda\in[0,1]</span><script type="math/tex">\lambda\in[0,1]</script></span>，两个极端的例子是 MC (<span><span class="MathJax_Preview">\lambda=1</span><script type="math/tex">\lambda=1</script></span>) 和 1-step TD (<span><span class="MathJax_Preview">\lambda=0</span><script type="math/tex">\lambda=0</script></span>)。</p>
<p>与n-step方法相比：</p>
<ul>
<li>Eligibility Traces 方法只需存储一个trace vector，而不是 n 个最新的 feature vectors</li>
<li>学习过程是连续且均匀的，不会有延迟</li>
<li>不需要在 episode 结束时才进行所有运算</li>
<li>学习可以立刻影响行为，不需要 n step 后才延迟生效</li>
</ul>
<p>前面讲过的很多方法根据后面的一些 rewards 来更新，这种形式称为 forward views ，通常 forward views 并不实用，因为 update 依赖于当前未知的量，这一章会介绍一种新方法，采用 eligibility trace 往前看最近经过的 states ，从而得到当前 TD error ，称之为 backward views 。</p>
<h2 id="121-the-lambdalambda-return"><strong>12.1 The <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return</strong><a class="headerlink" href="#121-the-lambdalambda-return" title="Permanent link">&para;</a></h2>
<p>n-step return 的定义如下：</p>
<div>
<div class="MathJax_Preview">
G _ { t : t + n } \doteq R _ { t + 1 } + \gamma R _ { t + 2 } + \cdots + \gamma ^ { n - 1 } R _ { t + n } + \gamma ^ { n } \hat { v } \left( S _ { t + n } , \mathbf { w } _ { t + n - 1 } \right)
</div>
<script type="math/tex; mode=display">
G _ { t : t + n } \doteq R _ { t + 1 } + \gamma R _ { t + 2 } + \cdots + \gamma ^ { n - 1 } R _ { t + n } + \gamma ^ { n } \hat { v } \left( S _ { t + n } , \mathbf { w } _ { t + n - 1 } \right)
</script>
</div>
<p>现在考虑多个 n-step return 的加权平均，只需权重和为 1，仍能用作 update target，如 <span><span class="MathJax_Preview">\frac { 1 } { 2 } G _ { t : t + 2 } + \frac { 1 } { 2 } G _ { t : t + 4 }</span><script type="math/tex">\frac { 1 } { 2 } G _ { t : t + 2 } + \frac { 1 } { 2 } G _ { t : t + 4 }</script></span> ，这种更新方式称为 compound update，其 backup 图如下</p>
<p><img alt="" src="../imgs/RLAI_12/compound.png" /></p>
<p>TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 也属于这种 averaging n-step update ，他包括了所有的 n-step updates，权重系数分别为 <span><span class="MathJax_Preview">\lambda^{n-1}, \lambda\in[0,1]</span><script type="math/tex">\lambda^{n-1}, \lambda\in[0,1]</script></span>，<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 定义如下（其中 <span><span class="MathJax_Preview">1-\lambda</span><script type="math/tex">1-\lambda</script></span> 确保能归一化）：</p>
<div>
<div class="MathJax_Preview">
G _ { t } ^ { \lambda } \doteq ( 1 - \lambda ) \sum _ { n = 1 } ^ { \infty } \lambda ^ { n - 1 } G _ { t : t + n }
</div>
<script type="math/tex; mode=display">
G _ { t } ^ { \lambda } \doteq ( 1 - \lambda ) \sum _ { n = 1 } ^ { \infty } \lambda ^ { n - 1 } G _ { t : t + n }
</script>
</div>
<p>其 backup 图如下：</p>
<p><img alt="" src="../imgs/RLAI_12/td-lamb.png" /></p>
<p>将上式提取一部分出来，可写为</p>
<div>
<div class="MathJax_Preview">
G _ { t } ^ { \lambda } = ( 1 - \lambda ) \sum _ { n = 1 } ^ { T - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { T - t - 1 } G _ { t }
</div>
<script type="math/tex; mode=display">
G _ { t } ^ { \lambda } = ( 1 - \lambda ) \sum _ { n = 1 } ^ { T - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { T - t - 1 } G _ { t }
</script>
</div>
<p>观察可知，当 <span><span class="MathJax_Preview">\lambda=1</span><script type="math/tex">\lambda=1</script></span> ，此方法为 MC；当 <span><span class="MathJax_Preview">\lambda=0</span><script type="math/tex">\lambda=0</script></span> ，此方法为 1-step TD。</p>
<p>更一般地，将这个 <span><span class="MathJax_Preview">G_t^\lambda</span><script type="math/tex">G_t^\lambda</script></span> 作为 update target ，此算法称为『<strong>offline <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return algorithm</strong>』，采用半梯度法更新：</p>
<div>
<div class="MathJax_Preview">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G _ { t } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)
</div>
<script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G _ { t } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)
</script>
</div>
<p>下图通过一个实例比较了算法效果：</p>
<p><img alt="" src="../imgs/RLAI_12/offline-lamb-compare.png" /></p>
<p>目前我们讨论的方法都是『<strong>forward views</strong>』算法，在每个 state 处都能得到一些未来的信息，如下面示意图所示。</p>
<p><img alt="" src="../imgs/RLAI_12/forward.png" /></p>
<h2 id="122-tdlambdalambda"><strong>12.2 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>)</strong><a class="headerlink" href="#122-tdlambdalambda" title="Permanent link">&para;</a></h2>
<p>本节介绍的 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 对上一节的 offline <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 有三点提升：</p>
<ul>
<li>单步更新权重向量，无需等待 episode 结束</li>
<li>计算在时间上均匀分布</li>
<li>不仅可用于 episode 问题，还适用于连续问题</li>
</ul>
<p>本节引入 eligibility trace <span><span class="MathJax_Preview">\mathbf{z}_t\in \mathbb{R}^d</span><script type="math/tex">\mathbf{z}_t\in \mathbb{R}^d</script></span> ，他与权向量 <span><span class="MathJax_Preview">\mathbf{w}_t</span><script type="math/tex">\mathbf{w}_t</script></span> 维度相同，权向量有长期的记忆性，其存在时间与系统等长，而 eligibility trace 则体现短期记忆，存在于 episode 内的一个子片段中。</p>
<p>eligibility trace 定义如下：</p>
<div>
<div class="MathJax_Preview">
\begin{array} { l } { \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } } \\ { \mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) , \quad 0 \leq t \leq T } \end{array}
</div>
<script type="math/tex; mode=display">
\begin{array} { l } { \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } } \\ { \mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) , \quad 0 \leq t \leq T } \end{array}
</script>
</div>
<p>eligibility trace 一直在追踪那些对『<strong>recent state valuation</strong>』有贡献的权重分量，这个 recent 体现在系数 <span><span class="MathJax_Preview">\gamma\lambda</span><script type="math/tex">\gamma\lambda</script></span> 上。</p>
<p>在 1-step TD 中，TD error 为</p>
<div>
<div class="MathJax_Preview">
\delta _ { t } \doteq R _ { t + 1 } + \gamma \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)
</div>
<script type="math/tex; mode=display">
\delta _ { t } \doteq R _ { t + 1 } + \gamma \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)
</script>
</div>
<p>更新式为</p>
<div>
<div class="MathJax_Preview">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t }\color{blue}{\nabla\hat{v}(S_t,\mathbf{w}_t)}
</div>
<script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t }\color{blue}{\nabla\hat{v}(S_t,\mathbf{w}_t)}
</script>
</div>
<p>将梯度增加一些信息</p>
<div>
<div class="MathJax_Preview">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t }[\color{blue}{\nabla\hat{v}(S_t,\mathbf{w}_t)+\gamma\lambda\mathbf{z}_{t-1}}]
</div>
<script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t }[\color{blue}{\nabla\hat{v}(S_t,\mathbf{w}_t)+\gamma\lambda\mathbf{z}_{t-1}}]
</script>
</div>
<p>即可得到 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 的更新式</p>
<div>
<div class="MathJax_Preview">
\mathbf { w } _ { t + 1 } \stackrel { \cdot } { = } \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t }
</div>
<script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \stackrel { \cdot } { = } \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t }
</script>
</div>
<p>算法伪代码如下</p>
<p><img alt="" src="../imgs/RLAI_12/td-lamb-code.png" /></p>
<p>TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 是 backward 的，即，每个时刻得到新的 TD error 后，又依据它对之前 states 的 eligibility trace 作一些调整，如下面示意图所示。</p>
<p><img alt="" src="../imgs/RLAI_12/backward.png" /></p>
<p>算法的实际测试效果如下图所示</p>
<p><img alt="" src="../imgs/RLAI_12/td-offline-lamb.png" /></p>
<p>当 <span><span class="MathJax_Preview">\lambda=0</span><script type="math/tex">\lambda=0</script></span> 时，trace 恰好就是 value function 的梯度，此时正好对应 1-step TD ；当 <span><span class="MathJax_Preview">\lambda=1</span><script type="math/tex">\lambda=1</script></span> 时，可以看出每一个 state 都刚好衰减 <span><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span> 倍，跑完这个 episode ，恰好就是 MC 。可以看出，使用了 eligibility trace 后仍能统一地表示各种算法。</p>
<p>若满足条件</p>
<div>
<div class="MathJax_Preview">
\sum _ { n = 1 } ^ { \infty } \alpha _ { n } = \infty \quad \text { and } \quad \sum _ { n = 1 } ^ { \infty } \alpha _ { n } ^ { 2 }&lt; \infty
</div>
<script type="math/tex; mode=display">
\sum _ { n = 1 } ^ { \infty } \alpha _ { n } = \infty \quad \text { and } \quad \sum _ { n = 1 } ^ { \infty } \alpha _ { n } ^ { 2 }< \infty
</script>
</div>
<p>线性 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 可以在 on-policy 下确保收敛，此时有上界</p>
<div>
<div class="MathJax_Preview">
\overline { \mathrm { VE } } \left( \mathbf { w } _ { \infty } \right) \leq \frac { 1 - \gamma \lambda } { 1 - \gamma } \min _ { \mathbf { w } } \overline { \mathrm { VE } } ( \mathbf { w } )
</div>
<script type="math/tex; mode=display">
\overline { \mathrm { VE } } \left( \mathbf { w } _ { \infty } \right) \leq \frac { 1 - \gamma \lambda } { 1 - \gamma } \min _ { \mathbf { w } } \overline { \mathrm { VE } } ( \mathbf { w } )
</script>
</div>
<h2 id="123-n-step-truncated-lambdalambda-return-methods"><strong>12.3 n-step Truncated <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return Methods</strong><a class="headerlink" href="#123-n-step-truncated-lambdalambda-return-methods" title="Permanent link">&para;</a></h2>
<p>前面讲过的 offline <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 是一个重要的概念，但并不实用，因为他需要跑完一整个 episode 才能结束，而在连续型任务中，n 可以无限大，<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 无法计算，因此需要考虑将序列截断，用估计值来替代抛弃掉的较远的 rewards 。</p>
<p>定义 truncated <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 如下：</p>
<div>
<div class="MathJax_Preview">
G _ { t :h } ^ { \lambda } \doteq ( 1 - \lambda ) \sum _ { n = 1 } ^ { h - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { h - t - 1 } G _ { t : h }
</div>
<script type="math/tex; mode=display">
G _ { t :h } ^ { \lambda } \doteq ( 1 - \lambda ) \sum _ { n = 1 } ^ { h - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { h - t - 1 } G _ { t : h }
</script>
</div>
<p>而之前定义的完整的 <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 为：</p>
<div>
<div class="MathJax_Preview">
G _ { t } ^ { \lambda } = ( 1 - \lambda ) \sum _ { n = 1 } ^ { T - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { T - t - 1 } G _ { t }
</div>
<script type="math/tex; mode=display">
G _ { t } ^ { \lambda } = ( 1 - \lambda ) \sum _ { n = 1 } ^ { T - t - 1 } \lambda ^ { n - 1 } G _ { t : t + n } + \lambda ^ { T - t - 1 } G _ { t }
</script>
</div>
<p>对比可知，truncated <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 提前结束了模拟（后面未模拟部分用估计值代替），在此算法中，update 只被延迟了 n 步。称该算法为 truncated TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) ，或 TTD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 。</p>
<p>下面是算法的 backup 示意图：</p>
<p><img alt="" src="../imgs/RLAI_12/ttd.png" /></p>
<p>算法的更新式为</p>
<div>
<div class="MathJax_Preview">
\mathbf { w } _ { t + n } \doteq \mathbf { w } _ { t + n - 1 } + \alpha \left[ G _ { t : t + n } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t + n - 1 } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t + n - 1 } \right)
</div>
<script type="math/tex; mode=display">
\mathbf { w } _ { t + n } \doteq \mathbf { w } _ { t + n - 1 } + \alpha \left[ G _ { t : t + n } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t + n - 1 } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t + n - 1 } \right)
</script>
</div>
<p>其中</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
&amp;G_ { t : t + k } ^ { \lambda } = \hat { v } \left( S _ { t } , \mathbf { w } _ { t - 1 } \right) + \sum _ { i = t } ^ { t + k - 1 } ( \gamma \lambda ) ^ { i - t } \delta _ { i } ^ { \prime }\\
&amp;\delta _ { t } ^ { \prime } \doteq R _ { t + 1 } + \gamma \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t - 1 } \right)
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
&G_ { t : t + k } ^ { \lambda } = \hat { v } \left( S _ { t } , \mathbf { w } _ { t - 1 } \right) + \sum _ { i = t } ^ { t + k - 1 } ( \gamma \lambda ) ^ { i - t } \delta _ { i } ^ { \prime }\\
&\delta _ { t } ^ { \prime } \doteq R _ { t + 1 } + \gamma \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t - 1 } \right)
\end{aligned}
</script>
</div>
<h2 id="124-redoing-updates-the-online-lambdalambda-return-algorithm"><strong>12.4 Redoing Updates: The Online <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return Algorithm</strong><a class="headerlink" href="#124-redoing-updates-the-online-lambdalambda-return-algorithm" title="Permanent link">&para;</a></h2>
<p>实用 truncated TD 涉及到对 n 的平衡，n 越大越接近 offline <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return ，越小则更新速度越快。此平衡是可以达到的，方法是每次获得新数据后，重新从头开始执行所有更新：</p>
<div>
<div class="MathJax_Preview">
\begin{array} { c l }{h = 1 : }&amp;{ \mathbf { w } _ { 1 } ^ { 1 } \doteq \mathbf { w } _ { 0 } ^ { 1 } + \alpha \left[ G _ { 0 : 1 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 1 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 1 } \right)}\\\\{ h = 2 : } &amp; { \mathbf { w } _ { 1 } ^ { 2 } \doteq \mathbf { w } _ { 0 } ^ { 2 } + \alpha \left[ G _ { 0 : 2 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 2 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 2 } \right) } \\ { } &amp; { \mathbf { w } _ { 2 } ^ { 2 } \doteq \mathbf { w } _ { 1 } ^ { 2 } + \alpha \left[ G _ { 1 : 2 } ^ { \lambda } - \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 2 } \right) \right] \nabla \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 2 } \right) }\\\\{ h = 3 :} &amp;{ \mathbf { w } _ { 1 } ^ { 3 } \doteq \mathbf { w } _ { 0 } ^ { 3 } + \alpha \left[ G _ { 0 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 3 } \right) } \\ {}&amp;{ \mathbf { w } _ { 2 } ^ { 3 } \doteq \mathbf { w } _ { 1 } ^ { 3 } + \alpha \left[ G _ { 1 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 3 } \right) } \\{}&amp; { \mathbf { w } _ { 3 } ^ { 3 } \doteq \mathbf { w } _ { 2 } ^ { 3 } + \alpha \left[ G _ { 2 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 2 } , \mathbf { w } _ { 2 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 2 } , \mathbf { w } _ { 2 } ^ { 3 } \right) } \end{array}
</div>
<script type="math/tex; mode=display">
\begin{array} { c l }{h = 1 : }&{ \mathbf { w } _ { 1 } ^ { 1 } \doteq \mathbf { w } _ { 0 } ^ { 1 } + \alpha \left[ G _ { 0 : 1 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 1 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 1 } \right)}\\\\{ h = 2 : } & { \mathbf { w } _ { 1 } ^ { 2 } \doteq \mathbf { w } _ { 0 } ^ { 2 } + \alpha \left[ G _ { 0 : 2 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 2 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 2 } \right) } \\ { } & { \mathbf { w } _ { 2 } ^ { 2 } \doteq \mathbf { w } _ { 1 } ^ { 2 } + \alpha \left[ G _ { 1 : 2 } ^ { \lambda } - \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 2 } \right) \right] \nabla \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 2 } \right) }\\\\{ h = 3 :} &{ \mathbf { w } _ { 1 } ^ { 3 } \doteq \mathbf { w } _ { 0 } ^ { 3 } + \alpha \left[ G _ { 0 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 0 } , \mathbf { w } _ { 0 } ^ { 3 } \right) } \\ {}&{ \mathbf { w } _ { 2 } ^ { 3 } \doteq \mathbf { w } _ { 1 } ^ { 3 } + \alpha \left[ G _ { 1 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 1 } , \mathbf { w } _ { 1 } ^ { 3 } \right) } \\{}& { \mathbf { w } _ { 3 } ^ { 3 } \doteq \mathbf { w } _ { 2 } ^ { 3 } + \alpha \left[ G _ { 2 : 3 } ^ { \lambda } - \hat { v } \left( S _ { 2 } , \mathbf { w } _ { 2 } ^ { 3 } \right) \right] \nabla \hat { v } \left( S _ { 2 } , \mathbf { w } _ { 2 } ^ { 3 } \right) } \end{array}
</script>
</div>
<p>其中 <span><span class="MathJax_Preview">\mathbf{w}_0^h</span><script type="math/tex">\mathbf{w}_0^h</script></span> 都继承自上一个 episode（因此所有的 <span><span class="MathJax_Preview">\mathbf{w}_0^h</span><script type="math/tex">\mathbf{w}_0^h</script></span> 也都为同一值），<span><span class="MathJax_Preview">\mathbf{w}_h^h</span><script type="math/tex">\mathbf{w}_h^h</script></span> 则为每一步的更新结果。</p>
<p>更一般的表示为：</p>
<div>
<div class="MathJax_Preview">
\mathbf { w } _ { t + 1 } ^ { h } \doteq \mathbf { w } _ { t } ^ { h } + \alpha \left[ G _ { t : h } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } ^ { h } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } ^ { h } \right)
</div>
<script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } ^ { h } \doteq \mathbf { w } _ { t } ^ { h } + \alpha \left[ G _ { t : h } ^ { \lambda } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } ^ { h } \right) \right] \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } ^ { h } \right)
</script>
</div>
<p>此算法称为『<strong>online <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return algorithm</strong>』，是完全在线算法，每个时间点 t 均使用已有数据产生一个新权重向量 <span><span class="MathJax_Preview">\mathbf{w}_t</span><script type="math/tex">\mathbf{w}_t</script></span> 。</p>
<p>他在每个时间点 h 都能充分利用上 h 时间之前的所有信息，可以看出现在这种算法对数据的利用率更高，更新效果更好，缺点则为每次均需从头计算，复杂度高。</p>
<p>下面是实际的性能比较：</p>
<p><img alt="" src="../imgs/RLAI_12/on-td-lamb.png" /></p>
<h2 id="125-true-online-tdlambdalambda"><strong>12.5 True Online TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>)</strong><a class="headerlink" href="#125-true-online-tdlambdalambda" title="Permanent link">&para;</a></h2>
<p>online <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 效果很好，但计算复杂度太高，需要考虑利用 eligibility trace 将算法变换为 backward view 算法，这便是本节要讲的『<strong>true online TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>)</strong>』。</p>
<p>之前的 online <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 方法产生的权重序列如下：</p>
<div>
<div class="MathJax_Preview">
\begin{array}{cccccc}
    \mathbf{w}_0^0 &amp;  &amp;  &amp;  &amp;  &amp;  \\
    \mathbf{w}_0^1 &amp; \mathbf{w}_1^1 &amp;  &amp;  &amp;  &amp;  \\
    \mathbf{w}_0^2 &amp; \mathbf{w}_1^2 &amp; \mathbf{w}_2^2 &amp;  &amp;  &amp;  \\
    \mathbf{w}_0^3 &amp; \mathbf{w}_1^3 &amp; \mathbf{w}_2^3 &amp; \mathbf{w}_3^3 &amp;  &amp;  \\
    \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp;  \\
    \mathbf{w}_0^T &amp; \mathbf{w}_1^T &amp; \mathbf{w}_2^T &amp; \mathbf{w}_3^T &amp; \cdots &amp; \mathbf{w}_T^T
\end{array}
</div>
<script type="math/tex; mode=display">
\begin{array}{cccccc}
    \mathbf{w}_0^0 &  &  &  &  &  \\
    \mathbf{w}_0^1 & \mathbf{w}_1^1 &  &  &  &  \\
    \mathbf{w}_0^2 & \mathbf{w}_1^2 & \mathbf{w}_2^2 &  &  &  \\
    \mathbf{w}_0^3 & \mathbf{w}_1^3 & \mathbf{w}_2^3 & \mathbf{w}_3^3 &  &  \\
    \vdots & \vdots & \vdots & \vdots & \ddots &  \\
    \mathbf{w}_0^T & \mathbf{w}_1^T & \mathbf{w}_2^T & \mathbf{w}_3^T & \cdots & \mathbf{w}_T^T
\end{array}
</script>
</div>
<p>事实上，我们需要的只是每行最后一个权重 <span><span class="MathJax_Preview">\mathbf{w}_t^t</span><script type="math/tex">\mathbf{w}_t^t</script></span> ，得到 <span><span class="MathJax_Preview">\mathbf{w}_t=\mathbf{w}_t^t</span><script type="math/tex">\mathbf{w}_t=\mathbf{w}_t^t</script></span> 。</p>
<p>对于 linear case，true online TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 定义如下：</p>
<div>
<div class="MathJax_Preview">
\begin{array}{l}
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t } + \alpha \left( \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } - \mathbf { w } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \left( \mathbf { z } _ { t } - \mathbf { x } _ { t } \right)\\
\mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \left( 1 - \alpha \gamma \lambda \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t }
\end{array}
</div>
<script type="math/tex; mode=display">
\begin{array}{l}
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t } + \alpha \left( \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } - \mathbf { w } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \left( \mathbf { z } _ { t } - \mathbf { x } _ { t } \right)\\
\mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \left( 1 - \alpha \gamma \lambda \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t }
\end{array}
</script>
</div>
<p>此算法可以产生和 online <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 算法一样的结果，空间要求和 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 相同，计算量稍微增加了 50%，但仍为 <span><span class="MathJax_Preview">O(d)</span><script type="math/tex">O(d)</script></span> 复杂度。</p>
<p>这一节 true online TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 使用的 eligibility trace 称为『<strong>dutch trace</strong>』，之前的 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 中则称为『<strong>accumulating trace</strong>』。</p>
<p><img alt="" src="../imgs/RLAI_12/true-td-lamb.png" /></p>
<h2 id="126-dutch-traces-in-monte-carlo-learning"><strong>12.6 Dutch Traces in Monte Carlo Learning</strong><a class="headerlink" href="#126-dutch-traces-in-monte-carlo-learning" title="Permanent link">&para;</a></h2>
<p>尽管 eligibility trace 于 TD 方法结合紧密，但他们本质上并无联系，事实上，eligibility trace 起源于 MC learning ，下面用一个例子简单介绍一下。</p>
<p>线性情况下，梯度 MC 法的更新式如下：</p>
<div>
<div class="MathJax_Preview">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } \right] \mathbf { x } _ { t }
</div>
<script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } \right] \mathbf { x } _ { t }
</script>
</div>
<p>为了简化问题，这里的 return <span><span class="MathJax_Preview">G</span><script type="math/tex">G</script></span> 只是 episode 结束后得到的单个 reward（因此没有下标），并且没有做 discounting 。想要做的优化就是，在 episode 每一步都进行一些计算，但仍只在 episode 结束后才进行更新，所以复杂度仍为 <span><span class="MathJax_Preview">O(d)</span><script type="math/tex">O(d)</script></span>。算法如下：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned} \mathbf { w } _ { T } &amp; = \mathbf { w } _ { T - 1 } + \alpha \left( G - \mathbf { w } _ { T - 1 } ^ { \top } \mathbf { x } _ { T - 1 } \right) \mathbf { x } _ { T - 1 } \\ &amp; = \mathbf { w } _ { T - 1 } + \alpha \mathbf { x } _ { T - 1 } \left( - \mathbf { x } _ { T - 1 } ^ { \top } \mathbf { w } _ { T - 1 } \right) + \alpha G \mathbf { x } _ { T - 1 } \\ &amp; = \left( \mathbf { I } - \alpha \mathbf { x } _ { T - 1 } \mathbf { x } _ { T - 1 } ^ { \top } \right) \mathbf { w } _ { T - 1 } + \alpha G \mathbf { x } _ { T - 1 } \\ &amp; = \mathbf { F } _ { T - 1 } \mathbf { w } _ { T - 1 } + \alpha G \mathbf { x } _ { T - 1 } \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf { w } _ { T } & = \mathbf { w } _ { T - 1 } + \alpha \left( G - \mathbf { w } _ { T - 1 } ^ { \top } \mathbf { x } _ { T - 1 } \right) \mathbf { x } _ { T - 1 } \\ & = \mathbf { w } _ { T - 1 } + \alpha \mathbf { x } _ { T - 1 } \left( - \mathbf { x } _ { T - 1 } ^ { \top } \mathbf { w } _ { T - 1 } \right) + \alpha G \mathbf { x } _ { T - 1 } \\ & = \left( \mathbf { I } - \alpha \mathbf { x } _ { T - 1 } \mathbf { x } _ { T - 1 } ^ { \top } \right) \mathbf { w } _ { T - 1 } + \alpha G \mathbf { x } _ { T - 1 } \\ & = \mathbf { F } _ { T - 1 } \mathbf { w } _ { T - 1 } + \alpha G \mathbf { x } _ { T - 1 } \end{aligned}
</script>
</div>
<p>这里引入 <span><span class="MathJax_Preview">\mathbf { F } _ { t } \doteq \mathbf { I } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top }</span><script type="math/tex">\mathbf { F } _ { t } \doteq \mathbf { I } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top }</script></span> 称为 遗忘矩阵（or 衰退矩阵），接上式，下面进行递归</p>
<div>
<div class="MathJax_Preview">
\begin{array} { l } { = \mathbf { F } _ { T - 1 } \left( \mathbf { F } _ { T - 2 } \mathbf { w } _ { T - 2 } + \alpha G \mathbf { x } _ { T - 2 } \right) + \alpha G \mathbf { x } _ { T - 1 } } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { w } _ { T - 2 } + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \left( \mathbf { F } _ { T - 3 } \mathbf { w } _ { T - 3 } + \alpha G \mathbf { x } _ { T - 3 } \right) + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { F } _ { T - 3 } \mathbf { W } _ { T - 3 } + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { x } _ { T - 3 } + \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) }
\\\vdots\\
= \underbrace { \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \cdots \mathbf { F } _ { 0 } \mathbf { w } _ { 0 } } _ { \mathbf { a } _ { T - 1 } } + \alpha G \underbrace {\sum _ { k = 0 } ^ { T - 1 } \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k }}_{\mathbf{z}_{T-1}}\\
= \mathbf { a } _ { T - 1 } + \alpha G \mathbf { z } _ { T - 1 }
\end{array}
</div>
<script type="math/tex; mode=display">
\begin{array} { l } { = \mathbf { F } _ { T - 1 } \left( \mathbf { F } _ { T - 2 } \mathbf { w } _ { T - 2 } + \alpha G \mathbf { x } _ { T - 2 } \right) + \alpha G \mathbf { x } _ { T - 1 } } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { w } _ { T - 2 } + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \left( \mathbf { F } _ { T - 3 } \mathbf { w } _ { T - 3 } + \alpha G \mathbf { x } _ { T - 3 } \right) + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) } \\ { = \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { F } _ { T - 3 } \mathbf { W } _ { T - 3 } + \alpha G \left( \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \mathbf { x } _ { T - 3 } + \mathbf { F } _ { T - 1 } \mathbf { x } _ { T - 2 } + \mathbf { x } _ { T - 1 } \right) }
\\\vdots\\
= \underbrace { \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \cdots \mathbf { F } _ { 0 } \mathbf { w } _ { 0 } } _ { \mathbf { a } _ { T - 1 } } + \alpha G \underbrace {\sum _ { k = 0 } ^ { T - 1 } \mathbf { F } _ { T - 1 } \mathbf { F } _ { T - 2 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k }}_{\mathbf{z}_{T-1}}\\
= \mathbf { a } _ { T - 1 } + \alpha G \mathbf { z } _ { T - 1 }
\end{array}
</script>
</div>
<p>其中 <span><span class="MathJax_Preview">\mathbf{a}_{T-1}, \mathbf{z}_{T-1}</span><script type="math/tex">\mathbf{a}_{T-1}, \mathbf{z}_{T-1}</script></span> 是 T-1 时刻的两个辅助记忆向量，即使不知道 G ，也能在每步先做一些这样的计算，用以存储一些信息。</p>
<p>事实上，<span><span class="MathJax_Preview">\mathbf{z}_t</span><script type="math/tex">\mathbf{z}_t</script></span> 是一个 dutch-style eligibility trace，初始值为 <span><span class="MathJax_Preview">\mathbf{z}_0=\mathbf{x}_0</span><script type="math/tex">\mathbf{z}_0=\mathbf{x}_0</script></span> ，他的更新式为：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned} \mathbf { z } _ { t } &amp; \doteq \sum _ { k = 0 } ^ { t } \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } , \quad 1 \leq t &lt; T \\ &amp; = \sum _ { k = 0 } ^ { t - 1 } \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } + \mathbf { x } _ { t } \\ &amp; = \mathbf { F } _ { t } \sum _ { k = 0 } ^ { t - 1 } \mathbf { F } _ { t - 1 } \mathbf { F } _ { t - 2 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } + \mathbf { x } _ { t } \\
  &amp;= \mathbf { F } _ { t } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t }  \\ &amp; = \left( \mathbf { I } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \right) \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t }  \\ &amp; = \mathbf { z } _ { t - 1 } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t }  \\ &amp; = \mathbf { z } _ { t - 1 } - \alpha \left( \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t } + \mathbf { x } _ { t }  \\ &amp; = \mathbf { z } _ { t - 1 } + \left( 1 - \alpha \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t }
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf { z } _ { t } & \doteq \sum _ { k = 0 } ^ { t } \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } , \quad 1 \leq t < T \\ & = \sum _ { k = 0 } ^ { t - 1 } \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } + \mathbf { x } _ { t } \\ & = \mathbf { F } _ { t } \sum _ { k = 0 } ^ { t - 1 } \mathbf { F } _ { t - 1 } \mathbf { F } _ { t - 2 } \cdots \mathbf { F } _ { k + 1 } \mathbf { x } _ { k } + \mathbf { x } _ { t } \\
  &= \mathbf { F } _ { t } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t }  \\ & = \left( \mathbf { I } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \right) \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t }  \\ & = \mathbf { z } _ { t - 1 } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t }  \\ & = \mathbf { z } _ { t - 1 } - \alpha \left( \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t } + \mathbf { x } _ { t }  \\ & = \mathbf { z } _ { t - 1 } + \left( 1 - \alpha \mathbf { z } _ { t - 1 } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t }
\end{aligned}
</script>
</div>
<p>辅助向量 <span><span class="MathJax_Preview">\mathbf{a}_t</span><script type="math/tex">\mathbf{a}_t</script></span> 初始值为 <span><span class="MathJax_Preview">\mathbf{a}_0=\mathbf{w}_0</span><script type="math/tex">\mathbf{a}_0=\mathbf{w}_0</script></span> ，更新式为</p>
<div>
<div class="MathJax_Preview">
\mathbf { a } _ { t } \doteq \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { 0 } \mathbf { w } _ { 0 } = \mathbf { F } _ { t } \mathbf { a } _ { t - 1 } = \mathbf { a } _ { t - 1 } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \mathbf { a } _ { t - 1 }
</div>
<script type="math/tex; mode=display">
\mathbf { a } _ { t } \doteq \mathbf { F } _ { t } \mathbf { F } _ { t - 1 } \cdots \mathbf { F } _ { 0 } \mathbf { w } _ { 0 } = \mathbf { F } _ { t } \mathbf { a } _ { t - 1 } = \mathbf { a } _ { t - 1 } - \alpha \mathbf { x } _ { t } \mathbf { x } _ { t } ^ { \top } \mathbf { a } _ { t - 1 }
</script>
</div>
<p>在 t &lt; T 时，每步更新辅助向量 <span><span class="MathJax_Preview">\mathbf{a}_t,\mathbf{z}_t</span><script type="math/tex">\mathbf{a}_t,\mathbf{z}_t</script></span> ，当 T 时刻获得 G 后再最终计算出 <span><span class="MathJax_Preview">\mathbf{w}_T</span><script type="math/tex">\mathbf{w}_T</script></span>。得到的结果和 MC 相同，但计算更简单。</p>
<p>本例说明了 eligibility trace 并不局限于 TD 方法，只要想做长期预测，都可以采用 eligibility trace 。</p>
<h2 id="127-sarsalambdalambda"><strong>12.7 Sarsa(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>)</strong><a class="headerlink" href="#127-sarsalambdalambda" title="Permanent link">&para;</a></h2>
<p>这一节把 eligibility trace 从 state-value 扩展到 action-value，只需简单地将 <span><span class="MathJax_Preview">\hat{v}(s,\mathbf{w})</span><script type="math/tex">\hat{v}(s,\mathbf{w})</script></span> 变为 <span><span class="MathJax_Preview">\hat{q}(s,a,\mathbf{w})</span><script type="math/tex">\hat{q}(s,a,\mathbf{w})</script></span> 。</p>
<p>action-value 形式的 n-step return 为：</p>
<div>
<div class="MathJax_Preview">
G _ { t : t + n } \doteq R _ { t + 1 } + \cdots + \gamma ^ { n - 1 } R _ { t + n } + \gamma ^ { n } \hat { q } \left( S _ { t + n } , A _ { t + n } , \mathbf { w } _ { t + n - 1 } \right)
</div>
<script type="math/tex; mode=display">
G _ { t : t + n } \doteq R _ { t + 1 } + \cdots + \gamma ^ { n - 1 } R _ { t + n } + \gamma ^ { n } \hat { q } \left( S _ { t + n } , A _ { t + n } , \mathbf { w } _ { t + n - 1 } \right)
</script>
</div>
<p>利用这个 return ，可以根据前面公式构造 action-value 形式的 truncated <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return <span><span class="MathJax_Preview">G_t^\lambda</span><script type="math/tex">G_t^\lambda</script></span> ，进而得到 action-value 形式的 offline <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 算法：</p>
<div>
<div class="MathJax_Preview">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G _ { t } ^ { \lambda } - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) \right] \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
</div>
<script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \left[ G _ { t } ^ { \lambda } - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) \right] \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
</script>
</div>
<p>算法示意图如下：</p>
<p><img alt="" src="../imgs/RLAI_12/sarsa-lamb.png" /></p>
<p>Sarsa(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 和 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 相似，更新式为</p>
<div>
<div class="MathJax_Preview">
\begin{array}{l}
\mathbf { w } _ { t + 1 } \stackrel { \cdot } { = } \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t }\\
\delta _ { t } \doteq R _ { t + 1 } + \gamma \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)\\
{ \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } } \\ { \mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) }
\end{array}
</div>
<script type="math/tex; mode=display">
\begin{array}{l}
\mathbf { w } _ { t + 1 } \stackrel { \cdot } { = } \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t }\\
\delta _ { t } \doteq R _ { t + 1 } + \gamma \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)\\
{ \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } } \\ { \mathbf { z } _ { t } \doteq \gamma \lambda \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) }
\end{array}
</script>
</div>
<p>算法伪码如下：</p>
<p><img alt="" src="../imgs/RLAI_12/sarsa-lamb-code.png" /></p>
<p>该算法与传统的 n-step sarsa 效果对比如下：</p>
<p><img alt="" src="../imgs/RLAI_12/sarsa-lamb-vs-n-sarsa.png" /></p>
<p>上面是 offline <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 算法，下面介绍 action-value 的 online <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 算法。</p>
<p><img alt="" src="../imgs/RLAI_12/online-sarsa-lamb-code.png" /></p>
<p>本节算法之间的比较：</p>
<p><img alt="" src="../imgs/RLAI_12/true-ol-sarsa-lamb-vs-sarsa-lamb.png" /></p>
<h2 id="128-variable-lambdalambda-and-gammagamma"><strong>12.8 Variable <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span> and <span><span class="MathJax_Preview">\gamma​</span><script type="math/tex">\gamma​</script></span></strong><a class="headerlink" href="#128-variable-lambdalambda-and-gammagamma" title="Permanent link">&para;</a></h2>
<p>为了更泛化地表示每一步中 bootstrapping 和 discounting 的程度，需要更通用的 <span><span class="MathJax_Preview">\lambda,\gamma</span><script type="math/tex">\lambda,\gamma</script></span> ，现定义函数 <span><span class="MathJax_Preview">\lambda : \mathcal{S} \times \mathcal { A } \rightarrow [ 0,1 ]</span><script type="math/tex">\lambda : \mathcal{S} \times \mathcal { A } \rightarrow [ 0,1 ]</script></span> 和 <span><span class="MathJax_Preview">\gamma : \mathcal{S} \rightarrow [ 0,1 ]</span><script type="math/tex">\gamma : \mathcal{S} \rightarrow [ 0,1 ]</script></span> ，从而得到 <span><span class="MathJax_Preview">\lambda _ { t } \doteq \lambda \left( S _ { t } , A _ { t } \right),\gamma _ { t } \doteq \gamma \left( S _ { t } \right)</span><script type="math/tex">\lambda _ { t } \doteq \lambda \left( S _ { t } , A _ { t } \right),\gamma _ { t } \doteq \gamma \left( S _ { t } \right)</script></span> 。</p>
<p>函数 <span><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span> 称为『<strong>termination function</strong>』，现在重新定义 return ：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned} G _ { t } &amp; \doteq R _ { t + 1 } + \gamma _ { t + 1 } G _ { t + 1 } \\ &amp; = R _ { t + 1 } + \gamma _ { t + 1 } R _ { t + 2 } + \gamma _ { t + 1 } \gamma _ { t + 2 } R _ { t + 3 } + \gamma _ { t + 1 } \gamma _ { t + 2 } \gamma _ { t + 3 } R _ { t + 4 } + \cdots \\ &amp; = \sum _ { k = t } ^ { \infty } \left( \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \right) R _ { k + 1 } \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} G _ { t } & \doteq R _ { t + 1 } + \gamma _ { t + 1 } G _ { t + 1 } \\ & = R _ { t + 1 } + \gamma _ { t + 1 } R _ { t + 2 } + \gamma _ { t + 1 } \gamma _ { t + 2 } R _ { t + 3 } + \gamma _ { t + 1 } \gamma _ { t + 2 } \gamma _ { t + 3 } R _ { t + 4 } + \cdots \\ & = \sum _ { k = t } ^ { \infty } \left( \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \right) R _ { k + 1 } \end{aligned}
</script>
</div>
<p>为保证结果有限，需要 <span><span class="MathJax_Preview">\prod _ { k = t } ^ { \infty } \gamma _ { k } = 0</span><script type="math/tex">\prod _ { k = t } ^ { \infty } \gamma _ { k } = 0</script></span> 。</p>
<p>这种形式的好处是，episodic 任务无需再指定开始状态和结束状态，只需使 <span><span class="MathJax_Preview">\gamma(s)=0</span><script type="math/tex">\gamma(s)=0</script></span> 即可，因此便能统一 episodic 和 discounted-continuing 。</p>
<p>上面说了对 discounting 的泛化，下面再介绍对 bootstrapping 的泛化。</p>
<p>若考虑对 state-value 做 bootstrap ，则泛化参数记为 <span><span class="MathJax_Preview">\lambda_s</span><script type="math/tex">\lambda_s</script></span> ，同理若对 action-value 做 bootstrap ，则泛化参数记为 <span><span class="MathJax_Preview">\lambda_a</span><script type="math/tex">\lambda_a</script></span>（<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span> 控制了 bootstrap 的程度，当为 1 时完全不做 bootstrap ，当为 0 时则完全是在 bootstrap ）。于是可以得到新的<strong>递归</strong>形式的 state-based <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return ：</p>
<div>
<div class="MathJax_Preview">
G _ { t } ^ { \lambda s } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda s } \right)
</div>
<script type="math/tex; mode=display">
G _ { t } ^ { \lambda s } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda s } \right)
</script>
</div>
<p>或是 action-based <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return ：</p>
<div>
<div class="MathJax_Preview">
G _ { t } ^ { \lambda a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda a } \right)
</div>
<script type="math/tex; mode=display">
G _ { t } ^ { \lambda a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda a } \right)
</script>
</div>
<p>或者 Expected Sarsa 形式：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
&amp;G _ { t } ^ { \lambda a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda a } \right)\\
&amp;\overline { V } _ { t } ( s ) \doteq \sum _ { a } \pi ( a | s ) \hat { q } \left( s , a , \mathbf { w } _ { t } \right)
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
&G _ { t } ^ { \lambda a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda a } \right)\\
&\overline { V } _ { t } ( s ) \doteq \sum _ { a } \pi ( a | s ) \hat { q } \left( s , a , \mathbf { w } _ { t } \right)
\end{aligned}
</script>
</div>
<h2 id="129-off-policy-traces-with-control-variates"><strong>12.9 Off-policy Traces with Control Variates</strong><a class="headerlink" href="#129-off-policy-traces-with-control-variates" title="Permanent link">&para;</a></h2>
<p>本节主要将 importance sampling 整合进算法。这里采用第 7 章的 per-decision 方法，定义如下的 <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return ：</p>
<div>
<div class="MathJax_Preview">
G _ { t } ^ { \lambda s } \doteq \rho _ { t } \left( R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda s } \right) \right) + \left( 1 - \rho _ { t } \right) \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)
</div>
<script type="math/tex; mode=display">
G _ { t } ^ { \lambda s } \doteq \rho _ { t } \left( R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) + \lambda _ { t + 1 } G _ { t + 1 } ^ { \lambda s } \right) \right) + \left( 1 - \rho _ { t } \right) \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)
</script>
</div>
<p>他的 truncated 形式可由 state-based TD error 逼近得到：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
&amp;\delta _ { t } ^ { s } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)\\
&amp;G _ { t } ^ { \lambda s } \approx \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) + \rho _ { t } \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i }
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
&\delta _ { t } ^ { s } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \hat { v } \left( S _ { t + 1 } , \mathbf { w } _ { t } \right) - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right)\\
&G _ { t } ^ { \lambda s } \approx \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) + \rho _ { t } \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i }
\end{aligned}
</script>
</div>
<p>通过上面形式的 <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return ，可以方便地进行 forward-view 更新</p>
<div>
<div class="MathJax_Preview">
\begin{aligned} \mathbf { w } _ { t + 1 } &amp; = \mathbf { w } _ { t } + \alpha \left( G _ { t } ^ { \lambda s } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right) \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \\ &amp; \approx \mathbf { w } _ { t } + \alpha \rho _ { t } \left( \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \right) \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf { w } _ { t + 1 } & = \mathbf { w } _ { t } + \alpha \left( G _ { t } ^ { \lambda s } - \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right) \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \\ & \approx \mathbf { w } _ { t } + \alpha \rho _ { t } \left( \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \right) \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \end{aligned}
</script>
</div>
<p>下面探究 forward view 和 backward view 的近似关系。对整个 forward view 过程进行求和，得到：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned} \sum _ { t = 1 } ^ { \infty } \left( \mathbf { w } _ { t + 1 } - \mathbf { w } _ { t } \right) &amp; \approx \sum _ { t = 1 } ^ { \infty } \sum _ { k = t } ^ { \infty } \alpha \rho _ { t } \delta _ { k } ^ { s } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ &amp; = \sum _ { k = 1 } ^ { \infty } \sum _ { t = 1 } ^ { k } \alpha \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ &amp; = \sum _ { k = 1 } ^ { \infty } \alpha \delta _ { k } ^ { s } \sum _ { t = 1 } ^ { k } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} \sum _ { t = 1 } ^ { \infty } \left( \mathbf { w } _ { t + 1 } - \mathbf { w } _ { t } \right) & \approx \sum _ { t = 1 } ^ { \infty } \sum _ { k = t } ^ { \infty } \alpha \rho _ { t } \delta _ { k } ^ { s } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ & = \sum _ { k = 1 } ^ { \infty } \sum _ { t = 1 } ^ { k } \alpha \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \delta _ { k } ^ { s } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ & = \sum _ { k = 1 } ^ { \infty } \alpha \delta _ { k } ^ { s } \sum _ { t = 1 } ^ { k } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \end{aligned}
</script>
</div>
<p>其中第二个等号用到了一个求和规则：</p>
<div>
<div class="MathJax_Preview">
\sum _ { t = x } ^ { y } \sum _ { k = t } ^ { y } = \sum _ { k = x } ^ { y } \sum _ { t = x } ^ { k }
</div>
<script type="math/tex; mode=display">
\sum _ { t = x } ^ { y } \sum _ { k = t } ^ { y } = \sum _ { k = x } ^ { y } \sum _ { t = x } ^ { k }
</script>
</div>
<p>若上式的第二个求和项可写作 eligibility trace 并用于更新，则更新式变为 backward view TD update 。即，若表达式为 k 时刻的 trace，那他可由 k-1 时刻的值更新而得：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned} \mathbf { z } _ { k } &amp; = \sum _ { t = 1 } ^ { k } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ &amp; = \sum _ { t = 1 } ^ { k - 1 } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } + \rho _ { k } \nabla \hat { v } \left( S _ { k } , \mathbf { w } _ { k } \right) \\ &amp; = \gamma _ { k } \lambda _ { k } \rho _ { k } \underbrace{\sum _ { t = 1 } ^ { k - 1 } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k - 1 } \gamma _ { i } \lambda _ { i } \rho _ { i }}_{\mathbf{z}_{k-1}} +\rho_k\nabla\hat{v}(S_k,\mathbf{w}_k)\\ &amp; = \rho _ { k } \left( \gamma _ { k } \lambda _ { k } \mathbf { z } _ { k - 1 } + \nabla \hat { v } \left( S _ { k } , \mathbf { w } _ { k } \right) \right) \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf { z } _ { k } & = \sum _ { t = 1 } ^ { k } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } \\ & = \sum _ { t = 1 } ^ { k - 1 } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i } + \rho _ { k } \nabla \hat { v } \left( S _ { k } , \mathbf { w } _ { k } \right) \\ & = \gamma _ { k } \lambda _ { k } \rho _ { k } \underbrace{\sum _ { t = 1 } ^ { k - 1 } \rho _ { t } \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \prod _ { i = t + 1 } ^ { k - 1 } \gamma _ { i } \lambda _ { i } \rho _ { i }}_{\mathbf{z}_{k-1}} +\rho_k\nabla\hat{v}(S_k,\mathbf{w}_k)\\ & = \rho _ { k } \left( \gamma _ { k } \lambda _ { k } \mathbf { z } _ { k - 1 } + \nabla \hat { v } \left( S _ { k } , \mathbf { w } _ { k } \right) \right) \end{aligned}
</script>
</div>
<p>整理即得</p>
<div>
<div class="MathJax_Preview">
\mathbf { z } _ { t } \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right)
</div>
<script type="math/tex; mode=display">
\mathbf { z } _ { t } \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + \nabla \hat { v } \left( S _ { t } , \mathbf { w } _ { t } \right) \right)
</script>
</div>
<p>这个 eligibility trace 结合 半梯度 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 更新即为一般的 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 算法（<span><span class="MathJax_Preview">\rho_t=1</span><script type="math/tex">\rho_t=1</script></span> 时对应 on-policy）。在 off-policy 情况下，算法性能还不错，但是作为一个半梯度算法，稳定性欠佳（后面几节会考虑扩展此算法来保证稳定性）。</p>
<p>对于 action-value 情况的算法，其实和 state-value 情况类似，现构造一个 action-based <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return ：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned} G _ { t } ^ { \lambda a } &amp; \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \left[ \rho _ { t + 1 } G _ { t + 1 } ^ { \lambda a } + \overline { V } _ { t } \left( S _ { t + 1 } \right) - \rho _ { t + 1 } \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right] \right) \\ &amp; = R _ { t + 1 } + \gamma _ { t + 1 } \left( \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \rho _ { t + 1 } \left[ G _ { t + 1 } ^ { \lambda a } - \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right] \right) \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} G _ { t } ^ { \lambda a } & \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \left[ \rho _ { t + 1 } G _ { t + 1 } ^ { \lambda a } + \overline { V } _ { t } \left( S _ { t + 1 } \right) - \rho _ { t + 1 } \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right] \right) \\ & = R _ { t + 1 } + \gamma _ { t + 1 } \left( \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \rho _ { t + 1 } \left[ G _ { t + 1 } ^ { \lambda a } - \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right] \right) \end{aligned}
</script>
</div>
<p>其中</p>
<div>
<div class="MathJax_Preview">
\overline { V } _ { t } ( s ) \doteq \sum _ { a } \pi ( a | s ) \hat { q } \left( s , a , \mathbf { w } _ { t } \right)
</div>
<script type="math/tex; mode=display">
\overline { V } _ { t } ( s ) \doteq \sum _ { a } \pi ( a | s ) \hat { q } \left( s , a , \mathbf { w } _ { t } \right)
</script>
</div>
<p>同样又基于 action-based TD error 来逼近 <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return ：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
&amp;G _ { t } ^ { \lambda a } \approx \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) + \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { a } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i }\\
&amp;\delta _ { t } ^ { a } = R _ { t + 1 } + \gamma _ { t + 1 } \overline { V } _ { t } \left( S _ { t + 1 } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
&G _ { t } ^ { \lambda a } \approx \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) + \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { a } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \rho _ { i }\\
&\delta _ { t } ^ { a } = R _ { t + 1 } + \gamma _ { t + 1 } \overline { V } _ { t } \left( S _ { t + 1 } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
\end{aligned}
</script>
</div>
<p>然后做类似变换，得到 eligibility trace for action values：</p>
<div>
<div class="MathJax_Preview">
\mathbf { z } _ { t } \doteq \gamma _ { t } \lambda _ { t } \rho _ { t } \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
</div>
<script type="math/tex; mode=display">
\mathbf { z } _ { t } \doteq \gamma _ { t } \lambda _ { t } \rho _ { t } \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
</script>
</div>
<p>将其用于半梯度更新可得到更一般的 Sarsa(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) ，同样可通用于 on-policy 和 off-policy 。</p>
<p><span><span class="MathJax_Preview">\lambda=1</span><script type="math/tex">\lambda=1</script></span> 时，目前这些算法和 MC 联系密切，而 <span><span class="MathJax_Preview">\lambda&lt;1</span><script type="math/tex">\lambda<1</script></span> 时，上面所有的 off-policy 算法都将面临 11 章提到过的『<strong>致命三因素（the deadly triad）</strong>』—— approximation、bootstrapping、off-policy 。</p>
<h2 id="1210-watkinss-qlambdalambda-to-tree-backuplambdalambda"><strong>12.10 Watkins's Q(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) to Tree-Backup(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>)</strong><a class="headerlink" href="#1210-watkinss-qlambdalambda-to-tree-backuplambdalambda" title="Permanent link">&para;</a></h2>
<p>近些年提出了很多在 Q-learning 上使用 eligibility trace 的扩展算法，最早的便是 Watkins's Q(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) ：若采取 greedy action，则照常对 eligibility trace 进行衰退，否则，就将首个 non-greedy action 之后的 traces 重置为 0 。算法的 backup 示意图如下：</p>
<p><img alt="" src="../imgs/RLAI_12/watkins.png" /></p>
<p>第 7 章介绍过无需 importance sampling 的 n-step tree backup 算法，下面将 eligibility trace 结合于其中，称为 Tree-Backup(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 或 TB(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 算法，示意图如下：</p>
<p><img alt="" src="../imgs/RLAI_12/tb-lamb.png" /></p>
<p>该算法的 <span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>-return 为使用 action values 的递归式：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned} G _ { t } ^ { \lambda a } &amp; \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \left[ \sum _ { a \neq A _ { t + 1 } } \pi ( a | S _ { t + 1 } ) \hat { q } \left( S _ { t + 1 } , a , \mathbf { w } _ { t } \right) + \pi \left( A _ { t + 1 } | S _ { t + 1 } \right) G _ { t + 1 } ^ { \lambda a } \right] \right) \\ &amp; = R _ { t + 1 } + \gamma _ { t + 1 } \left( \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \pi \left( A _ { t + 1 } | S _ { t + 1 } \right) \left( G _ { t + 1 } ^ { \lambda a } - \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right) \right) \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} G _ { t } ^ { \lambda a } & \doteq R _ { t + 1 } + \gamma _ { t + 1 } \left( \left( 1 - \lambda _ { t + 1 } \right) \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \left[ \sum _ { a \neq A _ { t + 1 } } \pi ( a | S _ { t + 1 } ) \hat { q } \left( S _ { t + 1 } , a , \mathbf { w } _ { t } \right) + \pi \left( A _ { t + 1 } | S _ { t + 1 } \right) G _ { t + 1 } ^ { \lambda a } \right] \right) \\ & = R _ { t + 1 } + \gamma _ { t + 1 } \left( \overline { V } _ { t } \left( S _ { t + 1 } \right) + \lambda _ { t + 1 } \pi \left( A _ { t + 1 } | S _ { t + 1 } \right) \left( G _ { t + 1 } ^ { \lambda a } - \hat { q } \left( S _ { t + 1 } , A _ { t + 1 } , \mathbf { w } _ { t } \right) \right) \right) \end{aligned}
</script>
</div>
<p>再对 return 做逼近：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
&amp;\delta _ { t } ^ { a } = R _ { t + 1 } + \gamma _ { t + 1 } \overline { V } _ { t } \left( S _ { t + 1 } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)\\
&amp;G _ { t } ^ { \lambda a } \approx \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) + \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { a } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \pi \left( A _ { i } | S _ { i } \right)
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
&\delta _ { t } ^ { a } = R _ { t + 1 } + \gamma _ { t + 1 } \overline { V } _ { t } \left( S _ { t + 1 } \right) - \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)\\
&G _ { t } ^ { \lambda a } \approx \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right) + \sum _ { k = t } ^ { \infty } \delta _ { k } ^ { a } \prod _ { i = t + 1 } ^ { k } \gamma _ { i } \lambda _ { i } \pi \left( A _ { i } | S _ { i } \right)
\end{aligned}
</script>
</div>
<p>最后得到 eligibility trace update：</p>
<div>
<div class="MathJax_Preview">
\mathbf { z } _ { t } \doteq \gamma _ { t } \lambda _ { t } \pi \left( A _ { t } | S _ { t } \right) \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
</div>
<script type="math/tex; mode=display">
\mathbf { z } _ { t } \doteq \gamma _ { t } \lambda _ { t } \pi \left( A _ { t } | S _ { t } \right) \mathbf { z } _ { t - 1 } + \nabla \hat { q } \left( S _ { t } , A _ { t } , \mathbf { w } _ { t } \right)
</script>
</div>
<p>再利用更新规则</p>
<div>
<div class="MathJax_Preview">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t }
</div>
<script type="math/tex; mode=display">
\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t }
</script>
</div>
<p>组成了完整的 TB(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 算法。该算法依然不稳定，同样需要结合后面的方法。</p>
<h2 id="1211-stable-off-policy-methods-with-traces"><strong>12.11 Stable Off-policy Methods with Traces</strong><a class="headerlink" href="#1211-stable-off-policy-methods-with-traces" title="Permanent link">&para;</a></h2>
<p>前面几节中的一些 eligibility trace 方法是可以在 off-policy 中取得稳定解的，这一节介绍四种最为重要的使用了 bootstrapping 和 discounting 的函数，他们的思想都基于 11 章中的 Gradient-TD、Emphatic-TD。下面的算法都假定了<strong>线性</strong>函数逼近这一前提（至于非线性，理论上也能做相似的处理），符号若无特殊说明，都和前面相同。</p>
<h3 id="1-gtdlambdalambda-tdc-eligibility-trace">(1) GTD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) ：TDC 算法的 eligibility trace 形式<a class="headerlink" href="#1-gtdlambdalambda-tdc-eligibility-trace" title="Permanent link">&para;</a></h3>
<p>目标：学习 <span><span class="MathJax_Preview">\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</span><script type="math/tex">\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</script></span> ，更新式如下：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
&amp;\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { s } \mathbf { z } _ { t } - \alpha \gamma _ { t + 1 } \left( 1 - \lambda _ { t + 1 } \right) \left( \mathbf { z } _ { t } ^ { \top } \mathbf { v } _ { t } \right) \mathbf { x } _ { t + 1 }\\
&amp;\mathbf { v } _ { t + 1 } \doteq \mathbf { v } _ { t } + \beta \delta _ { t } ^ { s } \mathbf { z } _ { t } - \beta \left( \mathbf { v } _ { t } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t }
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
&\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { s } \mathbf { z } _ { t } - \alpha \gamma _ { t + 1 } \left( 1 - \lambda _ { t + 1 } \right) \left( \mathbf { z } _ { t } ^ { \top } \mathbf { v } _ { t } \right) \mathbf { x } _ { t + 1 }\\
&\mathbf { v } _ { t + 1 } \doteq \mathbf { v } _ { t } + \beta \delta _ { t } ^ { s } \mathbf { z } _ { t } - \beta \left( \mathbf { v } _ { t } ^ { \top } \mathbf { x } _ { t } \right) \mathbf { x } _ { t }
\end{aligned}
</script>
</div>
<h3 id="2-gqlambdalambda-gradient-td-action-value-eligibility-trace">(2) GQ(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) ：Gradient-TD 算法（action-value）的 eligibility trace 形式<a class="headerlink" href="#2-gqlambdalambda-gradient-td-action-value-eligibility-trace" title="Permanent link">&para;</a></h3>
<p>目标：学习 <span><span class="MathJax_Preview">\hat { q } \left( s , a , \mathbf { w } _ { t } \right) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s , a ) \approx q _ { \pi } ( s , a )</span><script type="math/tex">\hat { q } \left( s , a , \mathbf { w } _ { t } \right) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s , a ) \approx q _ { \pi } ( s , a )</script></span> ，更新式如下：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
&amp;\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { a } \mathbf { z } _ { t } - \alpha \gamma _ { t + 1 } \left( 1 - \lambda _ { t + 1 } \right) \left( \mathbf { z } _ { t } ^ { \top } \mathbf { v } _ { t } \right) \overline { \mathbf { x } } _ { t + 1 }\\
&amp;\overline { \mathbf { x } } _ { t } \doteq \sum _ { a } \pi ( a | S _ { t } ) \mathbf { x } \left( S _ { t } , a \right)\\
&amp;\delta _ { t } ^ { a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \mathbf { w } _ { t } ^ { \top } \overline { \mathbf { x } } _ { t + 1 } - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t }
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
&\mathbf { w } _ { t + 1 } \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { a } \mathbf { z } _ { t } - \alpha \gamma _ { t + 1 } \left( 1 - \lambda _ { t + 1 } \right) \left( \mathbf { z } _ { t } ^ { \top } \mathbf { v } _ { t } \right) \overline { \mathbf { x } } _ { t + 1 }\\
&\overline { \mathbf { x } } _ { t } \doteq \sum _ { a } \pi ( a | S _ { t } ) \mathbf { x } \left( S _ { t } , a \right)\\
&\delta _ { t } ^ { a } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \mathbf { w } _ { t } ^ { \top } \overline { \mathbf { x } } _ { t + 1 } - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t }
\end{aligned}
</script>
</div>
<h3 id="3-htdlambdalambda-gtdlambdalambda-tdlambdalambda">(3) HTD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) ：由 GTD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 和 TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) 的结合算法<a class="headerlink" href="#3-htdlambdalambda-gtdlambdalambda-tdlambdalambda" title="Permanent link">&para;</a></h3>
<p>目标：学习 <span><span class="MathJax_Preview">\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</span><script type="math/tex">\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</script></span> ，更新式如下：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned} \mathbf { w } _ { t + 1 } &amp; \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { s } \mathbf { z } _ { t } + \alpha \left( \left( \mathbf { z } _ { t } - \mathbf { z } _ { t } ^ { b } \right) ^ { \top } \mathbf { v } _ { t } \right) \left( \mathbf { x } _ { t } - \gamma _ { t + 1 } \mathbf { x } _ { t + 1 } \right) \\ \mathbf { v } _ { t + 1 } &amp; \doteq \mathbf { v } _ { t } + \beta \delta _ { t } ^ { s } \mathbf { z } _ { t } - \beta \left( \mathbf { z } _ { t } ^ { b ^\top } \mathbf { v } _ { t } \right) \left( \mathbf { x } _ { t } - \gamma _ { t + 1 } \mathbf { x } _ { t + 1 } \right) , \quad \text { with } \mathbf { v } _ { 0 } \doteq \mathbf { 0 } \\ \mathbf { z } _ { t } &amp; \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t } \right) , \quad \text { with } \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } \\ \mathbf { z } _ { t } ^ { b } &amp; \doteq \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } ^ { b } + \mathbf { x } _ { t } , \quad \text { with } \mathbf { z } _ { - 1 } ^ { b } \doteq \mathbf { 0 } \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf { w } _ { t + 1 } & \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } ^ { s } \mathbf { z } _ { t } + \alpha \left( \left( \mathbf { z } _ { t } - \mathbf { z } _ { t } ^ { b } \right) ^ { \top } \mathbf { v } _ { t } \right) \left( \mathbf { x } _ { t } - \gamma _ { t + 1 } \mathbf { x } _ { t + 1 } \right) \\ \mathbf { v } _ { t + 1 } & \doteq \mathbf { v } _ { t } + \beta \delta _ { t } ^ { s } \mathbf { z } _ { t } - \beta \left( \mathbf { z } _ { t } ^ { b ^\top } \mathbf { v } _ { t } \right) \left( \mathbf { x } _ { t } - \gamma _ { t + 1 } \mathbf { x } _ { t + 1 } \right) , \quad \text { with } \mathbf { v } _ { 0 } \doteq \mathbf { 0 } \\ \mathbf { z } _ { t } & \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + \mathbf { x } _ { t } \right) , \quad \text { with } \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } \\ \mathbf { z } _ { t } ^ { b } & \doteq \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } ^ { b } + \mathbf { x } _ { t } , \quad \text { with } \mathbf { z } _ { - 1 } ^ { b } \doteq \mathbf { 0 } \end{aligned}
</script>
</div>
<h3 id="4-emphatic-tdlambdalambda-emphatic-td-eligibility-trace">(4) Emphatic TD(<span><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span>) ：Emphatic TD 的 eligibility trace 形式<a class="headerlink" href="#4-emphatic-tdlambdalambda-emphatic-td-eligibility-trace" title="Permanent link">&para;</a></h3>
<p>目标：学习 <span><span class="MathJax_Preview">\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</span><script type="math/tex">\hat { v } ( s , \mathbf { w } ) \doteq \mathbf { w } _ { t } ^ { \top } \mathbf { x } ( s ) \approx v _ { \pi } ( s )</script></span> ，此算法在 off-policy 下收敛性很强（代价是高方差、慢速），允许任何程度的 bootstrapping 。更新式如下：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned} &amp;\mathbf { w } _ { t + 1 }  \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t } \\ &amp;\delta _ { t } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t + 1 } - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } \\ &amp; \mathbf { z } _ { t } \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + M _ { t } \mathbf { x } _ { t } \right) , \text { with } \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } \\&amp; M _ { t } \doteq \lambda _ { t } I _ { t } + \left( 1 - \lambda _ { t } \right) F _ { t } \\ &amp;F _ { t } \doteq  \rho _ { t - 1 } \gamma _ { t } F _ { t - 1 } + I _ { t } , \quad \text { with } F _ { 0 } \doteq i \left( S _ { 0 } \right) \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} &\mathbf { w } _ { t + 1 }  \doteq \mathbf { w } _ { t } + \alpha \delta _ { t } \mathbf { z } _ { t } \\ &\delta _ { t } \doteq R _ { t + 1 } + \gamma _ { t + 1 } \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t + 1 } - \mathbf { w } _ { t } ^ { \top } \mathbf { x } _ { t } \\ & \mathbf { z } _ { t } \doteq \rho _ { t } \left( \gamma _ { t } \lambda _ { t } \mathbf { z } _ { t - 1 } + M _ { t } \mathbf { x } _ { t } \right) , \text { with } \mathbf { z } _ { - 1 } \doteq \mathbf { 0 } \\& M _ { t } \doteq \lambda _ { t } I _ { t } + \left( 1 - \lambda _ { t } \right) F _ { t } \\ &F _ { t } \doteq  \rho _ { t - 1 } \gamma _ { t } F _ { t - 1 } + I _ { t } , \quad \text { with } F _ { 0 } \doteq i \left( S _ { 0 } \right) \end{aligned}
</script>
</div>
<p>其中，</p>
<ul>
<li><span><span class="MathJax_Preview">M_t\geq0</span><script type="math/tex">M_t\geq0</script></span> ：emphasis</li>
<li><span><span class="MathJax_Preview">F_t\geq0</span><script type="math/tex">F_t\geq0</script></span> ：followon trace</li>
<li><span><span class="MathJax_Preview">I_t\geq 0</span><script type="math/tex">I_t\geq 0</script></span> ：interest</li>
</ul>
<h2 id="1212-implementation-issues"><strong>12.12 Implementation Issues</strong><a class="headerlink" href="#1212-implementation-issues" title="Permanent link">&para;</a></h2>
<p>看起来 eligibility trace 比 one-step 方法更复杂，因为他需要在每个时间点对所有状态做更新。但其实执行起来并不是什么大问题，因为实际中绝大多数 state 的 trace 都为 0，只有少量最近经历过的 state 的trace 大于 0 ，所以也只需做少量更新。</p>
<p>在有函数逼近的情况下，不使用 eligibility trace 的方法的计算优势有所下降，尤其是当使用了神经网络，使用 trace 时的内存和计算力的消耗只是原来的两倍。</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../RLAI_11/" title="Chapter 11" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Chapter 11
              </span>
            </div>
          </a>
        
        
          <a href="../RLAI_13/" title="Chapter 13" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Chapter 13
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2016-2020 ZHANGWP
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../../../assets/fonts/font-awesome.css">
    
      <a href="https://github.com/zawnpn" class="md-footer-social__link fa fa-github"></a>
    
      <a href="https://twitter.com/zawnpn" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://psnprofiles.com/zawnpn" class="md-footer-social__link fa fa-trophy"></a>
    
      <a href="https://steamcommunity.com/id/zawnpn/" class="md-footer-social__link fa fa-steam"></a>
    
      <a href="https://www.zhihu.com/people/zhangwanpeng" class="md-footer-social__link fa fa-globe"></a>
    
  </div>

      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../../assets/javascripts/application.583bbe55.js"></script>
      
        
        
          
          <script src="../../../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../../../../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../../../../assets/javascripts/lunr/lunr.jp.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../../.."}})</script>
      
        <script src="../../../../assets/extra.js"></script>
      
        <script src="//cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_SVG"></script>
      
    
    
      
    
  </body>
</html>