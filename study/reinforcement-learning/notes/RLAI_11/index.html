



<!DOCTYPE html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Welcome to zawnpn's blog.">
      
      
        <link rel="canonical" href="https://oncemath.com/study/reinforcement-learning/notes/RLAI_11/">
      
      
        <meta name="author" content="zawnpn">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="/assets/images/all_inclusive.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-3.0.4">
    
    
      
        <title>Chapter 11 - ONCE.MATH</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/application.451f80e5.css">
      
        <link rel="stylesheet" href="../../../../assets/stylesheets/application-palette.22915126.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
      <script src="../../../../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
    
    <link rel="stylesheet" href="../../../../assets/fonts/material-icons.css">
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="white" data-md-color-accent="light-blue">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="../../../../#-" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://oncemath.com" title="ONCE.MATH" class="md-header-nav__button md-logo">
          
            <i class="md-icon">all_inclusive</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                ONCE.MATH
              </span>
              <span class="md-header-nav__topic">
                Chapter 11
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/zawnpn/ONCEMATH/" title="前往 Github 仓库" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../.." title="Home" class="md-tabs__link">
          Home
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../" title="Study" class="md-tabs__link md-tabs__link--active">
          Study
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../../projects/" title="Projects" class="md-tabs__link">
          Projects
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../../notes/" title="Notes" class="md-tabs__link">
          Notes
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../../math/" title="Math" class="md-tabs__link">
          Math
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../../diary/" title="Diary" class="md-tabs__link">
          Diary
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../../share/" title="Share" class="md-tabs__link">
          Share
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../../../about/" title="About" class="md-tabs__link">
          About
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://oncemath.com" title="ONCE.MATH" class="md-nav__button md-logo">
      
        <i class="md-icon">all_inclusive</i>
      
    </a>
    ONCE.MATH
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/zawnpn/ONCEMATH/" title="前往 Github 仓库" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      Home
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        Home
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../.." title="主页" class="md-nav__link">
      主页
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../links/" title="友情链接" class="md-nav__link">
      友情链接
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../donates/" title="打赏" class="md-nav__link">
      打赏
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Study
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Study
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../" title="My Study" class="md-nav__link">
      My Study
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-2" type="checkbox" id="nav-2-2" checked>
    
    <label class="md-nav__link" for="nav-2-2">
      Reinforcement
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-2">
        Reinforcement
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-2-1" type="checkbox" id="nav-2-2-1" checked>
    
    <label class="md-nav__link" for="nav-2-2-1">
      Reinforcement Learning An Introduction
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-2-2-1">
        Reinforcement Learning An Introduction
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_2/" title="Chapter 2" class="md-nav__link">
      Chapter 2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_3/" title="Chapter 3" class="md-nav__link">
      Chapter 3
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_4/" title="Chapter 4" class="md-nav__link">
      Chapter 4
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_5/" title="Chapter 5" class="md-nav__link">
      Chapter 5
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_6/" title="Chapter 6" class="md-nav__link">
      Chapter 6
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_7/" title="Chapter 7" class="md-nav__link">
      Chapter 7
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_8/" title="Chapter 8" class="md-nav__link">
      Chapter 8
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_9/" title="Chapter 9" class="md-nav__link">
      Chapter 9
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_10/" title="Chapter 10" class="md-nav__link">
      Chapter 10
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Chapter 11
      </label>
    
    <a href="./" title="Chapter 11" class="md-nav__link md-nav__link--active">
      Chapter 11
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#111-semi-gradient-methods" title="11.1 Semi-gradient Methods" class="md-nav__link">
    11.1 Semi-gradient Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#semi-gradient-off-policy-td0" title="semi-gradient off-policy TD(0)" class="md-nav__link">
    semi-gradient off-policy TD(0)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#semi-gradient-expected-sarsa" title="semi-gradient Expected Sarsa" class="md-nav__link">
    semi-gradient Expected Sarsa
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n-step-semi-gradient-expected-sarsa" title="n-step semi-gradient Expected Sarsa" class="md-nav__link">
    n-step semi-gradient Expected Sarsa
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n-step-semi-gradient-tree-backup" title="n-step semi-gradient tree-backup" class="md-nav__link">
    n-step semi-gradient tree-backup
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#112-examples-of-off-policy-divergence" title="11.2 Examples of Off-policy Divergence" class="md-nav__link">
    11.2 Examples of Off-policy Divergence
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#113-the-deadly-triad" title="11.3 The Deadly Triad" class="md-nav__link">
    11.3 The Deadly Triad
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#114-linear-value-function-geometry" title="11.4 Linear Value-function Geometry" class="md-nav__link">
    11.4 Linear Value-function Geometry
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#115-gradient-descent-in-the-bellman-error" title="11.5 Gradient Descent in the Bellman Error" class="md-nav__link">
    11.5 Gradient Descent in the Bellman Error
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#116-the-bellman-error-is-not-learnable" title="11.6 The Bellman Error is Not Learnable" class="md-nav__link">
    11.6 The Bellman Error is Not Learnable
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#117-gradient-td-methods" title="11.7 Gradient-TD Methods" class="md-nav__link">
    11.7 Gradient-TD Methods
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#118-emphatic-td-methods" title="11.8 Emphatic-TD Methods" class="md-nav__link">
    11.8 Emphatic-TD Methods
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#119-reducing-variance" title="11.9 Reducing Variance" class="md-nav__link">
    11.9 Reducing Variance
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../RLAI_12/" title="Chapter 12" class="md-nav__link">
      Chapter 12
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-2-2" type="checkbox" id="nav-2-2-2">
    
    <label class="md-nav__link" for="nav-2-2-2">
      Some Introduction
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-2-2-2">
        Some Introduction
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../MCTS_introduction/" title="MCTS" class="md-nav__link">
      MCTS
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Projects
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Projects
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../projects/" title="My Projects" class="md-nav__link">
      My Projects
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../projects/FFT-GPU-Accel/" title="基于GPU的快速傅里叶变换并行化加速" class="md-nav__link">
      基于GPU的快速傅里叶变换并行化加速
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-3" type="checkbox" id="nav-3-3">
    
    <label class="md-nav__link" for="nav-3-3">
      Steam-Toolkit
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-3">
        Steam-Toolkit
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../projects/steam-market-price-bot/" title="Steam市场比价爬虫" class="md-nav__link">
      Steam市场比价爬虫
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-4" type="checkbox" id="nav-3-4">
    
    <label class="md-nav__link" for="nav-3-4">
      NKU-Toolkit
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-4">
        NKU-Toolkit
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../projects/nku-eamis/" title="NKU-EAMIS工具" class="md-nav__link">
      NKU-EAMIS工具
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../projects/nku-sms-rss/" title="NKU-SMS-RSS" class="md-nav__link">
      NKU-SMS-RSS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../projects/eamis-miniapp/" title="NKU-EAMIS_MiniApp(南开大学教务助手小程序)" class="md-nav__link">
      NKU-EAMIS_MiniApp(南开大学教务助手小程序)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../projects/eamis-workflow/" title="NKU-EAMIS for iOS(Workflow)" class="md-nav__link">
      NKU-EAMIS for iOS(Workflow)
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Notes
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        Notes
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../notes/" title="My Notes" class="md-nav__link">
      My Notes
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../notes/to-do/" title="To Do" class="md-nav__link">
      To Do
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../notes/python/" title="Python" class="md-nav__link">
      Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../notes/data-processing/" title="Data Processing" class="md-nav__link">
      Data Processing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../notes/linux/" title="Linux" class="md-nav__link">
      Linux
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Math
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Math
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/" title="Math Experience" class="md-nav__link">
      Math Experience
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-2" type="checkbox" id="nav-5-2">
    
    <label class="md-nav__link" for="nav-5-2">
      数学建模
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-2">
        数学建模
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/2017-mcm-icm/" title="2017美赛参赛整理(Problem D)" class="md-nav__link">
      2017美赛参赛整理(Problem D)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/2016-guosai/" title="2016数学建模国赛" class="md-nav__link">
      2016数学建模国赛
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/math-model-szb/" title="数学建模之2016深圳杯——初次尝试" class="md-nav__link">
      数学建模之2016深圳杯——初次尝试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/polygon-to-ellipse/" title="随机多边形转化为椭圆的过程研究" class="md-nav__link">
      随机多边形转化为椭圆的过程研究
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-3" type="checkbox" id="nav-5-3">
    
    <label class="md-nav__link" for="nav-5-3">
      NKU 数院试题整理
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-3">
        NKU 数院试题整理
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-3-1" type="checkbox" id="nav-5-3-1">
    
    <label class="md-nav__link" for="nav-5-3-1">
      分析
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-3-1">
        分析
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/functional-analysis-final/" title="2017-2018第一学期泛函分析期末考试" class="md-nav__link">
      2017-2018第一学期泛函分析期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/real-variable-function/" title="2016-2017第二学期实变函数期末考试" class="md-nav__link">
      2016-2017第二学期实变函数期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/mathematical-analysis-3-3-final/" title="2016-2017第一学期数学分析3-3期末考试" class="md-nav__link">
      2016-2017第一学期数学分析3-3期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/complex-analysis-final/" title="2016-2017第一学期复变函数期末考试" class="md-nav__link">
      2016-2017第一学期复变函数期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/mathematical-analysis-3-3-middle/" title="2016-2017第一学期数学分析3-3期中考试" class="md-nav__link">
      2016-2017第一学期数学分析3-3期中考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/mathematical-analysis-3-2-final/" title="2015-2016第二学期数学分析3-2期末考试（含解答）" class="md-nav__link">
      2015-2016第二学期数学分析3-2期末考试（含解答）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/mathematical-analysis-3-2-middle/" title="2015-2016第二学期数学分析3-2期中考试" class="md-nav__link">
      2015-2016第二学期数学分析3-2期中考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/mathematical-analysis-3-1-final/" title="2015-2016第一学期数学分析3-1期末考试" class="md-nav__link">
      2015-2016第一学期数学分析3-1期末考试
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-3-2" type="checkbox" id="nav-5-3-2">
    
    <label class="md-nav__link" for="nav-5-3-2">
      代数
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-3-2">
        代数
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/abstract-algebra-final/" title="2016-2017第一学期抽象代数期末考试" class="md-nav__link">
      2016-2017第一学期抽象代数期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/abstract-algebra-middle/" title="2016-2017第一学期抽象代数期中考试" class="md-nav__link">
      2016-2017第一学期抽象代数期中考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/advanced-algebra-2-2-final/" title="2015-2016第二学期高等代数2-2期末考试" class="md-nav__link">
      2015-2016第二学期高等代数2-2期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/advanced-algebra-2-2-middle/" title="2015-2016第二学期高等代数2-2期中考试" class="md-nav__link">
      2015-2016第二学期高等代数2-2期中考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/advanced-algebra-2-1-final/" title="2015-2016第一学期高等代数2-1期末考试" class="md-nav__link">
      2015-2016第一学期高等代数2-1期末考试
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-3-3" type="checkbox" id="nav-5-3-3">
    
    <label class="md-nav__link" for="nav-5-3-3">
      概率统计
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-3-3">
        概率统计
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/probability-final/" title="2016-2017第二学期概率论期末考试" class="md-nav__link">
      2016-2017第二学期概率论期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/probability-middle/" title="2016-2017第二学期概率论期中考试" class="md-nav__link">
      2016-2017第二学期概率论期中考试
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-3-4" type="checkbox" id="nav-5-3-4">
    
    <label class="md-nav__link" for="nav-5-3-4">
      微分方程
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-3-4">
        微分方程
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/PDE-final/" title="2017-2018第一学期数理方程期末考试" class="md-nav__link">
      2017-2018第一学期数理方程期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/ODE-final/" title="2016-2017第一学期常微分方程期末考试" class="md-nav__link">
      2016-2017第一学期常微分方程期末考试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../math/exam/ODE-middle/" title="2016-2017第一学期常微分方程期中考试" class="md-nav__link">
      2016-2017第一学期常微分方程期中考试
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      Diary
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        Diary
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../diary/" title="My Diary" class="md-nav__link">
      My Diary
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../diary/game-play/" title="游戏记录 & 简评" class="md-nav__link">
      游戏记录 & 简评
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../diary/roc-fly/" title="鹏程万里" class="md-nav__link">
      鹏程万里
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../diary/blog-history/" title="博客历史" class="md-nav__link">
      博客历史
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      Share
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        Share
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/" title="Share" class="md-nav__link">
      Share
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/nku-sms-exams/" title="NKU 数院试题整理" class="md-nav__link">
      NKU 数院试题整理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/my-postgraduate-share/" title="保研推免经验分享 - 数学系跨保 CS" class="md-nav__link">
      保研推免经验分享 - 数学系跨保 CS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../share/github-student-pack/" title="Student Developer Pack - GitHub Education" class="md-nav__link">
      Student Developer Pack - GitHub Education
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-8" type="checkbox" id="nav-8">
    
    <label class="md-nav__link" for="nav-8">
      About
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-8">
        About
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../../about/" title="About Me" class="md-nav__link">
      About Me
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#111-semi-gradient-methods" title="11.1 Semi-gradient Methods" class="md-nav__link">
    11.1 Semi-gradient Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#semi-gradient-off-policy-td0" title="semi-gradient off-policy TD(0)" class="md-nav__link">
    semi-gradient off-policy TD(0)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#semi-gradient-expected-sarsa" title="semi-gradient Expected Sarsa" class="md-nav__link">
    semi-gradient Expected Sarsa
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n-step-semi-gradient-expected-sarsa" title="n-step semi-gradient Expected Sarsa" class="md-nav__link">
    n-step semi-gradient Expected Sarsa
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n-step-semi-gradient-tree-backup" title="n-step semi-gradient tree-backup" class="md-nav__link">
    n-step semi-gradient tree-backup
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#112-examples-of-off-policy-divergence" title="11.2 Examples of Off-policy Divergence" class="md-nav__link">
    11.2 Examples of Off-policy Divergence
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#113-the-deadly-triad" title="11.3 The Deadly Triad" class="md-nav__link">
    11.3 The Deadly Triad
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#114-linear-value-function-geometry" title="11.4 Linear Value-function Geometry" class="md-nav__link">
    11.4 Linear Value-function Geometry
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#115-gradient-descent-in-the-bellman-error" title="11.5 Gradient Descent in the Bellman Error" class="md-nav__link">
    11.5 Gradient Descent in the Bellman Error
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#116-the-bellman-error-is-not-learnable" title="11.6 The Bellman Error is Not Learnable" class="md-nav__link">
    11.6 The Bellman Error is Not Learnable
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#117-gradient-td-methods" title="11.7 Gradient-TD Methods" class="md-nav__link">
    11.7 Gradient-TD Methods
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#118-emphatic-td-methods" title="11.8 Emphatic-TD Methods" class="md-nav__link">
    11.8 Emphatic-TD Methods
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#119-reducing-variance" title="11.9 Reducing Variance" class="md-nav__link">
    11.9 Reducing Variance
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/zawnpn/ONCEMATH/edit/master/docs/study/reinforcement-learning/notes/RLAI_11.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="-">强化学习导论（十一）- 离线策略的近似方法<a class="headerlink" href="#-" title="Permanent link">&para;</a></h1>
<p>前两章（9、10 章）已经讲了on-policy 情形下对于函数近似的拓展，本章继续讲解 off-policy 下对函数近似的拓展，但是这个拓展比on-policy时更难更不同。</p>
<p>在第六第七章中讲到的 off-policy 方法可以拓展到函数近似的情况下，但是这些方法在半梯度法下不能像在 on-policy 下一样良好地收敛。</p>
<p>Off-policy 在函数逼近时有两大难点：</p>
<ol>
<li>
<p>update target 发生变化。这个问题之前已通过 importance sampling 解决。</p>
</li>
<li>
<p>update distribution 发生变化，已不再是原先的 on-policy distribution。</p>
</li>
</ol>
<p>要解决上述的第二个难点，有两种方法：</p>
<ul>
<li>通过之前讲的 importance sampling 将 update distribution 转变为 on-policy distribution 。</li>
<li>提出一种不依赖任何特定分布的 true gradient 方法。</li>
</ul>
<h2 id="111-semi-gradient-methods"><strong>11.1 Semi-gradient Methods</strong><a class="headerlink" href="#111-semi-gradient-methods" title="Permanent link">&para;</a></h2>
<p>这一节主要目的是将 off-policy 下的查表法改造为梯度 / 半梯度法，主要针对第一个难点（变化的 update target）。大多数情况下，这个方法表现良好，少数情况存在发散的情况。</p>
<p>这些算法大多数采用了『<strong>单步重要性比例</strong>』：</p>
<div>
<div class="MathJax_Preview">
\rho_t\doteq\rho_{t:t}=\frac{\pi(A_t|S_t)}{b(A_t|S_t)}
</div>
<script type="math/tex; mode=display">
\rho_t\doteq\rho_{t:t}=\frac{\pi(A_t|S_t)}{b(A_t|S_t)}
</script>
</div>
<h3 id="semi-gradient-off-policy-td0"><strong>semi-gradient off-policy TD(0)</strong><a class="headerlink" href="#semi-gradient-off-policy-td0" title="Permanent link">&para;</a></h3>
<div>
<div class="MathJax_Preview">
\mathbf{w}_{t+1}\doteq\mathbf{w}_t+\alpha\rho_t\delta_t\nabla\hat{v}(S_t,\mathbf{w}_t)
</div>
<script type="math/tex; mode=display">
\mathbf{w}_{t+1}\doteq\mathbf{w}_t+\alpha\rho_t\delta_t\nabla\hat{v}(S_t,\mathbf{w}_t)
</script>
</div>
<p>其中</p>
<ul>
<li>episodic and discounted problem:</li>
</ul>
<div>
<div class="MathJax_Preview">
\delta_t\doteq R_{t+1}+\gamma\hat{v}(S_{t+1},\mathbf{w}_t)-\hat{v}(S_t,\mathbf{w}_t)
</div>
<script type="math/tex; mode=display">
\delta_t\doteq R_{t+1}+\gamma\hat{v}(S_{t+1},\mathbf{w}_t)-\hat{v}(S_t,\mathbf{w}_t)
</script>
</div>
<ul>
<li>continuing and undiscounted problem:</li>
</ul>
<div>
<div class="MathJax_Preview">
\delta_t\doteq R_{t+1}-\bar{R}_t+\hat{v}(S_{t+1},\mathbf{w}_t)-\hat{v}(S_t,\mathbf{w}_t)
</div>
<script type="math/tex; mode=display">
\delta_t\doteq R_{t+1}-\bar{R}_t+\hat{v}(S_{t+1},\mathbf{w}_t)-\hat{v}(S_t,\mathbf{w}_t)
</script>
</div>
<h3 id="semi-gradient-expected-sarsa"><strong>semi-gradient Expected Sarsa</strong><a class="headerlink" href="#semi-gradient-expected-sarsa" title="Permanent link">&para;</a></h3>
<div>
<div class="MathJax_Preview">
\mathbf{w}_{t+1}\doteq\mathbf{w}_t+\alpha\delta_t\nabla\hat{q}(S_t,A_t,\mathbf{w}_t)
</div>
<script type="math/tex; mode=display">
\mathbf{w}_{t+1}\doteq\mathbf{w}_t+\alpha\delta_t\nabla\hat{q}(S_t,A_t,\mathbf{w}_t)
</script>
</div>
<p>其中</p>
<ul>
<li>episodic and discounted problem:</li>
</ul>
<div>
<div class="MathJax_Preview">
\delta_t\doteq R_{t+1}+\gamma\sum_a\pi(a|S_{t+1})\hat{q}(S_{t+1},a,\mathbf{w}_t)-\hat{q}(S_t,A_t,\mathbf{w}_t)
</div>
<script type="math/tex; mode=display">
\delta_t\doteq R_{t+1}+\gamma\sum_a\pi(a|S_{t+1})\hat{q}(S_{t+1},a,\mathbf{w}_t)-\hat{q}(S_t,A_t,\mathbf{w}_t)
</script>
</div>
<ul>
<li>continuing and undiscounted problem:</li>
</ul>
<div>
<div class="MathJax_Preview">
\delta_t\doteq R_{t+1}-\bar{R}_t+\sum_a\pi(a|S_{t+1})\hat{q}(S_{t+1},a,\mathbf{w}_t)-\hat{q}(S_t,A_t,\mathbf{w}_t)
</div>
<script type="math/tex; mode=display">
\delta_t\doteq R_{t+1}-\bar{R}_t+\sum_a\pi(a|S_{t+1})\hat{q}(S_{t+1},a,\mathbf{w}_t)-\hat{q}(S_t,A_t,\mathbf{w}_t)
</script>
</div>
<p>这里梯度更新并未使用 importance sampling ，后面会解释。</p>
<p>上面都是针对单步算法，而对于多步算法，无论是 state value 还是 action value ，都需要做 importance sampling 。</p>
<h3 id="n-step-semi-gradient-expected-sarsa"><strong>n-step semi-gradient Expected Sarsa</strong><a class="headerlink" href="#n-step-semi-gradient-expected-sarsa" title="Permanent link">&para;</a></h3>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\mathbf{w}_{t+n}&amp;\doteq\mathbf{w}_{t+n-1}+\alpha\prod_{k=t+1}^{t+n}\rho_k\delta_{t:t+n}\nabla\hat{q}(S_t,A_t,\mathbf{w}_{t+n-1})\\
\delta_{t:t+n}&amp;\doteq G_{t:t+n}-\hat{q}(S_t,A_t,\mathbf{w}_{t+n-1})
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{w}_{t+n}&\doteq\mathbf{w}_{t+n-1}+\alpha\prod_{k=t+1}^{t+n}\rho_k\delta_{t:t+n}\nabla\hat{q}(S_t,A_t,\mathbf{w}_{t+n-1})\\
\delta_{t:t+n}&\doteq G_{t:t+n}-\hat{q}(S_t,A_t,\mathbf{w}_{t+n-1})
\end{aligned}
</script>
</div>
<p>其中</p>
<ul>
<li>episodic and discounted problem:</li>
</ul>
<div>
<div class="MathJax_Preview">
G_{t:t+n}\doteq R_{t+1}+\cdots+\gamma^{n-1}R_{t+n}+\gamma^n\hat{q}(S_{t+n},A_{t+n},\mathbf{w}_{t+n-1})
</div>
<script type="math/tex; mode=display">
G_{t:t+n}\doteq R_{t+1}+\cdots+\gamma^{n-1}R_{t+n}+\gamma^n\hat{q}(S_{t+n},A_{t+n},\mathbf{w}_{t+n-1})
</script>
</div>
<ul>
<li>continuing and undiscounted problem:</li>
</ul>
<div>
<div class="MathJax_Preview">
G_{t:t+n}\doteq R_{t+1}-\bar{R}_t+\cdots+R_{t+n}-\bar{R}_{t+n-1}+\hat{q}(S_{t+n},A_{t+n},\mathbf{w}_{t+n-1})
</div>
<script type="math/tex; mode=display">
G_{t:t+n}\doteq R_{t+1}-\bar{R}_t+\cdots+R_{t+n}-\bar{R}_{t+n-1}+\hat{q}(S_{t+n},A_{t+n},\mathbf{w}_{t+n-1})
</script>
</div>
<h3 id="n-step-semi-gradient-tree-backup"><strong>n-step semi-gradient tree-backup</strong><a class="headerlink" href="#n-step-semi-gradient-tree-backup" title="Permanent link">&para;</a></h3>
<p>第七章还讲过一种不需要 importance sampling 的算法：tree-backup 算法，其半梯度法如下：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\mathbf{w}_{t+n}&amp;\doteq\mathbf{w}_{t+n-1}+\alpha[G_{t:t+n}-\hat{q}(S_t,A_t,\mathbf{w}_{t+n-1})]\nabla\hat{q}(S_t,A_t,\mathbf{w}_{t+n-1})\\
G_{t:t+n}&amp;\doteq\hat{q}(S_t,A_t,\mathbf{w}_{t-1})+\sum_{k=t}^{t+n-1}\delta_k\prod_{i=t+1}^k\gamma\pi(A_i|S_i)
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{w}_{t+n}&\doteq\mathbf{w}_{t+n-1}+\alpha[G_{t:t+n}-\hat{q}(S_t,A_t,\mathbf{w}_{t+n-1})]\nabla\hat{q}(S_t,A_t,\mathbf{w}_{t+n-1})\\
G_{t:t+n}&\doteq\hat{q}(S_t,A_t,\mathbf{w}_{t-1})+\sum_{k=t}^{t+n-1}\delta_k\prod_{i=t+1}^k\gamma\pi(A_i|S_i)
\end{aligned}
</script>
</div>
<h2 id="112-examples-of-off-policy-divergence"><strong>11.2 Examples of Off-policy Divergence</strong><a class="headerlink" href="#112-examples-of-off-policy-divergence" title="Permanent link">&para;</a></h2>
<p>从本节开始讨论第二类难点，也就是 update distribution 不再是 on-policy distribution 。本节主要是讲了 off-policy 下使用半梯度法导致不稳定或不收敛的反例。</p>
<p>例子的具体情况略过，其结论是，参数 <span><span class="MathJax_Preview">\mathbf{w}</span><script type="math/tex">\mathbf{w}</script></span> 更新的稳定性与步长参数 <span><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span> 无关，只需大于 0 即可，而其值的大小只影响参数 <span><span class="MathJax_Preview">\mathbf{w}</span><script type="math/tex">\mathbf{w}</script></span> 发散的速度，而非是否发散。</p>
<p>本例的一个特殊点是，它一直在重复一个状态转移来更新 <span><span class="MathJax_Preview">\mathbf{w}</span><script type="math/tex">\mathbf{w}</script></span> （这也是实际中可能发生的情况），因为 behavior policy 可能会选择 target policy 永远不会选择的那些 action（此时 <span><span class="MathJax_Preview">\rho_t=0</span><script type="math/tex">\rho_t=0</script></span> ，权重得不到更新）。</p>
<p>还有一个反例——Baird's counterexmaple ，这个例子主要是在说，bootstrapping 和 semi gradient 在非 on-policy 下结合时，会导致发散。</p>
<p>Q-learning 往往是收敛性最好的算法，但仍有使用 Q-learning 也发散的反例，一个解决方案是使 behavior policy 与 target policy 尽量<strong>接近</strong>（比如将 behavior policy 设为 target policy 的 <span><span class="MathJax_Preview">\varepsilon</span><script type="math/tex">\varepsilon</script></span>-greedy policy ）。</p>
<h2 id="113-the-deadly-triad"><strong>11.3 The Deadly Triad</strong><a class="headerlink" href="#113-the-deadly-triad" title="Permanent link">&para;</a></h2>
<p>上一节对存在不稳定性的情况举了例子，本节再来做一个归纳总结。</p>
<p>导致不稳定性有三个主要因素，称其为『<strong>致命三因素</strong>（The Deadly Triad）』：</p>
<ol>
<li>Function Approximation</li>
<li>Bootstrapping</li>
<li>Off-policy training</li>
</ol>
<p>结论：『<strong>当三者同时出现，会导致系统不稳定；只出现两个时则可避免不稳定性。</strong>』</p>
<p>关于三者的取舍情况，首先 function approximation <strong>最需要保留</strong>，他能够使我们的算法得到足够的<strong>扩展和延伸</strong>，变得更有<strong>泛化能力</strong>。</p>
<p>而 bootstrapping 是可以考虑放弃掉的，但代价是牺牲<strong>计算效率和数据利用率</strong>（bootstrapping 可以利用终止状态之前的数据来进行中途学习，所以效率高）。</p>
<p>最后， off-policy 能够将行为从目标函数分隔开，能够带来一定程度上的便利，但并非是必须的。不过若想要『<strong>并行学习</strong>』，则一定要使用 off-policy 。</p>
<h2 id="114-linear-value-function-geometry"><strong>11.4 Linear Value-function Geometry</strong><a class="headerlink" href="#114-linear-value-function-geometry" title="Permanent link">&para;</a></h2>
<p>为了更好理解 off-policy learning 的一些问题，考虑对函数逼近做一些抽象的分析。</p>
<p>设状态空间中的 state-value function 为映射 <span><span class="MathJax_Preview">v:S\to R</span><script type="math/tex">v:S\to R</script></span> （大部分的 v 函数并没有具体意义，即不对应任何具体的 policy ） 。</p>
<p>记状态空间为 <span><span class="MathJax_Preview">\mathcal S=\{s_1,s_2,\ldots,s_{|\mathcal S|}\}</span><script type="math/tex">\mathcal S=\{s_1,s_2,\ldots,s_{|\mathcal S|}\}</script></span> ，value function 则为向量 <span><span class="MathJax_Preview">[v(s_1),v(s_2),\ldots,v(s_{|\mathcal S|})]^T</span><script type="math/tex">[v(s_1),v(s_2),\ldots,v(s_{|\mathcal S|})]^T</script></span> 。</p>
<p>简化起见，设 <span><span class="MathJax_Preview">\mathcal S=\{s_1,s_2,s_3\}</span><script type="math/tex">\mathcal S=\{s_1,s_2,s_3\}</script></span> ，参数 <span><span class="MathJax_Preview">\mathbf{w}=(w_1,w_2)^T</span><script type="math/tex">\mathbf{w}=(w_1,w_2)^T</script></span> ，此时 value function <span><span class="MathJax_Preview">[v(s_1),v(s_2),v(s_3)]^T</span><script type="math/tex">[v(s_1),v(s_2),v(s_3)]^T</script></span> 可看作一个三维空间中的点。而参数 <span><span class="MathJax_Preview">\mathbf{w}</span><script type="math/tex">\mathbf{w}</script></span> 则能够通过一个二维子空间提供一个替代的坐标系，其线性组合而成的逼近函数 <span><span class="MathJax_Preview">v_{\mathbf{w}}</span><script type="math/tex">v_{\mathbf{w}}</script></span> 显然也在这个子空间内。</p>
<p>下图是一个状态空间的示例，一些具体的含义会逐渐通过后续的小节来解释。</p>
<p><img alt="" src="../imgs/RLAI_11/space.png" /></p>
<p>给定一个策略 <span><span class="MathJax_Preview">\pi</span><script type="math/tex">\pi</script></span> ，其对应的 <span><span class="MathJax_Preview">v_\pi</span><script type="math/tex">v_\pi</script></span> 可能较复杂，因此难以被参数的线性组合表示出来，故 <span><span class="MathJax_Preview">v_\pi</span><script type="math/tex">v_\pi</script></span> 可能在参数化的子平面外，而 approximation 要做的事情，就是在这个子平面中找到最接近离真实 <span><span class="MathJax_Preview">v_\pi</span><script type="math/tex">v_\pi</script></span> 最近的逼近函数 <span><span class="MathJax_Preview">v_\mathbf{w}</span><script type="math/tex">v_\mathbf{w}</script></span> 。</p>
<p>为了衡量 value function 之间的距离，这里定义一个距离</p>
<div>
<div class="MathJax_Preview">
||v||_\mu^2\doteq\sum_{s\in\mathcal S}\mu(s)v(s)^2
</div>
<script type="math/tex; mode=display">
||v||_\mu^2\doteq\sum_{s\in\mathcal S}\mu(s)v(s)^2
</script>
</div>
<p>将 value function 投影到子空间最近函数的运算定义为算子 <span><span class="MathJax_Preview">\Pi</span><script type="math/tex">\Pi</script></span> ：</p>
<div>
<div class="MathJax_Preview">
\Pi v\doteq v_{\mathbf{w}}\quad\mathrm{where}\quad\mathbf{w}=\arg\min_\mathbf{w}||v-v_{\mathbf{w}}||_\mu^2
</div>
<script type="math/tex; mode=display">
\Pi v\doteq v_{\mathbf{w}}\quad\mathrm{where}\quad\mathbf{w}=\arg\min_\mathbf{w}||v-v_{\mathbf{w}}||_\mu^2
</script>
</div>
<p>对于一个线性估计而言，投影算子可表示为矩阵（下式之中若不可求逆，则用伪逆）</p>
<div>
<div class="MathJax_Preview">
\Pi \doteq \mathbf{X}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}
</div>
<script type="math/tex; mode=display">
\Pi \doteq \mathbf{X}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}
</script>
</div>
<p><span><span class="MathJax_Preview">\mathbf{D}</span><script type="math/tex">\mathbf{D}</script></span> 为分布 <span><span class="MathJax_Preview">\mu(s)</span><script type="math/tex">\mu(s)</script></span> 的对角矩阵形式，<span><span class="MathJax_Preview">\mathbf{X}</span><script type="math/tex">\mathbf{X}</script></span> 则由特征向量组成</p>
<div>
<div class="MathJax_Preview">
\mathbf{D}=\left[\begin{array}{cccc}
\mu(s_1)&amp;&amp;&amp;\\
&amp;\mu(s_2)&amp;&amp;\\
&amp;&amp;\ddots&amp;\\
&amp;&amp;&amp;\mu(s_{|\mathcal S|})
\end{array}\right],\quad
\mathbf{X}=\left[\begin{array}{c}
\mathbf{x}(s_1)^T\\
\mathbf{x}(s_2)^T\\
\vdots\\
\mathbf{x}(s_{|\mathcal S|})^T
\end{array}\right]
</div>
<script type="math/tex; mode=display">
\mathbf{D}=\left[\begin{array}{cccc}
\mu(s_1)&&&\\
&\mu(s_2)&&\\
&&\ddots&\\
&&&\mu(s_{|\mathcal S|})
\end{array}\right],\quad
\mathbf{X}=\left[\begin{array}{c}
\mathbf{x}(s_1)^T\\
\mathbf{x}(s_2)^T\\
\vdots\\
\mathbf{x}(s_{|\mathcal S|})^T
\end{array}\right]
</script>
</div>
<p>使用这两个矩阵，还可以改写出 <span><span class="MathJax_Preview">||v||_\mu^2=v^T\mathbf{D}v</span><script type="math/tex">||v||_\mu^2=v^T\mathbf{D}v</script></span> ，<span><span class="MathJax_Preview">v_\mathbf{w}=\mathbf{Xw}</span><script type="math/tex">v_\mathbf{w}=\mathbf{Xw}</script></span> 。</p>
<p>回想之前求解 Bellman 方程</p>
<div>
<div class="MathJax_Preview">
v_\pi(s)=\sum_a\pi(a|s)\sum_{s',r}p(s',r|s,a)[r+\gamma v_\pi(s')],\forall s\in \mathcal S
</div>
<script type="math/tex; mode=display">
v_\pi(s)=\sum_a\pi(a|s)\sum_{s',r}p(s',r|s,a)[r+\gamma v_\pi(s')],\forall s\in \mathcal S
</script>
</div>
<p>若将 <span><span class="MathJax_Preview">v_\mathbf{w}</span><script type="math/tex">v_\mathbf{w}</script></span> 用以替代 <span><span class="MathJax_Preview">v_\pi</span><script type="math/tex">v_\pi</script></span> ，显然等号不再成立，于是可定义 Bellman Error (BE)：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\bar{\delta}_\mathbf{w}(s)&amp;=\left(\sum_a\pi(a|s)\sum_{s',r}p(s',r|s,a)[r+\gamma v_\mathbf{w}(s')]\right)-v_\mathbf{w}(s)\\
&amp;=\mathbb{E}[R_{t+1}+\gamma v_\mathbf{w}(S_{t+1})-v_\mathbf{w}(S_t)|S_t=s,A_t\sim\pi]
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\bar{\delta}_\mathbf{w}(s)&=\left(\sum_a\pi(a|s)\sum_{s',r}p(s',r|s,a)[r+\gamma v_\mathbf{w}(s')]\right)-v_\mathbf{w}(s)\\
&=\mathbb{E}[R_{t+1}+\gamma v_\mathbf{w}(S_{t+1})-v_\mathbf{w}(S_t)|S_t=s,A_t\sim\pi]
\end{aligned}
</script>
</div>
<p>易观察知，Bellman error 其实就是 TD error 的期望值。</p>
<p>可定义 <strong>Mean Squared Bellman Error</strong>： <span><span class="MathJax_Preview">\mathrm{MSBE}(\mathbf{w})=||\bar{\delta}_\mathbf{w}||_\mu^2</span><script type="math/tex">\mathrm{MSBE}(\mathbf{w})=||\bar{\delta}_\mathbf{w}||_\mu^2</script></span> 。从图 11.3 易知，线性逼近无法使 MSBE 减小至 0（需要 <span><span class="MathJax_Preview">v_\mathbf{w}=v_\pi</span><script type="math/tex">v_\mathbf{w}=v_\pi</script></span> ），后面两节会介绍如何最小化这个 MSBE 。</p>
<p>为简化描述，定义 Bellman 算子 <span><span class="MathJax_Preview">B_\pi:\mathbb{R}^{|\mathcal S|}\to \mathbb{R}^{|\mathcal S|}​</span><script type="math/tex">B_\pi:\mathbb{R}^{|\mathcal S|}\to \mathbb{R}^{|\mathcal S|}​</script></span> ，将 Bellman 方程记作算子形式：</p>
<div>
<div class="MathJax_Preview">
(B_\pi v)(s)\doteq \sum_a\pi(a|s)\sum_{s',r}p(s',r|s,a)[r+\gamma v(s')]
</div>
<script type="math/tex; mode=display">
(B_\pi v)(s)\doteq \sum_a\pi(a|s)\sum_{s',r}p(s',r|s,a)[r+\gamma v(s')]
</script>
</div>
<p>此时可将 Bellman error 记作 <span><span class="MathJax_Preview">\bar{\delta}_\mathbf{w}=B_\pi v_\mathbf{w}-v_\mathbf{w}</span><script type="math/tex">\bar{\delta}_\mathbf{w}=B_\pi v_\mathbf{w}-v_\mathbf{w}</script></span> 。</p>
<p><span><span class="MathJax_Preview">B_\pi</span><script type="math/tex">B_\pi</script></span> 能够产生子空间外新的 value function ，不断作用于 value function ，这有点类似 DP 法，它能够最终收敛到想要的 <span><span class="MathJax_Preview">v_\pi</span><script type="math/tex">v_\pi</script></span> ，如图 11.3 中所示。</p>
<p>同样可以将 Bellman error 投影到参数子空间，得到 <span><span class="MathJax_Preview">\Pi \bar{\delta}_{v_\mathbf{w}}</span><script type="math/tex">\Pi \bar{\delta}_{v_\mathbf{w}}</script></span> ，此时可定义 <strong>Mean Square Projected Bellman Error</strong>：</p>
<div>
<div class="MathJax_Preview">
\mathrm{MSPBE}(\mathbf{w})=||\Pi\bar{\delta}_\mathbf{w}||_\mu^2
</div>
<script type="math/tex; mode=display">
\mathrm{MSPBE}(\mathbf{w})=||\Pi\bar{\delta}_\mathbf{w}||_\mu^2
</script>
</div>
<p>对于线性逼近而言，这时显然就可以在子空间内找到使 MSPBE 为 0 的最优点了，这个点恰好就是前面讲过的 TD 不动点。</p>
<h2 id="115-gradient-descent-in-the-bellman-error"><strong>11.5 Gradient Descent in the Bellman Error</strong><a class="headerlink" href="#115-gradient-descent-in-the-bellman-error" title="Permanent link">&para;</a></h2>
<p>前一节介绍了多种目标函数（MSVE、MSBE、MSPBE 等），这一节回到 off-policy learning 问题。</p>
<p>若想使这些目标函数最小化，一般考虑 SGD 来处理，但前面讲过，只有 MC 才是 true SGD ，此时无论是 on-policy 还是 off-policy 其收敛性都很鲁棒，只不过收敛速度较半梯度法稍慢，而半梯度法则在 off-policy 训练中容易发散，且不太适合用于非线性逼近，true SGD 就不存在这种问题。</p>
<p>11.5 &amp; 11.6 节以 Bellman error 为目标函数来做优化，不过需要先说明的是，这种算法其实并不好，它的失败之处其实很有意思，能够为我们找到好方法提供思路。</p>
<p>首先，在以前的 TD 法中定义过一个 TD error：<span><span class="MathJax_Preview">\delta_t=R_{t+1}+\gamma\hat{v}(S_{t+1},\mathbf{w}_t)-\hat{v}(S_t,\mathbf{w}_t)</span><script type="math/tex">\delta_t=R_{t+1}+\gamma\hat{v}(S_{t+1},\mathbf{w}_t)-\hat{v}(S_t,\mathbf{w}_t)</script></span> ，但并未以它为优化目标来研究过，于是定义『<strong>均方 TD error</strong>』：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\mathrm{MSTDE}(\mathbf{w})&amp;=\sum_{s\in\mathcal S}\mu(s)\mathbb{E}[\delta_t^2|S_t=s,A_t\sim\pi]\\
&amp;=\sum_{s\in\mathcal S}\mu(s)\mathbb{E}[\rho_t\delta_t^2|S_t=s,A_t\sim b]\\
&amp;=\mathbb{E}_b[\rho_t\delta_t^2]
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\mathrm{MSTDE}(\mathbf{w})&=\sum_{s\in\mathcal S}\mu(s)\mathbb{E}[\delta_t^2|S_t=s,A_t\sim\pi]\\
&=\sum_{s\in\mathcal S}\mu(s)\mathbb{E}[\rho_t\delta_t^2|S_t=s,A_t\sim b]\\
&=\mathbb{E}_b[\rho_t\delta_t^2]
\end{aligned}
</script>
</div>
<p>此时的 SGD 更新式为</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\mathbf{w}_{t+1}&amp;=\mathbf{w}_t-\frac{1}{2}\alpha\nabla(\rho_t\delta_t^2)\\
&amp;=\mathbf{w}_t-\alpha\rho_t\delta_t\nabla\delta_t\\
&amp;=\mathbf{w}_t+\alpha\rho_t\delta_t(\nabla\hat{v}(S_t,\mathbf{w}_t)-\gamma\nabla\hat{v}(S_{t+1},\mathbf{w}_t))
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{w}_{t+1}&=\mathbf{w}_t-\frac{1}{2}\alpha\nabla(\rho_t\delta_t^2)\\
&=\mathbf{w}_t-\alpha\rho_t\delta_t\nabla\delta_t\\
&=\mathbf{w}_t+\alpha\rho_t\delta_t(\nabla\hat{v}(S_t,\mathbf{w}_t)-\gamma\nabla\hat{v}(S_{t+1},\mathbf{w}_t))
\end{aligned}
</script>
</div>
<p>这是一个 true SGD 法，称其为『<strong>naive residual-gradient 算法</strong>』。此方法虽然收敛性很鲁棒，但其实它收敛到的值并不是理想值，下面的一个例子具体地展现了这一点（真实最优解的 MSTDE 反而更大）。</p>
<p><img alt="" src="../imgs/RLAI_11/ex11-2.png" /></p>
<p>另一个更好的想法是优化 Bellman error，也就是 TD error 的期望，称该算法为『<strong>residual gradient 算法</strong>』其更新式为</p>
<p><img alt="" src="../imgs/RLAI_11/BE-SGD.png" /></p>
<p>从中看出，此更新式中有两个含有 <span><span class="MathJax_Preview">S_{t+1}</span><script type="math/tex">S_{t+1}</script></span> 的期望式，为保证无偏性，这两个 <span><span class="MathJax_Preview">S_{t+1}</span><script type="math/tex">S_{t+1}</script></span> 应该是独立的，所以需要<strong>在每一步都采两个样本</strong>，如果环境是<strong>确定性</strong>的，那么采取同一 action 后 <span><span class="MathJax_Preview">S_t\to S_{t+1}</span><script type="math/tex">S_t\to S_{t+1}</script></span> 的过程便是确定的，两处的 <span><span class="MathJax_Preview">S_{t+1}</span><script type="math/tex">S_{t+1}</script></span> 也必然是相同值，故做一次采样即可；但若是<strong>非确定性</strong>的环境，则必须采两次样，这在<strong>真实环境</strong>中无法做到（一旦和环境交互就已确定，不可回退），只能在<strong>模拟环境</strong>中通过回退再次模拟来实现。</p>
<p>这个算法是 true SGD，故也有较强的收敛性，但有三个缺点：</p>
<ul>
<li>比半梯度法慢</li>
<li>可能收敛到错误值（如例 11.3 所示）</li>
<li>可能不收敛（下一节讲）</li>
</ul>
<p><img alt="" src="../imgs/RLAI_11/ex11-3.png" /></p>
<h2 id="116-the-bellman-error-is-not-learnable"><strong>11.6 The Bellman Error is Not Learnable</strong><a class="headerlink" href="#116-the-bellman-error-is-not-learnable" title="Permanent link">&para;</a></h2>
<p>本节的『<strong>可学习</strong>（learnable）』与传统机器学习中的 learnable 定义（能够在多项式复杂度下有效地学习）不同，在强化学习中，若一些量<strong>在给定内部结构、知识等信息后可以计算，但通过观测得到的序列却无法计算或估计出来</strong>，则称这些量是<strong>不可学习</strong>的。</p>
<p><img alt="" src="../imgs/RLAI_11/ex-learnable.png" /></p>
<p>上面的例子中，两个不同的问题却有可能产生出相同的观测序列。若设 <span><span class="MathJax_Preview">\gamma = 0</span><script type="math/tex">\gamma = 0</script></span> ，三个 state 的 true value 应为 1、0、2 ，若设 <span><span class="MathJax_Preview">w=1</span><script type="math/tex">w=1</script></span> ，则左图的 MSVE 为 0 ，右图的 MSVE 为 1 。同样的观测序列，对应的理论 MSVE 值却不同，说明如果不给出问题背景，就无法学出正确对应的 MSVE ，因此 MSVE 就是 not learnable 的。</p>
<p>MSVE 仍然有一定使用价值，事实上，有着相同分布的 MDP 问题的<strong>最优参数其实是相同的</strong>，利用这个特殊性质，仍然可以采用 MSVE 作为目标函数来进行优化。</p>
<p>为更好理解，下面引入一个可学习的 『<strong>Mean Square Return Error</strong>』来探讨，他在 on-policy 下写作</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\mathrm{MSRE}(\mathbf{w})&amp;=\mathbb{E}[(G_t-\hat{v}(S_t,\mathbf{w}))^2]\\
&amp;=\mathrm{MSVE}(\mathbf{w})+\mathbb{E}[(G_t-v_\pi(S_t))^2]
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\mathrm{MSRE}(\mathbf{w})&=\mathbb{E}[(G_t-\hat{v}(S_t,\mathbf{w}))^2]\\
&=\mathrm{MSVE}(\mathbf{w})+\mathbb{E}[(G_t-v_\pi(S_t))^2]
\end{aligned}
</script>
</div>
<p>可以看出，MSRE 比 MSVE 多出一项与参数 <span><span class="MathJax_Preview">\mathbf{w}</span><script type="math/tex">\mathbf{w}</script></span> 无关的项，因此两种目标函数对应的最优参数 <span><span class="MathJax_Preview">\mathbf{w}^*</span><script type="math/tex">\mathbf{w}^*</script></span> 是相同的，而 MSRE 又是可学习的，故事实上仍可用 MSVE 来做优化。他们的关系如下图所示。</p>
<p><img alt="" src="../imgs/RLAI_11/MSVE-MSRE.png" /></p>
<p>再来看 MSBE ，他和 MSVE 一样，可由 MDP 问题结构信息计算求得，而无法通过观测 / 经验数据来进行学习。但与 MSVE 不同的是，观测序列的分布相同时，求出的最优解不再相同。下面的例子描述了这一情况。</p>
<p><img alt="" src="../imgs/RLAI_11/ex11-4.png" /></p>
<p>此外，另两种 bootstrapping 目标函数 MSPBE、MSTDE 可由 data 学习（learnable），他们的关系如下图所示。</p>
<p><img alt="" src="../imgs/RLAI_11/PBE-TDE.png" /></p>
<p>MSBE 由于不可学习，故只能用于 model-based learning，residual-gradient 是唯一能最小化 MSBE 的算法，需要对同一 state 做两次采样，对环境信息依赖程度较大，故此方法局限性较高。</p>
<h2 id="117-gradient-td-methods"><strong>11.7 Gradient-TD Methods</strong><a class="headerlink" href="#117-gradient-td-methods" title="Permanent link">&para;</a></h2>
<p>现考虑最小化 MSPBE 的 SGD 方法，下面介绍推导复杂度为 <span><span class="MathJax_Preview">O(d)</span><script type="math/tex">O(d)</script></span> 的算法。</p>
<p>首先，将 MSPBE 写作矩阵形式</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\mathrm{MSPBE}(\mathbf{w})&amp;=||\Pi\bar{\delta}_\mathbf{w}||_\mu^2\\
&amp;=(\Pi\bar{\delta}_\mathbf{w})^T\mathbf{D}\Pi\bar{\delta}_\mathbf{w}\\
&amp;=\bar{\delta}_\mathbf{w}^T\Pi^T\mathbf{D}\Pi\bar{\delta}_\mathbf{w}\\
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\mathrm{MSPBE}(\mathbf{w})&=||\Pi\bar{\delta}_\mathbf{w}||_\mu^2\\
&=(\Pi\bar{\delta}_\mathbf{w})^T\mathbf{D}\Pi\bar{\delta}_\mathbf{w}\\
&=\bar{\delta}_\mathbf{w}^T\Pi^T\mathbf{D}\Pi\bar{\delta}_\mathbf{w}\\
\end{aligned}
</script>
</div>
<p>由于前面已定义 <span><span class="MathJax_Preview">\Pi = \mathbf{X}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}</span><script type="math/tex">\Pi = \mathbf{X}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}</script></span> ，故有（注意 <span><span class="MathJax_Preview">\mathbf{D}</span><script type="math/tex">\mathbf{D}</script></span> 是对称矩阵）</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\Pi^T\mathbf{D}\Pi&amp;=[\mathbf{X}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}]^T\mathbf{D}[\mathbf{X}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}]\\
&amp;=\mathbf{DX}(\mathbf{X}^T\mathbf{DX})^{-1}\mathbf{X}^T\mathbf{D}\mathbf{X}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}\\
&amp;=\mathbf{DX}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\Pi^T\mathbf{D}\Pi&=[\mathbf{X}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}]^T\mathbf{D}[\mathbf{X}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}]\\
&=\mathbf{DX}(\mathbf{X}^T\mathbf{DX})^{-1}\mathbf{X}^T\mathbf{D}\mathbf{X}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}\\
&=\mathbf{DX}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{D}
\end{aligned}
</script>
</div>
<p>回到前式即得</p>
<div>
<div class="MathJax_Preview">
\mathrm{MSPBE}=(\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w})^{T}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}(\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w})
</div>
<script type="math/tex; mode=display">
\mathrm{MSPBE}=(\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w})^{T}(\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}(\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w})
</script>
</div>
<p>则其梯度为</p>
<div>
<div class="MathJax_Preview">
\nabla\mathrm{MSPBE}(\mathbf{w})=[2\nabla(\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w})^{T}](\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}(\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w})
</div>
<script type="math/tex; mode=display">
\nabla\mathrm{MSPBE}(\mathbf{w})=[2\nabla(\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w})^{T}](\mathbf{X}^T\mathbf{D}\mathbf{X})^{-1}(\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w})
</script>
</div>
<p><span><span class="MathJax_Preview">\mu</span><script type="math/tex">\mu</script></span> 是 behavior policy 下的状态分布，故上式中的各部分都可表示为该分布下的期望：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w}&amp;=\sum_s\mu(s)\mathbf{x}(s)\bar{\delta}_\mathbf{w}(s)=\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]\\
\nabla(\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w})^T&amp;=\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]^T=\mathbb{E}[\rho_t\nabla\delta_t^T\mathbf{x}_t^T]\\
&amp;=\mathbb{E}[\rho_t\nabla(R_{t+1}+\gamma\mathbf{w}^T\mathbf{x}_{t+1}-\mathbf{w}^T\mathbf{x}_{t})^T\mathbf{x}_t^T]\\
&amp;=\mathbb{E}[\rho_t(\gamma\mathbf{x}_{t+1}-\mathbf{x}_t)\mathbf{x}_t^T]\\
\mathbf{X}^T\mathbf{DX}&amp;=\sum_s\mu(s)\mathbf{x}_s\mathbf{x}_s^T=\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w}&=\sum_s\mu(s)\mathbf{x}(s)\bar{\delta}_\mathbf{w}(s)=\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]\\
\nabla(\mathbf{X}^T\mathbf{D}\bar{\delta}_\mathbf{w})^T&=\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]^T=\mathbb{E}[\rho_t\nabla\delta_t^T\mathbf{x}_t^T]\\
&=\mathbb{E}[\rho_t\nabla(R_{t+1}+\gamma\mathbf{w}^T\mathbf{x}_{t+1}-\mathbf{w}^T\mathbf{x}_{t})^T\mathbf{x}_t^T]\\
&=\mathbb{E}[\rho_t(\gamma\mathbf{x}_{t+1}-\mathbf{x}_t)\mathbf{x}_t^T]\\
\mathbf{X}^T\mathbf{DX}&=\sum_s\mu(s)\mathbf{x}_s\mathbf{x}_s^T=\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]
\end{aligned}
</script>
</div>
<p>代回前式，即得</p>
<div>
<div class="MathJax_Preview">
\nabla\mathrm{MSPBE}(\mathbf{w})=2\mathbb{E}[\rho_t(\gamma\mathbf{x}_{t+1}-\mathbf{x}_t)\mathbf{x}_t^T]\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]
</div>
<script type="math/tex; mode=display">
\nabla\mathrm{MSPBE}(\mathbf{w})=2\mathbb{E}[\rho_t(\gamma\mathbf{x}_{t+1}-\mathbf{x}_t)\mathbf{x}_t^T]\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]
</script>
</div>
<p>此时梯度为三个期望的乘积，且一、三项不独立，都依赖下一时刻的 <span><span class="MathJax_Preview">\mathbf{x}_{t+1}</span><script type="math/tex">\mathbf{x}_{t+1}</script></span>（第三项中是含在 <span><span class="MathJax_Preview">\delta_t</span><script type="math/tex">\delta_t</script></span> 内），所以不能对每个值采样然后直接相乘求期望，而应考虑分别分别对期望求估计后再组合得到梯度的无偏估计，但计算资源消耗较大，一个改进措施是，只估计某两项，然后对剩下一项做采样。</p>
<p>先估计并存储后两项，得到向量</p>
<div>
<div class="MathJax_Preview">
\mathbf{v}\approx\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]
</div>
<script type="math/tex; mode=display">
\mathbf{v}\approx\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]
</script>
</div>
<p>观察发现上式和一般『<strong>最小平方问题</strong>』解的形式（<span><span class="MathJax_Preview">\mathbf{w}=(\mathbf{\Phi}^T\mathbf{\Phi})^{-1}\mathbf{\Phi}^T\mathbf{t}</span><script type="math/tex">\mathbf{w}=(\mathbf{\Phi}^T\mathbf{\Phi})^{-1}\mathbf{\Phi}^T\mathbf{t}</script></span>）相似，此问题可看作是对 <span><span class="MathJax_Preview">\rho_t\delta_t</span><script type="math/tex">\rho_t\delta_t</script></span> 求最小平方估计，为了优化上面约等式误差，以 <span><span class="MathJax_Preview">(\mathbf{v}^T\mathbf{x}_t-\rho_t\delta_t)^2</span><script type="math/tex">(\mathbf{v}^T\mathbf{x}_t-\rho_t\delta_t)^2</script></span> 为目标函数，可得 SGD 更新式</p>
<div>
<div class="MathJax_Preview">
\mathbf{v}_{t+1}=\mathbf{v}_t+\beta(\rho_t\delta_t-\mathbf{v}_t^T\mathbf{x}_t)\mathbf{x}_t
</div>
<script type="math/tex; mode=display">
\mathbf{v}_{t+1}=\mathbf{v}_t+\beta(\rho_t\delta_t-\mathbf{v}_t^T\mathbf{x}_t)\mathbf{x}_t
</script>
</div>
<p>使用这个方法可以在每一步得到更新的 <span><span class="MathJax_Preview">\mathbf{v}</span><script type="math/tex">\mathbf{v}</script></span> ，在存储了 <span><span class="MathJax_Preview">\mathbf{v}</span><script type="math/tex">\mathbf{v}</script></span> 的情况下，参数 <span><span class="MathJax_Preview">\mathbf{w}</span><script type="math/tex">\mathbf{w}</script></span> 的更新式为</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\mathbf{w}_{t+1}&amp;=\mathbf{w}_t-\frac{1}{2}\alpha\nabla\mathrm{MSPBE}(\mathbf{w}_t)\\
&amp;=\mathbf{w}_t-\frac{1}{2}\alpha 2\mathbb{E}[\rho_t(\gamma\mathbf{x}_{t+1}-\mathbf{x}_t)\mathbf{x}_t^T]\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]\\
&amp;=\mathbf{w}_t+\alpha\mathbb{E}[\rho_t(\mathbf{x}_t-\gamma\mathbf{x}_{t+1})\mathbf{x}_t^T]\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]\\
&amp;\approx\mathbf{w}_t+\alpha\mathbb{E}[\rho_t(\mathbf{x}_t-\gamma\mathbf{x}_{t+1})\mathbf{x}_t^T]\mathbf{v}_t\\
&amp;\approx\mathbf{w}_t+\alpha\rho_t(\mathbf{x}_t-\gamma\mathbf{x}_{t+1})\mathbf{x}_t^T\mathbf{v}_t\qquad(\mathrm{sampling})
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{w}_{t+1}&=\mathbf{w}_t-\frac{1}{2}\alpha\nabla\mathrm{MSPBE}(\mathbf{w}_t)\\
&=\mathbf{w}_t-\frac{1}{2}\alpha 2\mathbb{E}[\rho_t(\gamma\mathbf{x}_{t+1}-\mathbf{x}_t)\mathbf{x}_t^T]\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]\\
&=\mathbf{w}_t+\alpha\mathbb{E}[\rho_t(\mathbf{x}_t-\gamma\mathbf{x}_{t+1})\mathbf{x}_t^T]\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]\\
&\approx\mathbf{w}_t+\alpha\mathbb{E}[\rho_t(\mathbf{x}_t-\gamma\mathbf{x}_{t+1})\mathbf{x}_t^T]\mathbf{v}_t\\
&\approx\mathbf{w}_t+\alpha\rho_t(\mathbf{x}_t-\gamma\mathbf{x}_{t+1})\mathbf{x}_t^T\mathbf{v}_t\qquad(\mathrm{sampling})
\end{aligned}
</script>
</div>
<p>称此算法为『GTD2』，若先计算 <span><span class="MathJax_Preview">(\mathbf{x}_t^T\mathbf{v}_t)</span><script type="math/tex">(\mathbf{x}_t^T\mathbf{v}_t)</script></span> ，则算法复杂度为 <span><span class="MathJax_Preview">O(d)</span><script type="math/tex">O(d)</script></span> 。一个略微的改进是计算 <span><span class="MathJax_Preview">\mathbf{v}_t</span><script type="math/tex">\mathbf{v}_t</script></span> 前先做一点分析调整</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\mathbf{w}_{t+1}&amp;=\mathbf{w}_t+\alpha\mathbb{E}[\rho_t(\mathbf{x}_t-\gamma\mathbf{x}_{t+1})\mathbf{x}_t^T]\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]\\
&amp;=\mathbf{w}_t+\alpha(\mathbb{E}[\rho_t\mathbf{x}_t\mathbf{x}_t^T]-\gamma\mathbb{E}[\rho_t\mathbf{x}_{t+1}\mathbf{x}_t^T])\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]\\
&amp;=\mathbf{w}_t+\alpha(\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]-\gamma\mathbb{E}[\rho_t\mathbf{x}_{t+1}\mathbf{x}_t^T]\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t])\\
&amp;\approx\mathbf{w}_t+\alpha(\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]-\gamma\mathbb{E}[\rho_t\mathbf{x}_{t+1}\mathbf{x}_t^T]\mathbf{v}_t)\\
&amp;\approx\mathbf{w}_t+\alpha\rho_t(\delta_t\mathbf{x}_t-\gamma\mathbf{x}_{t+1}\mathbf{x}_t^T\mathbf{v}_t) \qquad (\mathrm{sampling})
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{w}_{t+1}&=\mathbf{w}_t+\alpha\mathbb{E}[\rho_t(\mathbf{x}_t-\gamma\mathbf{x}_{t+1})\mathbf{x}_t^T]\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]\\
&=\mathbf{w}_t+\alpha(\mathbb{E}[\rho_t\mathbf{x}_t\mathbf{x}_t^T]-\gamma\mathbb{E}[\rho_t\mathbf{x}_{t+1}\mathbf{x}_t^T])\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]\\
&=\mathbf{w}_t+\alpha(\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]-\gamma\mathbb{E}[\rho_t\mathbf{x}_{t+1}\mathbf{x}_t^T]\mathbb{E}[\mathbf{x}_t\mathbf{x}_t^T]^{-1}\mathbb{E}[\rho_t\delta_t\mathbf{x}_t])\\
&\approx\mathbf{w}_t+\alpha(\mathbb{E}[\rho_t\delta_t\mathbf{x}_t]-\gamma\mathbb{E}[\rho_t\mathbf{x}_{t+1}\mathbf{x}_t^T]\mathbf{v}_t)\\
&\approx\mathbf{w}_t+\alpha\rho_t(\delta_t\mathbf{x}_t-\gamma\mathbf{x}_{t+1}\mathbf{x}_t^T\mathbf{v}_t) \qquad (\mathrm{sampling})
\end{aligned}
</script>
</div>
<p>称此算法为『TD(0) with gradient correction (TDC)』或者『GTD(0)』若先计算 <span><span class="MathJax_Preview">(\mathbf{x}_t^T\mathbf{v}_t)</span><script type="math/tex">(\mathbf{x}_t^T\mathbf{v}_t)</script></span> ，则算法复杂度为 <span><span class="MathJax_Preview">O(d)</span><script type="math/tex">O(d)</script></span> 。</p>
<p>TDC 算法在 Baird 反例上的实际表现如下图所示</p>
<p><img alt="" src="../imgs/RLAI_11/TDC.png" /></p>
<p>GTD2 及 TDC 都包含了两个学习过程，主过程学习 <span><span class="MathJax_Preview">\mathbf{w}</span><script type="math/tex">\mathbf{w}</script></span> ，次过程学习 <span><span class="MathJax_Preview">\mathbf{v}</span><script type="math/tex">\mathbf{v}</script></span>  。次过程在每一步中需要先于主过程，这种依赖关系称之为『<strong>层叠</strong>（cascade）』，关于学习率，通常需要满足极限</p>
<div>
<div class="MathJax_Preview">
\beta\to 0,\quad\frac{\alpha}{\beta}\to0
</div>
<script type="math/tex; mode=display">
\beta\to 0,\quad\frac{\alpha}{\beta}\to0
</script>
</div>
<p>Gradient TD 方法是最简单易懂的稳定 off-policy 方法，并且有很多的衍生方法。</p>
<h2 id="118-emphatic-td-methods"><strong>11.8 Emphatic-TD Methods</strong><a class="headerlink" href="#118-emphatic-td-methods" title="Permanent link">&para;</a></h2>
<p>这一节简单介绍了 Emphatic-TD 算法：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
\delta_t&amp;=R_{t+1}+\gamma\hat{v}(S_{t+1},\mathbf{w}_t)-\hat{v}(S_t,\mathbf{w}_t)\\
\mathbf{w}_{t+1}&amp;=\mathbf{w}_t+\alpha M_t\rho_t\delta_t\nabla\hat{v}(S_t,\mathbf{w}_t)\\
M_t&amp;=\gamma\rho_{t-1}M_{t-1}+I_t
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\delta_t&=R_{t+1}+\gamma\hat{v}(S_{t+1},\mathbf{w}_t)-\hat{v}(S_t,\mathbf{w}_t)\\
\mathbf{w}_{t+1}&=\mathbf{w}_t+\alpha M_t\rho_t\delta_t\nabla\hat{v}(S_t,\mathbf{w}_t)\\
M_t&=\gamma\rho_{t-1}M_{t-1}+I_t
\end{aligned}
</script>
</div>
<p>其中 <span><span class="MathJax_Preview">I_t</span><script type="math/tex">I_t</script></span> 表示 interest，为随机值，<span><span class="MathJax_Preview">M_t</span><script type="math/tex">M_t</script></span> 表示 emphasis 。</p>
<p>Emphatic-TD 算法在 Baird 反例上的实际表现如下图所示</p>
<p><img alt="" src="../imgs/RLAI_11/emphasis-td.png" /></p>
<p>该算法方差较大，导致其并不实用，所以如何减少算法的方差很值得研究。</p>
<h2 id="119-reducing-variance"><strong>11.9 Reducing Variance</strong><a class="headerlink" href="#119-reducing-variance" title="Permanent link">&para;</a></h2>
<p>off-policy 算法直观上显然要比 on-policy 算法有着更大的方差，他从行为策略中获得的数据可能和目标策略关系不大，极端情况下甚至可能完全学不到东西，比如一个人不能通过做饭的经验知识来学习如何开车。</p>
<p>只有当 behavior policy 与 target policy 相关性较大，即当两个策略经过的 states、actions 很接近，才能在 off-policy training 中取得较好的进展。</p>
<p>关于这些<strong>相关但又不一致</strong>的行为策略，主要的问题是如何尽量利用上他们。目前而言这一块已有很多相关的工作，本节末尾列举了很多方法，不作具体介绍。</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../RLAI_10/" title="Chapter 10" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                Chapter 10
              </span>
            </div>
          </a>
        
        
          <a href="../RLAI_12/" title="Chapter 12" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                Chapter 12
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2016-2019 ONCE.MATH
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../../../assets/fonts/font-awesome.css">
    
      <a href="https://github.com/zawnpn" class="md-footer-social__link fa fa-github"></a>
    
      <a href="https://twitter.com/zawnpn" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://steamcommunity.com/id/zawnpn/" class="md-footer-social__link fa fa-steam"></a>
    
      <a href="https://www.zhihu.com/people/zhangwanpeng" class="md-footer-social__link fa fa-globe"></a>
    
  </div>

      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../../assets/javascripts/application.583bbe55.js"></script>
      
        
        
          
          <script src="../../../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../../../../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../../../../assets/javascripts/lunr/lunr.jp.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../../.."}})</script>
      
        <script src="../../../../assets/extra.js"></script>
      
        <script src="//cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_SVG"></script>
      
    
    
      
    
  </body>
</html>